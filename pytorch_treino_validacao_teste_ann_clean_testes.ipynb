{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "#Importar bibliotecas\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar vari√°veis\n",
    "dataset_input = \"bin/dataset_input_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\"\n",
    "dataset_output = \"bin/dataset_output_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3EUlEQVR4nO3df3hU9Z3//df8SGYSIAMkJUMgGFQ0Kmmi/AihXmX7NdvQ5aqmdtuY2xXKctm7riI2XVqgCO7XtbHbpYstfMuNt1Z3V4Rlq6ylbFoaf6zeRCJJEFMVtSqJyCQEZCYESMLMuf9IMsnIQOaEZE4Cz8d1nSuZM+9z5nNOW/LqZz6fz7EZhmEIAABgGLNb3QAAAID+EFgAAMCwR2ABAADDHoEFAAAMewQWAAAw7BFYAADAsEdgAQAAwx6BBQAADHtOqxswGEKhkD799FONGTNGNpvN6uYAAIAYGIah1tZWZWRkyG6/cB/KJRFYPv30U2VmZlrdDAAAMACNjY2aPHnyBWsuicAyZswYSV0XnJKSYnFrAABALAKBgDIzM8N/xy/kkggsPV8DpaSkEFgAABhhYhnOwaBbAAAw7BFYAADAsEdgAQAAwx6BBQAADHsEFgAAMOwRWAAAwLBHYAEAAMMegQUAAAx7BBYAADDsEVgAAMCwR2ABAADDHoEFAAAMewMKLBs3blRWVpbcbrfy8/NVXV19wfrt27crOztbbrdbOTk52rVrV8T7Npst6vazn/1sIM0bNJ3BkP73b9/WQy/8Se1ng5a2BQCAy5npwLJt2zaVlZVp7dq1qq2tVW5uroqKitTc3By1fs+ePSotLdWSJUtUV1en4uJiFRcXq76+Plxz5MiRiO3JJ5+UzWbTN7/5zYFf2SAIGYae/P8+0lN7Plb72ZClbQEA4HJmMwzDMHNAfn6+Zs2apQ0bNkiSQqGQMjMztXTpUq1YseKc+pKSErW1tWnnzp3hfXPmzFFeXp42bdoU9TOKi4vV2tqqysrKmNoUCATk8Xjk9/uVkpJi5nIuKBgydNWqrt6gugf/UuNGJQ7auQEAuNyZ+fttqoelo6NDNTU1Kiws7D2B3a7CwkJVVVVFPaaqqiqiXpKKiorOW9/U1KTf/e53WrJkyXnb0d7erkAgELENBbut9/eguVwHAAAGkanA0tLSomAwqPT09Ij96enp8vl8UY/x+Xym6p9++mmNGTNGt99++3nbUV5eLo/HE94yMzPNXEbMbDabnN2pJRgisAAAYJVhN0voySef1J133im3233empUrV8rv94e3xsbGIWuPozuwnCWwAABgGaeZ4rS0NDkcDjU1NUXsb2pqktfrjXqM1+uNuf7VV1/VwYMHtW3btgu2w+VyyeVymWn6gDntNrVLCgYJLAAAWMVUD0tiYqJmzJgRMRg2FAqpsrJSBQUFUY8pKCg4Z/Ds7t27o9Y/8cQTmjFjhnJzc800a0j19rAwSwgAAKuY6mGRpLKyMi1atEgzZ87U7NmztX79erW1tWnx4sWSpIULF2rSpEkqLy+XJC1btkzz5s3TunXrtGDBAm3dulX79u3T5s2bI84bCAS0fft2rVu3bhAua/A4HV2ZjjEsAABYx3RgKSkp0dGjR7VmzRr5fD7l5eWpoqIiPLC2oaFBdntvx83cuXO1ZcsWrV69WqtWrdK0adO0Y8cOTZ8+PeK8W7dulWEYKi0tvchLGlyMYQEAwHqm12EZjoZqHRZJmvOTSvkCZ7Rz6c2aPskzqOcGAOByNmTrsFyO6GEBAMB6BJZ+OB2swwIAgNUILP1wsHAcAACWI7D0w8m0ZgAALEdg6YfDzrRmAACsRmDph5NBtwAAWI7A0o/wGBaW5gcAwDIEln4wrRkAAOsRWPrBLCEAAKxHYOlHzxiW4MhfEBgAgBGLwNKP3h4WpjUDAGAVAks/wrOEGHQLAIBlCCz9YB0WAACsR2DpB+uwAABgPQJLPxw8/BAAAMsRWPrhsNHDAgCA1Qgs/XAySwgAAMsRWPrRO63Z4oYAAHAZI7D0w+mghwUAAKsRWPrBs4QAALAegaUfTtZhAQDAcgSWftDDAgCA9Qgs/XDytGYAACxHYOmHnWcJAQBgOQJLP1iHBQAA6xFY+hFeh8WghwUAAKsQWPrBGBYAAKxHYOmHo3taM2NYAACwDoGlH/SwAABgPQJLP1iHBQAA6xFY+tH7LCECCwAAViGw9MNu6+lhYVozAABWIbD0gzEsAABYj8DSD8awAABgPQJLPxjDAgCA9Qgs/ehZh4XAAgCAdQgs/XDylRAAAJYjsPTDwaBbAAAsN6DAsnHjRmVlZcntdis/P1/V1dUXrN++fbuys7PldruVk5OjXbt2nVPzzjvv6NZbb5XH49GoUaM0a9YsNTQ0DKR5g4oeFgAArGc6sGzbtk1lZWVau3atamtrlZubq6KiIjU3N0et37Nnj0pLS7VkyRLV1dWpuLhYxcXFqq+vD9f8+c9/1s0336zs7Gy9/PLLOnDggB588EG53e6BX9kgsYd7WFiHBQAAq9gMwzDVdZCfn69Zs2Zpw4YNkqRQKKTMzEwtXbpUK1asOKe+pKREbW1t2rlzZ3jfnDlzlJeXp02bNkmS7rjjDiUkJOjf/u3fBnQRgUBAHo9Hfr9fKSkpAzrH+bz6/lHd9US1sr1jVPHAlwf13AAAXM7M/P021cPS0dGhmpoaFRYW9p7AbldhYaGqqqqiHlNVVRVRL0lFRUXh+lAopN/97ne65pprVFRUpAkTJig/P187duww07QhwxgWAACsZyqwtLS0KBgMKj09PWJ/enq6fD5f1GN8Pt8F65ubm3Xy5Ek9+uijmj9/vv7whz/oG9/4hm6//Xa98sorUc/Z3t6uQCAQsQ0VZ8+0ZnMdUQAAYBA5rW5AqHtsyG233abvf//7kqS8vDzt2bNHmzZt0rx58845pry8XP/wD/8Ql/bRwwIAgPVM9bCkpaXJ4XCoqakpYn9TU5O8Xm/UY7xe7wXr09LS5HQ6df3110fUXHfddeedJbRy5Ur5/f7w1tjYaOYyTAnPEgoSWAAAsIqpwJKYmKgZM2aosrIyvC8UCqmyslIFBQVRjykoKIiol6Tdu3eH6xMTEzVr1iwdPHgwoua9997TFVdcEfWcLpdLKSkpEdtQoYcFAADrmf5KqKysTIsWLdLMmTM1e/ZsrV+/Xm1tbVq8eLEkaeHChZo0aZLKy8slScuWLdO8efO0bt06LViwQFu3btW+ffu0efPm8DmXL1+ukpISffnLX9ZXvvIVVVRU6Le//a1efvnlwbnKi9DzLCHWYQEAwDqmA0tJSYmOHj2qNWvWyOfzKS8vTxUVFeGBtQ0NDbLbeztu5s6dqy1btmj16tVatWqVpk2bph07dmj69Onhmm984xvatGmTysvLdf/99+vaa6/Vb37zG918882DcIkXx8k6LAAAWM70OizD0VCuw/Lh0ZP6X+te0Ri3U289VDSo5wYA4HI2ZOuwXI6cPK0ZAADLEVj64XAw6BYAAKsRWPrhZJYQAACWI7D0w9Hnac2XwHAfAABGJAJLP3p6WCSJThYAAKxBYOmHo09gOcvUZgAALEFg6Yezz5oyjGMBAMAaBJZ+9MkrrHYLAIBFCCz9iOhh4QGIAABYgsDSjz5DWBRklhAAAJYgsPTDZrOxFgsAABYjsMSg71osAAAg/ggsMQj3sDCGBQAASxBYYtDbw8I6LAAAWIHAEgOngyc2AwBgJQJLDOw2xrAAAGAlAksMmCUEAIC1CCwxYJYQAADWIrDEwOmghwUAACsRWGLg4CshAAAsRWCJgZNpzQAAWIrAEgOHnWnNAABYicASAyeDbgEAsBSBJQZ2luYHAMBSBJYY0MMCAIC1CCwxYJYQAADWIrDEILzSrUFgAQDACgSWGPT2sDCtGQAAKxBYYhAew8KgWwAALEFgiQHrsAAAYC0CSwyYJQQAgLUILDFglhAAANYisMTAQQ8LAACWIrDEwMksIQAALEVgiUHvV0IWNwQAgMsUgSUGTgc9LAAAWInAEgPGsAAAYC0CSwycrMMCAIClCCwxoIcFAABrDSiwbNy4UVlZWXK73crPz1d1dfUF67dv367s7Gy53W7l5ORo165dEe9/5zvfkc1mi9jmz58/kKYNCdZhAQDAWqYDy7Zt21RWVqa1a9eqtrZWubm5KioqUnNzc9T6PXv2qLS0VEuWLFFdXZ2Ki4tVXFys+vr6iLr58+fryJEj4e3ZZ58d2BUNAQfPEgIAwFKmA8vPf/5z3X333Vq8eLGuv/56bdq0ScnJyXryySej1j/22GOaP3++li9fruuuu04PP/ywbrrpJm3YsCGizuVyyev1hrdx48YN7IqGAOuwAABgLVOBpaOjQzU1NSosLOw9gd2uwsJCVVVVRT2mqqoqol6SioqKzql/+eWXNWHCBF177bW65557dOzYsfO2o729XYFAIGIbSuGvhAx6WAAAsIKpwNLS0qJgMKj09PSI/enp6fL5fFGP8fl8/dbPnz9f//qv/6rKykr99Kc/1SuvvKKvfe1rCgaDUc9ZXl4uj8cT3jIzM81chmlOxrAAAGApp9UNkKQ77rgj/HtOTo6++MUv6qqrrtLLL7+sW2655Zz6lStXqqysLPw6EAgMaWhxdE9rZgwLAADWMNXDkpaWJofDoaampoj9TU1N8nq9UY/xer2m6iXpyiuvVFpamj744IOo77tcLqWkpERsQ4keFgAArGUqsCQmJmrGjBmqrKwM7wuFQqqsrFRBQUHUYwoKCiLqJWn37t3nrZekTz75RMeOHdPEiRPNNG/IsA4LAADWMj1LqKysTI8//riefvppvfPOO7rnnnvU1tamxYsXS5IWLlyolStXhuuXLVumiooKrVu3Tu+++64eeugh7du3T/fdd58k6eTJk1q+fLlef/11ffzxx6qsrNRtt92mq6++WkVFRYN0mRen91lCBBYAAKxgegxLSUmJjh49qjVr1sjn8ykvL08VFRXhgbUNDQ2y23tz0Ny5c7VlyxatXr1aq1at0rRp07Rjxw5Nnz5dkuRwOHTgwAE9/fTTOnHihDIyMvTVr35VDz/8sFwu1yBd5sWx23p6WJjWDACAFWyGMfLn6gYCAXk8Hvn9/iEZz7K1ukErnntLhddN0P+7aNagnx8AgMuRmb/fPEsoBizNDwCAtQgsMegZw8KgWwAArEFgiUHPOiz0sAAAYA0CSwycTGsGAMBSBJYYMIYFAABrEVhiQA8LAADWIrDEwB7uYWEdFgAArEBgiUG4h4WHHwIAYAkCSwwYwwIAgLUILDFw9kxrHvmLAgMAMCIRWGJADwsAANYisMSAMSwAAFiLwBIDelgAALAWgSUGPEsIAABrEVhi4LCxDgsAAFYisMTAwUq3AABYisASAydPawYAwFIElhg4HAy6BQDASgSWGDiZJQQAgKUILDHoO4bFYLVbAADijsASg54eFkmikwUAgPgjsMTA0SewnGVqMwAAcUdgiUHfwMI4FgAA4o/AEoPIHhYCCwAA8UZgiUHPOiySFOQBiAAAxB2BJQZ9OlgUZJYQAABxR2CJgc1mYy0WAAAsRGCJEc8TAgDAOgSWGIV7WBjDAgBA3BFYYtTbw8I6LAAAxBuBJUYOxrAAAGAZAkuMHN1TmxnDAgBA/BFYYsQsIQAArENgiRFfCQEAYB0CS4ycDqY1AwBgFQJLjOhhAQDAOgSWGDmZ1gwAgGUILDHqmSVEDwsAAPFHYImRo/tOMYYFAID4G1Bg2bhxo7KysuR2u5Wfn6/q6uoL1m/fvl3Z2dlyu93KycnRrl27zlv7ve99TzabTevXrx9I04ZMuIeFpfkBAIg704Fl27ZtKisr09q1a1VbW6vc3FwVFRWpubk5av2ePXtUWlqqJUuWqK6uTsXFxSouLlZ9ff05tc8//7xef/11ZWRkmL+SIebk4YcAAFjGdGD5+c9/rrvvvluLFy/W9ddfr02bNik5OVlPPvlk1PrHHntM8+fP1/Lly3Xdddfp4Ycf1k033aQNGzZE1B0+fFhLly7VM888o4SEhIFdzRBilhAAANYxFVg6OjpUU1OjwsLC3hPY7SosLFRVVVXUY6qqqiLqJamoqCiiPhQK6a677tLy5ct1ww039NuO9vZ2BQKBiG2ohVe6NQgsAADEm6nA0tLSomAwqPT09Ij96enp8vl8UY/x+Xz91v/0pz+V0+nU/fffH1M7ysvL5fF4wltmZqaZyxiQ3h4WpjUDABBvls8Sqqmp0WOPPaannnpKNpstpmNWrlwpv98f3hobG4e4lX3GsDDoFgCAuDMVWNLS0uRwONTU1BSxv6mpSV6vN+oxXq/3gvWvvvqqmpubNWXKFDmdTjmdTh06dEg/+MEPlJWVFfWcLpdLKSkpEdtQYx0WAACsYyqwJCYmasaMGaqsrAzvC4VCqqysVEFBQdRjCgoKIuolaffu3eH6u+66SwcOHND+/fvDW0ZGhpYvX67f//73Zq9nyDBLCAAA6zjNHlBWVqZFixZp5syZmj17ttavX6+2tjYtXrxYkrRw4UJNmjRJ5eXlkqRly5Zp3rx5WrdunRYsWKCtW7dq37592rx5syQpNTVVqampEZ+RkJAgr9era6+99mKvb9AwSwgAAOuYDiwlJSU6evSo1qxZI5/Pp7y8PFVUVIQH1jY0NMhu7+24mTt3rrZs2aLVq1dr1apVmjZtmnbs2KHp06cP3lXEgYMeFgAALGMzjJE/TzcQCMjj8cjv9w/ZeJaybfv1XN1hrfqrbH33y1cNyWcAAHA5MfP32/JZQiNF71dCFjcEAIDLEIElRk4H67AAAGAVAkuMGMMCAIB1CCwxcrIOCwAAliGwxIgeFgAArENgiRHrsAAAYB0CS4wcPEsIAADLEFhi5ORpzQAAWIbAEqPwV0Ijf509AABGHAJLjJyMYQEAwDIElhg5uqc1M4YFAID4I7DEiB4WAACsQ2CJEeuwAABgHQJLjFiHBQAA6xBYYtTbw8K0ZgAA4o3AEiPGsAAAYB0CS4z4SggAAOsQWGLkdDDoFgAAqxBYYtSzDgs9LAAAxB+BJUZOpjUDAGAZAkuMGMMCAIB1CCwxctjoYQEAwCoElhg5HD09LKzDAgBAvBFYYhQew8LDDwEAiDsCS4x6xrCEDAILAADxRmCJkbN7WjNjWAAAiD8CS4yYJQQAgHUILDFiDAsAANYhsMSIHhYAAKxDYImRg5VuAQCwDIElRk4767AAAGAVAkuM6GEBAMA6BJYYOXlaMwAAliGwxKh3aX4CCwAA8UZgiZGTWUIAAFiGwBKjvmNYDJbnBwAgrggsMerpYZEkOlkAAIgvAkuM7H0Cy1mmNgMAEFcDCiwbN25UVlaW3G638vPzVV1dfcH67du3Kzs7W263Wzk5Odq1a1fE+w899JCys7M1atQojRs3ToWFhdq7d+9AmjZk+vawMI4FAID4Mh1Ytm3bprKyMq1du1a1tbXKzc1VUVGRmpubo9bv2bNHpaWlWrJkierq6lRcXKzi4mLV19eHa6655hpt2LBBb731ll577TVlZWXpq1/9qo4ePTrwKxtkjogeFgILAADxZDNMjiDNz8/XrFmztGHDBklSKBRSZmamli5dqhUrVpxTX1JSora2Nu3cuTO8b86cOcrLy9OmTZuifkYgEJDH49Ef//hH3XLLLf22qafe7/crJSXFzOXELBgydNWqrp6hugf/UuNGJQ7J5wAAcLkw8/fbVA9LR0eHampqVFhY2HsCu12FhYWqqqqKekxVVVVEvSQVFRWdt76jo0ObN2+Wx+NRbm5u1Jr29nYFAoGIbaj16WBRkFlCAADElanA0tLSomAwqPT09Ij96enp8vl8UY/x+Xwx1e/cuVOjR4+W2+3Wv/zLv2j37t1KS0uLes7y8nJ5PJ7wlpmZaeYyBsRms7EWCwAAFhk2s4S+8pWvaP/+/dqzZ4/mz5+vb3/72+cdF7Ny5Ur5/f7w1tjYGJc28jwhAACsYSqwpKWlyeFwqKmpKWJ/U1OTvF5v1GO8Xm9M9aNGjdLVV1+tOXPm6IknnpDT6dQTTzwR9Zwul0spKSkRWzyEe1iCBBYAAOLJVGBJTEzUjBkzVFlZGd4XCoVUWVmpgoKCqMcUFBRE1EvS7t27z1vf97zt7e1mmjfkentYWIcFAIB4cpo9oKysTIsWLdLMmTM1e/ZsrV+/Xm1tbVq8eLEkaeHChZo0aZLKy8slScuWLdO8efO0bt06LViwQFu3btW+ffu0efNmSVJbW5seeeQR3XrrrZo4caJaWlq0ceNGHT58WN/61rcG8VIvnoMxLAAAWMJ0YCkpKdHRo0e1Zs0a+Xw+5eXlqaKiIjywtqGhQXZ7b8fN3LlztWXLFq1evVqrVq3StGnTtGPHDk2fPl2S5HA49O677+rpp59WS0uLUlNTNWvWLL366qu64YYbBukyB4ej+7oYwwIAQHyZXodlOIrHOiySNOcnlfIFzmjn0ps1fZJnyD4HAIDLwZCtw3K54yshAACsQWAxwelgWjMAAFYgsJhADwsAANYgsJjgZFozAACWILCY0DNLiB4WAADii8BigqP7bjGGBQCA+CKwmBDuYWFpfgAA4orAYoKThx8CAGAJAosJPbOEQiN/rT0AAEYUAosJ9LAAAGANAosJveuwMK0ZAIB4IrCYEO5hYdAtAABxRWAxgXVYAACwBoHFBNZhAQDAGgQWE5z0sAAAYAkCiwkOZgkBAGAJAosJTmYJAQBgCQKLCb3Tmi1uCAAAlxkCiwlOBz0sAABYgcBiAmNYAACwBoHFBGYJAQBgDQKLCXYbPSwAAFiBwGJC7xgWAgsAAPFEYDHBwbOEAACwBIHFBNZhAQDAGgQWE8LrsBj0sAAAEE8EFhN6e1gILAAAxBOBxQRH97RmxrAAABBfBBYT6GEBAMAaBBYT7Kx0CwCAJQgsJtDDAgCANQgsJvQ+S4hpzQAAxBOBxQR6WAAAsAaBxQQHgQUAAEsQWEzoeZYQg24BAIgvAosJPeuw0MMCAEB8EVhMcDKtGQAASxBYTLDbGMMCAIAVCCwm0MMCAIA1BhRYNm7cqKysLLndbuXn56u6uvqC9du3b1d2drbcbrdycnK0a9eu8HudnZ360Y9+pJycHI0aNUoZGRlauHChPv3004E0bUg5HD09LKzDAgBAPJkOLNu2bVNZWZnWrl2r2tpa5ebmqqioSM3NzVHr9+zZo9LSUi1ZskR1dXUqLi5WcXGx6uvrJUmnTp1SbW2tHnzwQdXW1uq5557TwYMHdeutt17clQ2BcA8LDz8EACCubIZhmPrrm5+fr1mzZmnDhg2SpFAopMzMTC1dulQrVqw4p76kpERtbW3auXNneN+cOXOUl5enTZs2Rf2MN954Q7Nnz9ahQ4c0ZcqUftsUCATk8Xjk9/uVkpJi5nJM2fPnFv1fj+/VNemj9YfvzxuyzwEA4HJg5u+3qR6Wjo4O1dTUqLCwsPcEdrsKCwtVVVUV9ZiqqqqIekkqKio6b70k+f1+2Ww2jR07Nur77e3tCgQCEVs8OLunNTOGBQCA+DIVWFpaWhQMBpWenh6xPz09XT6fL+oxPp/PVP2ZM2f0ox/9SKWlpedNW+Xl5fJ4POEtMzPTzGUMGCvdAgBgjWE1S6izs1Pf/va3ZRiGfvWrX523buXKlfL7/eGtsbExLu1jDAsAANZwmilOS0uTw+FQU1NTxP6mpiZ5vd6ox3i93pjqe8LKoUOH9OKLL17wuyyXyyWXy2Wm6YOCHhYAAKxhqoclMTFRM2bMUGVlZXhfKBRSZWWlCgoKoh5TUFAQUS9Ju3fvjqjvCSvvv/++/vjHPyo1NdVMs+LGwTosAABYwlQPiySVlZVp0aJFmjlzpmbPnq3169erra1NixcvliQtXLhQkyZNUnl5uSRp2bJlmjdvntatW6cFCxZo69at2rdvnzZv3iypK6z89V//tWpra7Vz504Fg8Hw+Jbx48crMTFxsK71ojntrMMCAIAVTAeWkpISHT16VGvWrJHP51NeXp4qKirCA2sbGhpkt/d23MydO1dbtmzR6tWrtWrVKk2bNk07duzQ9OnTJUmHDx/WCy+8IEnKy8uL+KyXXnpJf/EXfzHASxt89LAAAGAN0+uwDEfxWoel4dgpfflnLyk50aG3//f8IfscAAAuB0O2Dsvlrndp/hGf8QAAGFEILCY4mSUEAIAlCCwm9B3Dcgl8kwYAwIhBYDGhp4dFkuhkAQAgfggsJtj7BJazTG0GACBuCCwm9O1hYRwLAADxQ2AxwRHRw0JgAQAgXggsJjj7LIgX5AGIAADEDYHFhD4dLAoySwgAgLghsJhgs9lYiwUAAAsQWEzieUIAAMQfgcWkcA8LY1gAAIgbAotJ9nAPC+uwAAAQLwQWkxjDAgBA/BFYTHJ0T21mDAsAAPFDYDGJHhYAAOKPwGKSg8ACAEDcEVhMcjqY1gwAQLwRWEyihwUAgPgjsJjkZFozAABxR2AxyW6jhwUAgHgjsJjEGBYAAOKPwGJSzzosLM0PAED8EFhMcvLwQwAA4o7AYlLPLKGQQWABACBeCCwm0cMCAED8EVhM6l2HhWnNAADEC4HFpHAPC4NuAQCIGwKLSax0CwBA/BFYTHIwhgUAgLgjsJjk7FmHhcACAEDcEFhMoocFAID4I7CY1DPoNkRgAQAgbggsJtHDAgBA/BFYTOp5+CHrsAAAED8EFpPoYQEAIP4ILCY5bKzDAgBAvBFYTHJ0T2umhwUAgPgZUGDZuHGjsrKy5Ha7lZ+fr+rq6gvWb9++XdnZ2XK73crJydGuXbsi3n/uuef01a9+VampqbLZbNq/f/9AmhUXvWNYCCwAAMSL6cCybds2lZWVae3ataqtrVVubq6KiorU3NwctX7Pnj0qLS3VkiVLVFdXp+LiYhUXF6u+vj5c09bWpptvvlk//elPB34lceLgWUIAAMSdzTAMU3958/PzNWvWLG3YsEGSFAqFlJmZqaVLl2rFihXn1JeUlKitrU07d+4M75szZ47y8vK0adOmiNqPP/5YU6dOVV1dnfLy8mJuUyAQkMfjkd/vV0pKipnLMW3dHw7qly9+oEUFV+gfbps+pJ8FAMClzMzfb1M9LB0dHaqpqVFhYWHvCex2FRYWqqqqKuoxVVVVEfWSVFRUdN764S788ENzOQ8AAFwEp5nilpYWBYNBpaenR+xPT0/Xu+++G/UYn88Xtd7n85lsaq/29na1t7eHXwcCgQGfy6yelW47zrIOCwAA8TIiZwmVl5fL4/GEt8zMzLh99uRxyZKknQeO6M9HT8btcwEAuJyZCixpaWlyOBxqamqK2N/U1CSv1xv1GK/Xa6o+FitXrpTf7w9vjY2NAz6XWV/PzVDBlak61RHUvc/U6kxnMG6fDQDA5cpUYElMTNSMGTNUWVkZ3hcKhVRZWamCgoKoxxQUFETUS9Lu3bvPWx8Ll8ullJSUiC1eHHab1t+Rp9RRiXrX16pHfvdO3D4bAIDLlemvhMrKyvT444/r6aef1jvvvKN77rlHbW1tWrx4sSRp4cKFWrlyZbh+2bJlqqio0Lp16/Tuu+/qoYce0r59+3TfffeFa44fP679+/fr7bffliQdPHhQ+/fvv6hxLkMpPcWtdd/OlST92+uH9N9vHbG4RQAAXNpMB5aSkhL98z//s9asWaO8vDzt379fFRUV4YG1DQ0NOnKk9w/43LlztWXLFm3evFm5ubn6z//8T+3YsUPTp/dOCX7hhRd04403asGCBZKkO+64QzfeeOM5056Hk7+4doL+73lXSpJ++JsDajx+yuIWAQBw6TK9DstwFM91WPrqDIb07f+nSnUNJ5SbOVbP3p2v5ERTE68AALhsDdk6LIiU4LDrl6U3KsXt1JuNJ1S6+XW1nGzv/0AAAGAKgeUiTR6XrKf+drbGJSfozU/8+uav9ujjljarmwUAwCWFwDIIbpoyTr+5Z64yxyfp0LFT+uav9ujNxhNWNwsAgEsGgWWQXPmF0frNPXM1fVKKjrV16I7Nr2vngU91CQwRAgDAcgSWQTRhjFtbv1ugL1/zBZ3uDOq+LXVa8vQ+ZhABAHCRCCyDbLTLqScWzdT9/+tqJThsevHdZv3lv7yi//PyBzx/CACAAWJa8xD6oPmkVu94S69/eFySdOUXRmnxl6bqtrwMpbgTLG4dAADWMvP3m8AyxAzD0PN1h/XI797RsbYOSVJSgkNfz52o0tlTlJc5VjabzeJWAgAQfwSWYch/ulP/WfOJnq1u0AfNvU95njwuSQVXpmru1akquDJNXo/bwlYCABA/BJZhzDAM7Tv0mZ6tbtDvDhxR++fGtWSlJuv6jBRdkz5G16aP0bXeMZoyPllOB8ONAACXFgLLCNHWflZvfHxcVX8+pqoPj6n+sF+hKP9pOOw2TfS4NXlckiaPS9aksUlKT3FrwhiXJqS4NGGMW6mjE5VAqAEAjCAElhHKf7pTbzae0EFfqw42teq97u1MZ2yzizxJCUodlajU0YkaP6prG5fc+3PcqISun8mJGjcqUSluJ+NnAACWIbBcQkIhQ82t7frks1P65LPT+uSzUzp84rSaA+1qbm1Xc+sZtZzsUDBa10w/HHZbd6DpCjI9QSd1lEtpoxOVOtql1FGJ+sIYl74wxqXRLgIOAGDwmPn7zaOFhzm73Savxy2vx62ZWdFrgiFD/tOdOnayXcfaOnTsZIeOt7XreFunPjvVoc9Odeh4W9fPz7r3neoIKhgy1HKyPeYHNiYlOLq/gnIpPcWtiR63vJ4keVPcyhjr1qRxSfrCaBehBgAw6AgslwCH3Rb+CmhajMec6QyGA8zxtg4dP9Wh4yfbdbytIxx6jrW1q+Vkh462tutk+1md7gzq0LFTOnTs/Cv3upx2TRqbpEnjknRFarKyUkfpitRRykpNVub4ZLkTHINz0QCAywpfCSEmpzrO6mhr19dQTYEz8vm7t8AZHfGf0acnTssXOKML/bfJbpMyxyfrqi+M1lVfGKWrvjBa13jH6Jr0MRrtIjsDwOWGMSywRMfZkHz+M/rkxCl9cvy0Dh1v08fHTunQsTYdajml1vaz5z02c3ySrk0fo2xvim7ISNENGR5ljk/i6yUAuIQRWDDsGIahlpMd+vPRk/qg+WT450Ffq5pbo4+hGeN26vqJKfriZI9yJo9V7mSPpoxPJsQAwCWCwIIR5bO2Dh1satVBX6veORJQ/ad+vec7qY7gudO5xyYnKGeSR3mZY8Nb6miXBa0GAFwsAgtGvI6zIX3QfFL1h/1667BfBz45oXeOtEYNMZPHJYXDy41TxuqGDA+DewFgBCCw4JLUcTakg75W7f/khPY3nNCbn5yIeC5TD6fdpuu6v0rKnTxWX8z0aNqEMXLY+SoJAIYTAgsuG4EznTrQ6Nf+xs+0v/GE9jeeUMvJjnPqkhIcuj4jRdO7B/T2PK8p0cnjDADAKgQWXLYMw9DhE6e1v/GEDnzi15uNJ1R/2K+2juA5tQkOm65M65pafW36aF2TPkZXTxitzPHJPJcJAOKAwAL0EQwZ+vDoSf3p04DqD/v1p08D+tOnfgXORJ9m7bTbNGV8sqamjdLUtFGakpqszHHJ4YdPJiUyPgYABgOBBehHT0/M+00nux406WvVu75Wfdhyst+HTaaNTuzzaAK3vCnu8POW0kZ3/Uwd5eLrJgDoB4EFGKBQyJAvcEYftbTpw5Y2fXS0TZ98dkqNn53WJ8cvvPjd5412OTVuVILGdz8d25OUIE9SglLc3T+TnBrtStBot1OjXU6NcTs1yuXUqESHkhOdBB4AlzwefggMkN1uU8bYJGWMTdKXrk6LeM8wuh4y+emJM/IFTuuI/4ya/F2PJjja/RDJo63tOnayQ2dDhk62n9XJ9rNqPH56QG1JcNiUlNAVXpITHXInOJSc6FBSokMup0PuBLvcCd0/nQ65+vx0OR1KdNrlctq7f3a9TnTYI/YnOHp+2uRyOOR02JTg6HrNAn0AhhMCCxAjm82mscmJGpucqOszzv//BELdT8/uelJ2pz7rfrhk4HSnAqc75T/dqcCZs/Kf7uwKNWe6gk3rmU61dQTVcbbrK6nOoKHO4NnzjrUZagkOm5z2rvDSFWLsEYGm5z2nwy6nvWu/w24Lv+dw2JRgt8nRXefoU+O028I/7eHX9s+97t5svb/bw68lu80mp8Mmu61rc9h7f/a837Ov9/euUGq3dZ3HFn6tcF3f3212Reyz9X1Pks0mgh0QJwQWYJDZ7TaNG9X1NdBAdAZDOtUR1KmOs2prD+p0R1CnO7ten+4I6szZoM50hnSms2v/mc6Q2s8G1R7xs2frCkDtZ0PqOBtSR7D7Z/fvnT37gqFzHlzZFZiCOt05CDflEtYTYmzqDTWfDzbqE3j61kldYahrf8/vXQHIbu/a13OMrc+5+r7uPVfvPlufc/a00db9i63v677nVZ9jwp/RvV99PyPyvDrPebqbeoH3o5zjnON73+z7+RHvRT3eFvV8fX2+9vPt7bsjWjvOe0yUNkb9/PN92AVrzq2KXmOLoebz5+k/eCc4bPrxguv7rRsqBBZgmElw2OVJssuTlBC3zzQMQ2dDhs4Gja4g07OdNdQZ6vq9572zQUNngyF1hrp/Bg2dDXXt7wyGus4TMhTs8/vZ7t+DPe+FumpDEa8NhYyu34N9aj+/L9jndcjoanPI6K0LGQq/F+p5bRgy+rwf6nn/c+8Z0gWfOB793nWdo/vVYP9HAwwbiU47gQWAtWw2W/dXP1KSLu9p24ZhyDDUFYC6fz/3dVfYMbr3yVDXa3UHn+7c0hOKQkbPvsjXRvcx5/yuyGOMnvMbvaHK6A5H0Y7tqesq+PxnRL7f9zP67os4f597o/PVGOGP672PfdrQ/Sl9PjMy3p3vM/smyM/Hwb7hsqdtxufei/yM8wdK4zxtjKjp55jzHXfuZxmfe93/Z0WrM6JUnVvT/4li+Sypq/fYSgQWAOjD1jNWRTb+gQSGEeZNAgCAYY/AAgAAhj0CCwAAGPYILAAAYNgjsAAAgGGPwAIAAIY9AgsAABj2BhRYNm7cqKysLLndbuXn56u6uvqC9du3b1d2drbcbrdycnK0a9euiPcNw9CaNWs0ceJEJSUlqbCwUO+///5AmgYAAC5BpgPLtm3bVFZWprVr16q2tla5ubkqKipSc3Nz1Po9e/aotLRUS5YsUV1dnYqLi1VcXKz6+vpwzT/90z/pF7/4hTZt2qS9e/dq1KhRKioq0pkzZwZ+ZQAA4JJhMy60VnEU+fn5mjVrljZs2CBJCoVCyszM1NKlS7VixYpz6ktKStTW1qadO3eG982ZM0d5eXnatGmTDMNQRkaGfvCDH+jv//7vJUl+v1/p6el66qmndMcdd/TbpkAgII/HI7/fr5SU8z9FFwAADB9m/n6b6mHp6OhQTU2NCgsLe09gt6uwsFBVVVVRj6mqqoqol6SioqJw/UcffSSfzxdR4/F4lJ+ff95ztre3KxAIRGwAAODSZSqwtLS0KBgMKj09PWJ/enq6fD5f1GN8Pt8F63t+mjlneXm5PB5PeMvMzDRzGQAAYIQZkbOEVq5cKb/fH94aGxutbhIAABhCph5GmpaWJofDoaampoj9TU1N8nq9UY/xer0XrO/52dTUpIkTJ0bU5OXlRT2ny+WSy+UKv+4ZhsNXQwAAjBw9f7djGU5rKrAkJiZqxowZqqysVHFxsaSuQbeVlZW67777oh5TUFCgyspKPfDAA+F9u3fvVkFBgSRp6tSp8nq9qqysDAeUQCCgvXv36p577ompXa2trZLEV0MAAIxAra2t8ng8F6wxFVgkqaysTIsWLdLMmTM1e/ZsrV+/Xm1tbVq8eLEkaeHChZo0aZLKy8slScuWLdO8efO0bt06LViwQFu3btW+ffu0efNmSZLNZtMDDzygf/zHf9S0adM0depUPfjgg8rIyAiHov5kZGSosbFRY8aMkc1mM3tJFxQIBJSZmanGxkZmIA0x7nX8cK/jh3sdP9zr+Bmse20YhlpbW5WRkdFvrenAUlJSoqNHj2rNmjXy+XzKy8tTRUVFeNBsQ0OD7PbeoTFz587Vli1btHr1aq1atUrTpk3Tjh07NH369HDND3/4Q7W1tem73/2uTpw4oZtvvlkVFRVyu90xtclut2vy5MlmL8WUlJQU/gcQJ9zr+OFexw/3On641/EzGPe6v56VHqbXYbncsMZL/HCv44d7HT/c6/jhXsePFfd6RM4SAgAAlxcCSz9cLpfWrl0bMSsJQ4N7HT/c6/jhXscP9zp+rLjXfCUEAACGPXpYAADAsEdgAQAAwx6BBQAADHsEFgAAMOwRWPqxceNGZWVlye12Kz8/X9XV1VY3aUQrLy/XrFmzNGbMGE2YMEHFxcU6ePBgRM2ZM2d07733KjU1VaNHj9Y3v/nNc55HBfMeffTR8MrSPbjXg+fw4cP6m7/5G6WmpiopKUk5OTnat29f+H3DMLRmzRpNnDhRSUlJKiws1Pvvv29hi0euYDCoBx98UFOnTlVSUpKuuuoqPfzwwxHPo+F+D8z//M//6Otf/7oyMjJks9m0Y8eOiPdjua/Hjx/XnXfeqZSUFI0dO1ZLlizRyZMnL75xBs5r69atRmJiovHkk08af/rTn4y7777bGDt2rNHU1GR100asoqIi49e//rVRX19v7N+/3/irv/orY8qUKcbJkyfDNd/73veMzMxMo7Ky0ti3b58xZ84cY+7cuRa2euSrrq42srKyjC9+8YvGsmXLwvu514Pj+PHjxhVXXGF85zvfMfbu3Wt8+OGHxu9//3vjgw8+CNc8+uijhsfjMXbs2GG8+eabxq233mpMnTrVOH36tIUtH5keeeQRIzU11di5c6fx0UcfGdu3bzdGjx5tPPbYY+Ea7vfA7Nq1y/jxj39sPPfcc4Yk4/nnn494P5b7On/+fCM3N9d4/fXXjVdffdW4+uqrjdLS0otuG4HlAmbPnm3ce++94dfBYNDIyMgwysvLLWzVpaW5udmQZLzyyiuGYRjGiRMnjISEBGP79u3hmnfeeceQZFRVVVnVzBGttbXVmDZtmrF7925j3rx54cDCvR48P/rRj4ybb775vO+HQiHD6/UaP/vZz8L7Tpw4YbhcLuPZZ5+NRxMvKQsWLDD+9m//NmLf7bffbtx5552GYXC/B8vnA0ss9/Xtt982JBlvvPFGuOa///u/DZvNZhw+fPii2sNXQufR0dGhmpoaFRYWhvfZ7XYVFhaqqqrKwpZdWvx+vyRp/PjxkqSamhp1dnZG3Pfs7GxNmTKF+z5A9957rxYsWBBxTyXu9WB64YUXNHPmTH3rW9/ShAkTdOONN+rxxx8Pv//RRx/J5/NF3GuPx6P8/Hzu9QDMnTtXlZWVeu+99yRJb775pl577TV97Wtfk8T9Hiqx3NeqqiqNHTtWM2fODNcUFhbKbrdr7969F/X5ph9+eLloaWlRMBgMP9SxR3p6ut59912LWnVpCYVCeuCBB/SlL30p/DBMn8+nxMREjR07NqI2PT1dPp/PglaObFu3blVtba3eeOONc97jXg+eDz/8UL/61a9UVlamVatW6Y033tD999+vxMRELVq0KHw/o/17wr02b8WKFQoEAsrOzpbD4VAwGNQjjzyiO++8U5K430Mklvvq8/k0YcKEiPedTqfGjx9/0feewALL3Hvvvaqvr9drr71mdVMuSY2NjVq2bJl2794d85PPMTChUEgzZ87UT37yE0nSjTfeqPr6em3atEmLFi2yuHWXnv/4j//QM888oy1btuiGG27Q/v379cADDygjI4P7fQnjK6HzSEtLk8PhOGfGRFNTk7xer0WtunTcd9992rlzp1566SVNnjw5vN/r9aqjo0MnTpyIqOe+m1dTU6Pm5mbddNNNcjqdcjqdeuWVV/SLX/xCTqdT6enp3OtBMnHiRF1//fUR+6677jo1NDRIUvh+8u/J4Fi+fLlWrFihO+64Qzk5Obrrrrv0/e9/X+Xl5ZK430Mllvvq9XrV3Nwc8f7Zs2d1/Pjxi773BJbzSExM1IwZM1RZWRneFwqFVFlZqYKCAgtbNrIZhqH77rtPzz//vF588UVNnTo14v0ZM2YoISEh4r4fPHhQDQ0N3HeTbrnlFr311lvav39/eJs5c6buvPPO8O/c68HxpS996Zzp+e+9956uuOIKSdLUqVPl9Xoj7nUgENDevXu51wNw6tQp2e2Rf74cDodCoZAk7vdQieW+FhQU6MSJE6qpqQnXvPjiiwqFQsrPz7+4BlzUkN1L3NatWw2Xy2U89dRTxttvv21897vfNcaOHWv4fD6rmzZi3XPPPYbH4zFefvll48iRI+Ht1KlT4Zrvfe97xpQpU4wXX3zR2Ldvn1FQUGAUFBRY2OpLR99ZQobBvR4s1dXVhtPpNB555BHj/fffN5555hkjOTnZ+Pd///dwzaOPPmqMHTvW+K//+i/jwIEDxm233cY02wFatGiRMWnSpPC05ueee85IS0szfvjDH4ZruN8D09raatTV1Rl1dXWGJOPnP/+5UVdXZxw6dMgwjNju6/z5840bb7zR2Lt3r/Haa68Z06ZNY1pzPPzyl780pkyZYiQmJhqzZ882Xn/9daubNKJJirr9+te/DtecPn3a+Lu/+ztj3LhxRnJysvGNb3zDOHLkiHWNvoR8PrBwrwfPb3/7W2P69OmGy+UysrOzjc2bN0e8HwqFjAcffNBIT083XC6XccsttxgHDx60qLUjWyAQMJYtW2ZMmTLFcLvdxpVXXmn8+Mc/Ntrb28M13O+Beemll6L+G71o0SLDMGK7r8eOHTNKS0uN0aNHGykpKcbixYuN1tbWi26bzTD6LA0IAAAwDDGGBQAADHsEFgAAMOwRWAAAwLBHYAEAAMMegQUAAAx7BBYAADDsEVgAAMCwR2ABAADDHoEFAAAMewQWAAAw7BFYAADAsEdgAQAAw97/DwDjiHREofz8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75737209e+06 -3.64096883e+05 -2.94700000e+00  8.55000000e+00\n",
      "  7.75740486e+06 -3.64088830e+05 -2.85800000e+00  8.51000000e+00\n",
      " -7.00000000e-03] -> [ 8.51064205e+00 -6.24996610e-03  1.66576598e-02  8.46653461e+00\n",
      " -6.77172840e-03  1.64704807e-02  8.46408272e+00 -7.91417062e-03\n",
      "  1.96595825e-02  8.46856403e+00 -9.65752080e-03  1.91923007e-02\n",
      "  8.46929550e+00 -6.72112405e-03  1.66018307e-02  8.47451496e+00\n",
      " -1.05522797e-02  1.68123990e-02  8.46906853e+00 -9.25011933e-03\n",
      "  1.94494203e-02  8.47102928e+00 -5.48800826e-03  2.13579610e-02\n",
      "  8.46728516e+00  6.58910722e-04  2.29613706e-02  8.47488689e+00\n",
      " -4.94590402e-03  1.97285637e-02  8.47006893e+00 -6.85170293e-03\n",
      "  2.24484354e-02  8.47311497e+00 -7.00437278e-03  1.51324719e-02\n",
      "  8.47889900e+00 -7.26510584e-03  2.14610267e-02  8.47375011e+00\n",
      " -1.54057145e-03  2.56196558e-02  8.47890186e+00 -7.56984949e-03\n",
      "  2.17268616e-02  8.47527218e+00 -2.68369913e-03  2.06096247e-02\n",
      "  8.47642803e+00 -6.05563447e-03  2.17407569e-02  8.48370075e+00\n",
      " -1.53028220e-03  2.39050165e-02  8.48651409e+00 -8.84612650e-03\n",
      "  1.47756990e-02  8.48278522e+00 -2.26233155e-03  1.90600678e-02\n",
      "  8.48384285e+00 -5.08555770e-03  2.40585171e-02  8.48547077e+00\n",
      " -2.06360593e-03  2.45039985e-02  8.48743916e+00 -1.27735585e-02\n",
      "  1.72526985e-02  8.49814034e+00 -8.55714455e-03  1.70293897e-02\n",
      "  8.48408604e+00 -5.92418760e-03  2.13977434e-02  8.49697495e+00\n",
      " -7.51760602e-03  2.00568140e-02  8.49987507e+00 -4.82054055e-03\n",
      "  1.56404786e-02  8.50115490e+00 -7.27607310e-03  1.95999090e-02\n",
      "  8.49340153e+00 -7.15493411e-03  1.69284027e-02  8.50049496e+00\n",
      " -4.90884483e-03  1.92106217e-02  8.49554253e+00 -4.68432158e-03\n",
      "  2.11677495e-02  8.49920273e+00 -7.41367042e-03  1.98958069e-02\n",
      "  8.49795723e+00 -5.11973351e-03  1.65905375e-02  8.50198936e+00\n",
      " -3.35395429e-03  1.89527646e-02  8.50494671e+00 -5.56804985e-03\n",
      "  1.58755556e-02  8.50930786e+00 -4.85448539e-03  2.39221156e-02\n",
      "  8.50923729e+00 -6.99400343e-03  2.65022069e-02  8.50384045e+00\n",
      " -1.13087520e-03  1.96099468e-02  8.51101017e+00 -2.92689353e-03\n",
      "  1.99381858e-02  8.50225449e+00 -4.02204692e-03  2.22624540e-02\n",
      "  8.52042484e+00 -2.60625780e-03  2.46382356e-02  8.51096153e+00\n",
      " -1.73310935e-03  2.00259425e-02  8.50489140e+00 -4.63607162e-03\n",
      "  2.32414529e-02  8.51058674e+00 -5.55817783e-03  2.14458294e-02\n",
      "  8.51084042e+00 -7.75552541e-03  2.05305219e-02  8.51299095e+00\n",
      "  6.16803765e-04  1.94552392e-02  8.52142906e+00  1.02928281e-03\n",
      "  1.71073563e-02  8.51918793e+00 -2.82283500e-03  1.77059993e-02\n",
      "  8.52187157e+00 -5.19266725e-03  2.49820612e-02  8.51989746e+00\n",
      "  2.57487968e-03  1.65734962e-02] (expected [ 8.510e+00 -7.000e-03  2.000e-02  8.511e+00 -7.000e-03  2.000e-02\n",
      "  8.511e+00 -7.000e-03  2.000e-02  8.511e+00 -7.000e-03  2.000e-02\n",
      "  8.511e+00 -7.000e-03  2.000e-02  8.511e+00 -7.000e-03  2.000e-02\n",
      "  8.512e+00 -7.000e-03  2.000e-02  8.512e+00 -7.000e-03  2.000e-02\n",
      "  8.512e+00 -7.000e-03  2.000e-02  8.512e+00 -7.000e-03  2.000e-02\n",
      "  8.512e+00 -7.000e-03  2.000e-02  8.513e+00 -7.000e-03  2.000e-02\n",
      "  8.513e+00 -7.000e-03  2.000e-02  8.513e+00 -7.000e-03  2.000e-02\n",
      "  8.513e+00 -7.000e-03  2.000e-02  8.513e+00 -7.000e-03  2.000e-02\n",
      "  8.514e+00 -7.000e-03  2.000e-02  8.514e+00 -7.000e-03  2.000e-02\n",
      "  8.514e+00 -7.000e-03  2.000e-02  8.514e+00 -7.000e-03  2.000e-02\n",
      "  8.514e+00 -7.000e-03  2.000e-02  8.515e+00 -7.000e-03  2.000e-02\n",
      "  8.515e+00 -7.000e-03  2.000e-02  8.515e+00 -7.000e-03  2.000e-02\n",
      "  8.515e+00 -7.000e-03  2.000e-02  8.515e+00 -7.000e-03  2.000e-02\n",
      "  8.516e+00 -7.000e-03  2.000e-02  8.516e+00 -7.000e-03  2.000e-02\n",
      "  8.516e+00 -7.000e-03  2.000e-02  8.516e+00 -7.000e-03  2.000e-02\n",
      "  8.516e+00 -7.000e-03  2.000e-02  8.517e+00 -7.000e-03  2.000e-02\n",
      "  8.517e+00 -7.000e-03  2.000e-02  8.517e+00 -7.000e-03  2.000e-02\n",
      "  8.517e+00 -7.000e-03  2.000e-02  8.517e+00 -7.000e-03  2.000e-02\n",
      "  8.518e+00 -7.000e-03  2.000e-02  8.518e+00 -7.000e-03  2.000e-02\n",
      "  8.518e+00 -7.000e-03  2.000e-02  8.518e+00 -7.000e-03  2.000e-02\n",
      "  8.518e+00 -7.000e-03  2.000e-02  8.519e+00 -7.000e-03  2.000e-02\n",
      "  8.519e+00 -7.000e-03  2.000e-02  8.519e+00 -7.000e-03  2.000e-02\n",
      "  8.519e+00 -7.000e-03  2.000e-02  8.519e+00 -7.000e-03  2.000e-02\n",
      "  8.520e+00 -7.000e-03  2.000e-02  8.520e+00 -7.000e-03  2.000e-02\n",
      "  8.520e+00 -7.000e-03  2.000e-02  8.520e+00 -7.000e-03  2.000e-02])\n",
      "[ 7.75744547e+06 -3.63583437e+05  2.22400000e+00  8.55000000e+00\n",
      "  7.75746570e+06 -3.63610614e+05  2.15800000e+00  8.60700000e+00\n",
      "  1.40000000e-02] -> [8.597873   0.01195377 0.01848722 8.551796   0.01221688 0.01823978\n",
      " 8.552573   0.01257159 0.0197059  8.555421   0.01032315 0.01945563\n",
      " 8.554475   0.0134901  0.01842061 8.55631    0.01019729 0.01871081\n",
      " 8.557578   0.01131399 0.01971347 8.558604   0.01269892 0.02009983\n",
      " 8.560137   0.01640264 0.02124916 8.56046    0.01328906 0.0204142\n",
      " 8.561741   0.01219544 0.02086176 8.562192   0.01170651 0.01850955\n",
      " 8.561523   0.0121132  0.02073683 8.563989   0.01503977 0.02249661\n",
      " 8.566863   0.01169926 0.02023114 8.5663185  0.01453656 0.02006216\n",
      " 8.566624   0.01236977 0.02101739 8.568942   0.0151595  0.02174316\n",
      " 8.571163   0.01128451 0.01772804 8.570666   0.01473596 0.01949101\n",
      " 8.57456    0.01290515 0.02174896 8.573783   0.0144836  0.02180737\n",
      " 8.575364   0.00994368 0.01835634 8.57868    0.0112583  0.01889084\n",
      " 8.573791   0.01262776 0.0203633  8.578205   0.01237401 0.01937363\n",
      " 8.579145   0.01414184 0.01856933 8.58001    0.01247834 0.02013355\n",
      " 8.580699   0.01191128 0.01821849 8.584381   0.01353116 0.01922373\n",
      " 8.581607   0.01344205 0.02100491 8.58745    0.01269706 0.02030171\n",
      " 8.586835   0.01315058 0.01863885 8.58526    0.01325667 0.01903216\n",
      " 8.589165   0.01269875 0.01814828 8.588288   0.01380606 0.02167681\n",
      " 8.59232    0.01142717 0.02309091 8.590164   0.01452667 0.02036412\n",
      " 8.592553   0.01391237 0.0197999  8.593913   0.0138972  0.02064401\n",
      " 8.5976095  0.013559   0.02163953 8.592729   0.01422139 0.01991093\n",
      " 8.59427    0.01274995 0.02168339 8.596998   0.01213475 0.02036901\n",
      " 8.599984   0.01131129 0.01998639 8.599403   0.01469614 0.01920454\n",
      " 8.601176   0.01435354 0.01869308 8.6002     0.01270251 0.01881894\n",
      " 8.598672   0.01284215 0.02286371 8.604736   0.01530214 0.01866152] (expected [8.607 0.014 0.02  8.55  0.014 0.02  8.55  0.014 0.02  8.55  0.014 0.02\n",
      " 8.55  0.014 0.02  8.55  0.014 0.02  8.55  0.014 0.02  8.55  0.014 0.02\n",
      " 8.55  0.014 0.02  8.55  0.014 0.02  8.55  0.014 0.02  8.55  0.014 0.02\n",
      " 8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02\n",
      " 8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02\n",
      " 8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02\n",
      " 8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02  8.55  0.013 0.02\n",
      " 8.55  0.013 0.02  8.55  0.012 0.02  8.55  0.012 0.02  8.55  0.012 0.02\n",
      " 8.55  0.012 0.02  8.55  0.012 0.02  8.55  0.012 0.02  8.55  0.012 0.02\n",
      " 8.55  0.012 0.02  8.55  0.012 0.02  8.55  0.012 0.02  8.55  0.012 0.02\n",
      " 8.55  0.012 0.02  8.55  0.012 0.02  8.55  0.011 0.02  8.55  0.011 0.02\n",
      " 8.55  0.011 0.02  8.55  0.011 0.02  8.55  0.011 0.02  8.55  0.011 0.02\n",
      " 8.55  0.011 0.02  8.55  0.011 0.02 ])\n",
      "[ 7.75751686e+06 -3.64032125e+05  6.25000000e-01  8.54700000e+00\n",
      "  7.75749009e+06 -3.64052084e+05  6.14000000e-01  8.44000000e+00\n",
      "  8.00000000e-03] -> [8.4633274e+00 5.1183086e-03 1.9410321e-02 8.4191055e+00 5.3760558e-03\n",
      " 1.9260574e-02 8.4199820e+00 5.9235245e-03 1.9904200e-02 8.4224424e+00\n",
      " 4.7198348e-03 1.9954644e-02 8.4236870e+00 6.5585524e-03 1.9329816e-02\n",
      " 8.4258184e+00 4.3617561e-03 1.9196227e-02 8.4266634e+00 4.7394186e-03\n",
      " 1.9977160e-02 8.4281120e+00 5.2452385e-03 1.9849546e-02 8.4296379e+00\n",
      " 7.7652149e-03 2.0682350e-02 8.4321480e+00 5.5812299e-03 2.0191930e-02\n",
      " 8.4330034e+00 4.8105419e-03 2.0464674e-02 8.4345274e+00 4.7291890e-03\n",
      " 1.9693539e-02 8.4368057e+00 4.8216432e-03 2.0042853e-02 8.4378395e+00\n",
      " 6.9490373e-03 2.1159559e-02 8.4395313e+00 5.3220391e-03 1.9919232e-02\n",
      " 8.4409447e+00 6.7188144e-03 1.9806035e-02 8.4421186e+00 5.9320517e-03\n",
      " 2.0270668e-02 8.4442425e+00 7.1002319e-03 2.0899035e-02 8.4461546e+00\n",
      " 5.2744523e-03 1.9194787e-02 8.4473963e+00 6.9887862e-03 1.9854598e-02\n",
      " 8.4485350e+00 6.1607063e-03 2.0635065e-02 8.4511166e+00 7.0233606e-03\n",
      " 2.0528369e-02 8.4527044e+00 5.3565055e-03 1.9459382e-02 8.4562511e+00\n",
      " 5.6080185e-03 1.9313261e-02 8.4550018e+00 6.0432926e-03 1.9850109e-02\n",
      " 8.4586744e+00 5.9629381e-03 1.9587904e-02 8.4605322e+00 6.6497773e-03\n",
      " 1.9707900e-02 8.4616165e+00 6.1616749e-03 2.0490820e-02 8.4623957e+00\n",
      " 5.9974268e-03 1.9108025e-02 8.4649754e+00 6.5701753e-03 1.9944951e-02\n",
      " 8.4645061e+00 6.7045763e-03 2.0663852e-02 8.4674673e+00 6.4516813e-03\n",
      " 1.9769207e-02 8.4687243e+00 6.4399317e-03 1.9488933e-02 8.4700871e+00\n",
      " 6.4159622e-03 1.9787945e-02 8.4731445e+00 6.3522831e-03 1.9523598e-02\n",
      " 8.4746532e+00 6.8943053e-03 2.0287067e-02 8.4763155e+00 5.8493670e-03\n",
      " 2.1193817e-02 8.4766397e+00 6.9921650e-03 2.0286102e-02 8.4795160e+00\n",
      " 6.8384930e-03 1.9820884e-02 8.4796753e+00 6.8813115e-03 2.0542979e-02\n",
      " 8.4836054e+00 6.5491349e-03 2.0458996e-02 8.4836998e+00 6.9653541e-03\n",
      " 1.9889612e-02 8.4840651e+00 6.4261928e-03 2.0912819e-02 8.4863129e+00\n",
      " 6.1887056e-03 2.0001311e-02 8.4878778e+00 5.9375688e-03 1.9710183e-02\n",
      " 8.4903259e+00 7.0434958e-03 1.9904181e-02 8.4927359e+00 6.6163838e-03\n",
      " 1.9146670e-02 8.4929104e+00 6.3220672e-03 1.9488893e-02 8.4949160e+00\n",
      " 6.5793693e-03 2.1305408e-02 8.4965706e+00 6.8029948e-03 1.9390129e-02] (expected [8.440e+00 8.000e-03 2.000e-02 8.440e+00 8.000e-03 2.000e-02 8.441e+00\n",
      " 8.000e-03 2.000e-02 8.442e+00 8.000e-03 2.000e-02 8.442e+00 8.000e-03\n",
      " 2.000e-02 8.443e+00 8.000e-03 2.000e-02 8.443e+00 8.000e-03 2.000e-02\n",
      " 8.444e+00 8.000e-03 2.000e-02 8.444e+00 7.000e-03 2.000e-02 8.445e+00\n",
      " 7.000e-03 2.000e-02 8.445e+00 7.000e-03 2.000e-02 8.446e+00 7.000e-03\n",
      " 2.000e-02 8.446e+00 7.000e-03 2.000e-02 8.447e+00 7.000e-03 2.000e-02\n",
      " 8.447e+00 7.000e-03 2.000e-02 8.448e+00 7.000e-03 2.000e-02 8.448e+00\n",
      " 6.000e-03 2.000e-02 8.449e+00 6.000e-03 2.000e-02 8.450e+00 6.000e-03\n",
      " 2.000e-02 8.450e+00 6.000e-03 2.000e-02 8.451e+00 6.000e-03 2.000e-02\n",
      " 8.451e+00 6.000e-03 2.000e-02 8.452e+00 6.000e-03 2.000e-02 8.452e+00\n",
      " 6.000e-03 2.000e-02 8.453e+00 6.000e-03 2.000e-02 8.453e+00 5.000e-03\n",
      " 2.000e-02 8.454e+00 5.000e-03 2.000e-02 8.454e+00 5.000e-03 2.000e-02\n",
      " 8.455e+00 5.000e-03 2.000e-02 8.455e+00 5.000e-03 2.000e-02 8.456e+00\n",
      " 5.000e-03 2.000e-02 8.456e+00 5.000e-03 2.000e-02 8.457e+00 5.000e-03\n",
      " 2.000e-02 8.458e+00 5.000e-03 2.000e-02 8.458e+00 5.000e-03 2.000e-02\n",
      " 8.459e+00 4.000e-03 2.000e-02 8.459e+00 4.000e-03 2.000e-02 8.460e+00\n",
      " 4.000e-03 2.000e-02 8.460e+00 4.000e-03 2.000e-02 8.461e+00 4.000e-03\n",
      " 2.000e-02 8.461e+00 4.000e-03 2.000e-02 8.462e+00 4.000e-03 2.000e-02\n",
      " 8.462e+00 4.000e-03 2.000e-02 8.463e+00 4.000e-03 2.000e-02 8.463e+00\n",
      " 4.000e-03 2.000e-02 8.464e+00 4.000e-03 2.000e-02 8.465e+00 4.000e-03\n",
      " 2.000e-02 8.465e+00 4.000e-03 2.000e-02 8.466e+00 4.000e-03 2.000e-02\n",
      " 8.466e+00 4.000e-03 2.000e-02])\n",
      "[ 7.75656206e+06 -3.63746146e+05 -2.48500000e+00  8.55000000e+00\n",
      "  7.75658946e+06 -3.63724933e+05 -2.47800000e+00  8.69300000e+00\n",
      " -2.00000000e-03] -> [ 8.6250925e+00 -4.1075367e-03  1.8689284e-02  8.5779486e+00\n",
      " -4.0102452e-03  1.8851090e-02  8.5746469e+00 -3.3809990e-03\n",
      "  2.0002846e-02  8.5754890e+00 -4.3448396e-03  2.0021401e-02\n",
      "  8.5761652e+00 -2.8627962e-03  1.8753558e-02  8.5777025e+00\n",
      " -5.2626058e-03  1.8875614e-02  8.5726967e+00 -4.1341931e-03\n",
      "  1.9856639e-02  8.5727930e+00 -3.0264556e-03  1.9843824e-02\n",
      "  8.5699072e+00 -2.2919849e-04  2.1284968e-02  8.5743704e+00\n",
      " -2.7944148e-03  2.0261131e-02  8.5696363e+00 -3.4915507e-03\n",
      "  2.0665422e-02  8.5710220e+00 -3.7802383e-03  1.8835589e-02\n",
      "  8.5754738e+00 -3.7285239e-03  2.0514207e-02  8.5704222e+00\n",
      " -1.2041628e-03  2.1516711e-02  8.5704784e+00 -3.0369163e-03\n",
      "  2.0163968e-02  8.5685329e+00 -1.0042787e-03  1.9763477e-02\n",
      "  8.5673981e+00 -2.2687726e-03  2.0777546e-02  8.5699177e+00\n",
      " -8.3243102e-04  2.1219470e-02  8.5697269e+00 -3.1472072e-03\n",
      "  1.8322891e-02  8.5688362e+00 -1.2650266e-03  2.0096950e-02\n",
      "  8.5643654e+00 -1.8567145e-03  2.0971473e-02  8.5687895e+00\n",
      " -9.8988786e-04  2.1210842e-02  8.5676641e+00 -3.9577931e-03\n",
      "  1.8837348e-02  8.5724525e+00 -2.8153099e-03  1.8713459e-02\n",
      "  8.5658493e+00 -2.1559224e-03  2.0071540e-02  8.5710983e+00\n",
      " -2.7691424e-03  1.9614309e-02  8.5721645e+00 -1.5821010e-03\n",
      "  1.8912893e-02  8.5717764e+00 -2.0200163e-03  2.0052189e-02\n",
      "  8.5661879e+00 -2.2112057e-03  1.9247262e-02  8.5682325e+00\n",
      " -9.7297132e-04  1.9475028e-02  8.5635490e+00 -1.5467331e-03\n",
      "  2.0595426e-02  8.5630922e+00 -2.1555871e-03  1.9980207e-02\n",
      "  8.5621138e+00 -1.3628826e-03  1.8520238e-02  8.5652714e+00\n",
      " -1.0769377e-03  1.9688286e-02  8.5656319e+00 -2.1287426e-03\n",
      "  1.8706419e-02  8.5688162e+00 -1.1426657e-03  2.1305710e-02\n",
      "  8.5646791e+00 -1.9755308e-03  2.2186831e-02  8.5621901e+00\n",
      " -1.9010156e-05  2.0349938e-02  8.5654593e+00 -1.3797954e-03\n",
      "  2.0139888e-02  8.5580673e+00 -1.5394390e-04  2.0661116e-02\n",
      "  8.5672808e+00 -7.8438222e-04  2.1104157e-02  8.5646162e+00\n",
      " -5.0239265e-04  1.9873228e-02  8.5582714e+00 -1.0133609e-03\n",
      "  2.0828657e-02  8.5602694e+00 -1.6801804e-03  2.0183343e-02\n",
      "  8.5581818e+00 -2.4957731e-03  1.9743085e-02  8.5607996e+00\n",
      "  1.3613850e-03  1.9577786e-02  8.5643568e+00  6.2733889e-05\n",
      "  1.9239653e-02  8.5604448e+00 -4.8466399e-04  1.9155465e-02\n",
      "  8.5645895e+00 -1.0949671e-03  2.1912184e-02  8.5586920e+00\n",
      "  9.3241408e-04  1.8691398e-02] (expected [ 8.693e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02\n",
      "  8.550e+00 -2.000e-03  2.000e-02  8.550e+00 -2.000e-03  2.000e-02])\n",
      "[ 7.75746164e+06 -3.64069886e+05  4.78000000e-01  8.55000000e+00\n",
      "  7.75743129e+06 -3.64083806e+05  3.72000000e-01  8.43400000e+00\n",
      "  8.00000000e-03] -> [8.4533949e+00 5.4795127e-03 1.9804547e-02 8.4094095e+00 5.6855232e-03\n",
      " 1.9784141e-02 8.4105482e+00 6.3516051e-03 2.0060126e-02 8.4124107e+00\n",
      " 5.7800822e-03 2.0292602e-02 8.4139652e+00 6.7867190e-03 1.9745976e-02\n",
      " 8.4156713e+00 5.1810816e-03 1.9388631e-02 8.4168587e+00 5.2515268e-03\n",
      " 2.0118423e-02 8.4182615e+00 5.3534806e-03 1.9714899e-02 8.4199295e+00\n",
      " 7.2397403e-03 2.0494089e-02 8.4220552e+00 5.5020750e-03 2.0042203e-02\n",
      " 8.4232216e+00 4.9282014e-03 2.0293310e-02 8.4247494e+00 5.0536469e-03\n",
      " 2.0189330e-02 8.4269876e+00 4.9347728e-03 1.9711213e-02 8.4281549e+00\n",
      " 6.6839159e-03 2.0471245e-02 8.4293432e+00 5.9903264e-03 1.9808903e-02\n",
      " 8.4312019e+00 6.6049695e-03 1.9637235e-02 8.4324589e+00 6.5138526e-03\n",
      " 1.9913517e-02 8.4340391e+00 6.8639591e-03 2.0482160e-02 8.4356470e+00\n",
      " 6.0981885e-03 1.9875234e-02 8.4374132e+00 6.8674311e-03 2.0139866e-02\n",
      " 8.4381304e+00 6.5656006e-03 2.0054039e-02 8.4408979e+00 7.0129894e-03\n",
      " 1.9921355e-02 8.4423151e+00 6.7479163e-03 2.0011082e-02 8.4447937e+00\n",
      " 6.5876804e-03 1.9403204e-02 8.4454994e+00 6.5363422e-03 1.9588087e-02\n",
      " 8.4478474e+00 6.4392388e-03 1.9753486e-02 8.4496050e+00 6.5699071e-03\n",
      " 2.0198446e-02 8.4508104e+00 6.7510456e-03 2.0613426e-02 8.4521132e+00\n",
      " 6.8091229e-03 1.9673077e-02 8.4538927e+00 6.8709403e-03 2.0314261e-02\n",
      " 8.4544430e+00 7.0167258e-03 2.0427937e-02 8.4564371e+00 6.9494992e-03\n",
      " 1.9452706e-02 8.4580507e+00 6.8037882e-03 1.9776406e-02 8.4597206e+00\n",
      " 6.7501059e-03 2.0257391e-02 8.4620342e+00 6.7983642e-03 2.0177342e-02\n",
      " 8.4637480e+00 7.0457011e-03 1.9662052e-02 8.4649105e+00 6.7606028e-03\n",
      " 2.0284489e-02 8.4661970e+00 6.9214739e-03 2.0230133e-02 8.4684038e+00\n",
      " 6.8480298e-03 1.9916728e-02 8.4691467e+00 7.0107728e-03 2.0550489e-02\n",
      " 8.4715786e+00 6.6783577e-03 1.9915044e-02 8.4732733e+00 6.8943053e-03\n",
      " 1.9872893e-02 8.4740057e+00 6.8340674e-03 2.0440035e-02 8.4757051e+00\n",
      " 6.7414790e-03 1.9828159e-02 8.4769878e+00 6.7090914e-03 1.9545436e-02\n",
      " 8.4795103e+00 6.7390352e-03 2.0297691e-02 8.4813175e+00 6.3257515e-03\n",
      " 1.9418705e-02 8.4820518e+00 6.6156797e-03 1.9823037e-02 8.4843569e+00\n",
      " 6.8642795e-03 2.0498838e-02 8.4853163e+00 6.1103888e-03 1.9655354e-02] (expected [8.434e+00 8.000e-03 2.000e-02 8.435e+00 8.000e-03 2.000e-02 8.435e+00\n",
      " 8.000e-03 2.000e-02 8.436e+00 8.000e-03 2.000e-02 8.436e+00 8.000e-03\n",
      " 2.000e-02 8.437e+00 8.000e-03 2.000e-02 8.438e+00 8.000e-03 2.000e-02\n",
      " 8.438e+00 7.000e-03 2.000e-02 8.439e+00 7.000e-03 2.000e-02 8.439e+00\n",
      " 7.000e-03 2.000e-02 8.440e+00 7.000e-03 2.000e-02 8.440e+00 7.000e-03\n",
      " 2.000e-02 8.441e+00 7.000e-03 2.000e-02 8.442e+00 7.000e-03 2.000e-02\n",
      " 8.442e+00 7.000e-03 2.000e-02 8.443e+00 7.000e-03 2.000e-02 8.443e+00\n",
      " 7.000e-03 2.000e-02 8.444e+00 7.000e-03 2.000e-02 8.445e+00 7.000e-03\n",
      " 2.000e-02 8.445e+00 7.000e-03 2.000e-02 8.446e+00 7.000e-03 2.000e-02\n",
      " 8.446e+00 7.000e-03 2.000e-02 8.447e+00 7.000e-03 2.000e-02 8.447e+00\n",
      " 7.000e-03 2.000e-02 8.448e+00 7.000e-03 2.000e-02 8.449e+00 7.000e-03\n",
      " 2.000e-02 8.449e+00 7.000e-03 2.000e-02 8.450e+00 7.000e-03 2.000e-02\n",
      " 8.450e+00 7.000e-03 2.000e-02 8.451e+00 7.000e-03 2.000e-02 8.452e+00\n",
      " 7.000e-03 2.000e-02 8.452e+00 7.000e-03 2.000e-02 8.453e+00 7.000e-03\n",
      " 2.000e-02 8.453e+00 7.000e-03 2.000e-02 8.454e+00 7.000e-03 2.000e-02\n",
      " 8.454e+00 7.000e-03 2.000e-02 8.455e+00 7.000e-03 2.000e-02 8.456e+00\n",
      " 7.000e-03 2.000e-02 8.456e+00 7.000e-03 2.000e-02 8.457e+00 7.000e-03\n",
      " 2.000e-02 8.457e+00 7.000e-03 2.000e-02 8.458e+00 7.000e-03 2.000e-02\n",
      " 8.458e+00 7.000e-03 2.000e-02 8.459e+00 7.000e-03 2.000e-02 8.460e+00\n",
      " 7.000e-03 2.000e-02 8.460e+00 7.000e-03 2.000e-02 8.461e+00 7.000e-03\n",
      " 2.000e-02 8.461e+00 7.000e-03 2.000e-02 8.462e+00 7.000e-03 2.000e-02\n",
      " 8.463e+00 7.000e-03 2.000e-02])\n"
     ]
    }
   ],
   "source": [
    "#CONFIGURAR PARA VARIAS SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,150))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 150)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 150)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 150)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end]  # Modify this line\n",
    "            y_batch = y_train[start:end]  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 1)\n"
     ]
    }
   ],
   "source": [
    "print(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757372.089 -364096.883      -2.947       8.55  7757404.855 -364088.83\n",
      "       -2.858       8.51       -0.007]]\n",
      "[[ 0.35923312 -1.51726102 -1.47723057  0.48526663  0.42967534 -1.4810064\n",
      "  -1.43298184  0.55399534 -0.08572757]]\n",
      "[7757372.089 -364096.883      -2.947       8.55  7757404.855 -364088.83\n",
      "      -2.858       8.51       -0.007] -> [ 8.510642   -0.00624997  0.01665766  8.466535   -0.00677173  0.01647048\n",
      "  8.464083   -0.00791417  0.01965958  8.468564   -0.00965752  0.0191923\n",
      "  8.4692955  -0.00672112  0.01660183  8.474515   -0.01055228  0.0168124\n",
      "  8.469069   -0.00925012  0.01944942  8.471029   -0.00548801  0.02135796\n",
      "  8.467285    0.00065891  0.02296137  8.474887   -0.0049459   0.01972856\n",
      "  8.470069   -0.0068517   0.02244844  8.473115   -0.00700437  0.01513247\n",
      "  8.478899   -0.00726511  0.02146103  8.47375    -0.00154057  0.02561966\n",
      "  8.478902   -0.00756985  0.02172686  8.475272   -0.0026837   0.02060962\n",
      "  8.476428   -0.00605563  0.02174076  8.483701   -0.00153028  0.02390502\n",
      "  8.486514   -0.00884613  0.0147757   8.482785   -0.00226233  0.01906007\n",
      "  8.483843   -0.00508556  0.02405852  8.485471   -0.00206361  0.024504\n",
      "  8.487439   -0.01277356  0.0172527   8.49814    -0.00855714  0.01702939\n",
      "  8.484086   -0.00592419  0.02139774  8.496975   -0.00751761  0.02005681\n",
      "  8.499875   -0.00482054  0.01564048  8.501155   -0.00727607  0.01959991\n",
      "  8.493402   -0.00715493  0.0169284   8.500495   -0.00490884  0.01921062\n",
      "  8.495543   -0.00468432  0.02116775  8.499203   -0.00741367  0.01989581\n",
      "  8.497957   -0.00511973  0.01659054  8.501989   -0.00335395  0.01895276\n",
      "  8.504947   -0.00556805  0.01587556  8.509308   -0.00485449  0.02392212\n",
      "  8.509237   -0.006994    0.02650221  8.50384    -0.00113088  0.01960995\n",
      "  8.51101    -0.00292689  0.01993819  8.5022545  -0.00402205  0.02226245\n",
      "  8.520425   -0.00260626  0.02463824  8.510962   -0.00173311  0.02002594\n",
      "  8.504891   -0.00463607  0.02324145  8.510587   -0.00555818  0.02144583\n",
      "  8.51084    -0.00775553  0.02053052  8.512991    0.0006168   0.01945524\n",
      "  8.521429    0.00102928  0.01710736  8.519188   -0.00282283  0.017706\n",
      "  8.521872   -0.00519267  0.02498206  8.519897    0.00257488  0.0165735 ] (expected [ 8.51  -0.007  0.02   8.511 -0.007  0.02   8.511 -0.007  0.02   8.511\n",
      " -0.007  0.02   8.511 -0.007  0.02   8.511 -0.007  0.02   8.512 -0.007\n",
      "  0.02   8.512 -0.007  0.02   8.512 -0.007  0.02   8.512 -0.007  0.02\n",
      "  8.512 -0.007  0.02   8.513 -0.007  0.02   8.513 -0.007  0.02   8.513\n",
      " -0.007  0.02   8.513 -0.007  0.02   8.513 -0.007  0.02   8.514 -0.007\n",
      "  0.02   8.514 -0.007  0.02   8.514 -0.007  0.02   8.514 -0.007  0.02\n",
      "  8.514 -0.007  0.02   8.515 -0.007  0.02   8.515 -0.007  0.02   8.515\n",
      " -0.007  0.02   8.515 -0.007  0.02   8.515 -0.007  0.02   8.516 -0.007\n",
      "  0.02   8.516 -0.007  0.02   8.516 -0.007  0.02   8.516 -0.007  0.02\n",
      "  8.516 -0.007  0.02   8.517 -0.007  0.02   8.517 -0.007  0.02   8.517\n",
      " -0.007  0.02   8.517 -0.007  0.02   8.517 -0.007  0.02   8.518 -0.007\n",
      "  0.02   8.518 -0.007  0.02   8.518 -0.007  0.02   8.518 -0.007  0.02\n",
      "  8.518 -0.007  0.02   8.519 -0.007  0.02   8.519 -0.007  0.02   8.519\n",
      " -0.007  0.02   8.519 -0.007  0.02   8.519 -0.007  0.02   8.52  -0.007\n",
      "  0.02   8.52  -0.007  0.02   8.52  -0.007  0.02   8.52  -0.007  0.02 ])\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(1):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        print(X_sample)\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        print(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9)\n"
     ]
    }
   ],
   "source": [
    "X_sample = X_test_raw[1:2]\n",
    "print(X_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757445.468 -363583.437       2.224       8.55  7757465.696 -363610.614\n",
      "        2.158       8.607       0.   ]]\n"
     ]
    }
   ],
   "source": [
    "X_sample[0, 8] = 0.000\n",
    "print(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757750.975 -363847.325      -2.485       2.5   7757759.112 -363841.075\n",
      "       -2.485       2.902      -0.   ]]\n",
      "[[ 1.26659207 -0.27974198 -1.24881179 -2.58876423  1.27859044 -0.25543732\n",
      "  -1.24577649 -2.4471998   0.05157178]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dummy_input = X_test_raw[i: i+1]\n",
    "    print(dummy_input)\n",
    "    dummy_input = scaler.transform(dummy_input)\n",
    "    print(dummy_input)\n",
    "    dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "    traced_script_module = torch.jit.trace(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"model_clean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757219.02030919 -363790.45257479       0.02507255       7.59847813\n",
      " 7757221.91891166 -363789.01252881       0.02444362       7.47429562\n",
      "      -0.00269055]\n",
      "[419.98896269 203.30314877   2.00996865   1.96946407 420.14477201\n",
      " 203.81701318   2.01436103   1.86837855   0.05217095]\n"
     ]
    }
   ],
   "source": [
    "mean = scaler.mean_\n",
    "std_dev = scaler.scale_\n",
    "print(mean)\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_test_cpp = np.array([7757481.724, -363634.012, 2.313, 8.372, 7757506.813, -363650.764, 2.799, 7.703, -0.037])\n",
    "X_test_cpp = scaler.transform(X_test_cpp)\n",
    "print(X_test_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0573,  1.5971, -0.0614, -0.1519,  2.0956,  0.6641,  0.5896, -0.4267,\n",
      "          1.4114]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=24, bias=True)\n",
       "  (1): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (2): Linear(in_features=12, out_features=6, bias=True)\n",
       "  (3): Linear(in_features=6, out_features=150, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n",
      "          1.2702]])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have a trained model 'model'\n",
    "#dummy_input = torch.randn(1, 9)  # Adjust as necessary\n",
    "dummy_input = X_test_raw[i: i+1]\n",
    "dummy_input = scaler.transform(dummy_input)\n",
    "dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "print(dummy_input)\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Dados/caiopinho/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.ones(1, 9, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Convert the model to Torch Script\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, dummy_input)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Save the Torch Script module\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m script_module\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/jit/_trace.py:778\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    773\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrace doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support compiling individual module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms functions.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    774\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use trace_module\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m     )\n\u001b[1;32m    777\u001b[0m name \u001b[39m=\u001b[39m _qualified_name(func)\n\u001b[0;32m--> 778\u001b[0m traced \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_function_from_trace(\n\u001b[1;32m    779\u001b[0m     name, func, example_inputs, var_lookup_fn, strict, _force_outplace\n\u001b[1;32m    780\u001b[0m )\n\u001b[1;32m    782\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m check_trace:\n",
      "\u001b[0;31mTypeError\u001b[0m: _create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"model.onnx\")\n",
    "\n",
    "# Convert the model to Torch Script\n",
    "script_module = torch.jit.trace(model, dummy_input)\n",
    "\n",
    "# Save the Torch Script module\n",
    "script_module.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "       -2.487       4.803       0.001]]\n",
      "[[ 1.16240348 -0.45512402 -1.25481378  0.4579256   1.19118628 -0.4031037\n",
      "  -1.25742504 -1.43256721  0.07519625]]\n",
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001]\n"
     ]
    }
   ],
   "source": [
    "X_sample2 = X_test_raw[0: 1]\n",
    "print(X_sample2)\n",
    "\n",
    "X_sample2 = scaler.transform(X_sample2)\n",
    "print(X_sample2)\n",
    "X_sample2 = X_test_raw[0]\n",
    "print(X_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001] -> [ 4.8010063  -0.00074159  0.01997822  4.8005514  -0.00091523  0.02000268\n",
      "  4.814805   -0.00176182  0.01970529  4.8287263  -0.000778    0.02051836\n",
      "  4.8326116  -0.00174367  0.01992373  4.856453   -0.00167146  0.01983681\n",
      "  4.864167   -0.00193731  0.01993301  4.879089   -0.00164818  0.02014743\n",
      "  4.8937235  -0.00073487  0.02012613  4.8967085  -0.00159477  0.01993886\n",
      "  4.9280586  -0.00181691  0.01975316  4.925619   -0.00195716  0.02010386\n",
      "  4.950785   -0.00190242  0.02001777  4.957052   -0.00186971  0.0202428\n",
      "  4.97818    -0.00249793  0.01988537  4.995721   -0.00255796  0.02014657\n",
      "  4.994455   -0.0025937   0.01995826  5.008133   -0.00280979  0.02011759\n",
      "  5.0308924  -0.00291541  0.01984772  5.0377316  -0.00323275  0.02050596\n",
      "  5.0456805  -0.00307235  0.0199565   5.065904   -0.00340613  0.01975301\n",
      "  5.074639   -0.00332363  0.01996499  5.1010294  -0.00328155  0.01999776\n",
      "  5.1006637  -0.00362112  0.01982425  5.1268015  -0.00374103  0.01991623\n",
      "  5.138431   -0.00395512  0.01991449  5.14359    -0.00391159  0.01998987\n",
      "  5.1597624  -0.00423715  0.0200338   5.164531   -0.00380588  0.01998207\n",
      "  5.1826973  -0.00437438  0.02011609  5.1961102  -0.00469906  0.02033865\n",
      "  5.2155013  -0.00415806  0.02007735  5.2181277  -0.00392795  0.01971572\n",
      "  5.235365   -0.0039203   0.02010624  5.2443867  -0.00465819  0.01985199\n",
      "  5.254088   -0.00413277  0.02006014  5.2746816  -0.0038663   0.0199084\n",
      "  5.2876625  -0.00470388  0.0199628   5.2932086  -0.00375362  0.02029131\n",
      "  5.3144155  -0.0036635   0.02001484  5.3334975  -0.00344844  0.01998478\n",
      "  5.3484445  -0.00428118  0.01996177  5.3510637  -0.00424473  0.0199277\n",
      "  5.3572283  -0.00406776  0.02008447  5.3868194  -0.00447915  0.02004181\n",
      "  5.3942337  -0.00368278  0.01986287  5.4088097  -0.00456195  0.02005492\n",
      "  5.414704   -0.00376444  0.02006499  5.440771   -0.0048934   0.01993128] (expected [4.803 0.001 0.02  4.819 0.001 0.02  4.835 0.001 0.02  4.851 0.001 0.02\n",
      " 4.867 0.001 0.02  4.883 0.001 0.02  4.899 0.001 0.02  4.915 0.001 0.02\n",
      " 4.931 0.001 0.02  4.947 0.001 0.02  4.963 0.001 0.02  4.979 0.001 0.02\n",
      " 4.995 0.001 0.02  5.011 0.001 0.02  5.027 0.001 0.02  5.043 0.001 0.02\n",
      " 5.059 0.001 0.02  5.075 0.001 0.02  5.091 0.001 0.02  5.107 0.001 0.02\n",
      " 5.123 0.001 0.02  5.139 0.001 0.02  5.155 0.001 0.02  5.171 0.    0.02\n",
      " 5.187 0.    0.02  5.203 0.    0.02  5.219 0.    0.02  5.235 0.    0.02\n",
      " 5.251 0.    0.02  5.267 0.    0.02  5.283 0.    0.02  5.299 0.    0.02\n",
      " 5.315 0.    0.02  5.331 0.    0.02  5.347 0.    0.02  5.363 0.    0.02\n",
      " 5.379 0.    0.02  5.395 0.    0.02  5.411 0.    0.02  5.427 0.    0.02\n",
      " 5.443 0.    0.02  5.459 0.    0.02  5.475 0.    0.02  5.491 0.    0.02\n",
      " 5.507 0.    0.02  5.523 0.    0.02  5.539 0.    0.02  5.555 0.    0.02\n",
      " 5.571 0.    0.02  5.587 0.001 0.02 ])\n",
      "[7757801.761 -363519.424       3.074       8.016 7757831.521 -363531.805\n",
      "       2.493       8.334       0.025] -> [8.332953   0.02570583 0.02057826 8.279287   0.0260936  0.01937635\n",
      " 8.279661   0.02568588 0.02047574 8.281424   0.02454777 0.01915007\n",
      " 8.274772   0.02515006 0.02098195 8.281982   0.02503929 0.01914372\n",
      " 8.278026   0.02583499 0.0184833  8.280119   0.02489562 0.02037758\n",
      " 8.2803     0.02479535 0.02028337 8.273154   0.02475645 0.01960913\n",
      " 8.286489   0.02491888 0.01928371 8.275139   0.02615823 0.01904969\n",
      " 8.283588   0.0249912  0.020569   8.279796   0.02533591 0.02059739\n",
      " 8.283659   0.02476165 0.02070565 8.287676   0.02572682 0.02014912\n",
      " 8.276308   0.02517223 0.01923848 8.27715    0.02432403 0.01998729\n",
      " 8.284091   0.0255501  0.01925227 8.280431   0.02544269 0.02009993\n",
      " 8.276081   0.0244431  0.01982384 8.280431   0.02421162 0.0209767\n",
      " 8.276962   0.02461271 0.02015173 8.288047   0.02541332 0.02063011\n",
      " 8.277835   0.02415167 0.02029199 8.287139   0.0238065  0.01952587\n",
      " 8.285027   0.02313591 0.01905958 8.280449   0.02377018 0.01999696\n",
      " 8.28143    0.02516142 0.02103802 8.275567   0.02468783 0.02011264\n",
      " 8.279786   0.02446736 0.0203737  8.279707   0.02499932 0.01933622\n",
      " 8.283042   0.02523439 0.01940995 8.276601   0.02493435 0.01961403\n",
      " 8.27914    0.02568574 0.02154677 8.276657   0.02521071 0.02053792\n",
      " 8.274283   0.02505938 0.02104003 8.278971   0.02595724 0.01849017\n",
      " 8.2789345  0.02633464 0.01930214 8.273977   0.02619009 0.02057384\n",
      " 8.278184   0.02495228 0.0193009  8.282623   0.02417462 0.0207606\n",
      " 8.285052   0.02478037 0.02051708 8.276708   0.02573486 0.01951893\n",
      " 8.273311   0.02499515 0.0200881  8.283986   0.02586628 0.01974319\n",
      " 8.279172   0.02529712 0.02044044 8.281159   0.02531607 0.01932614\n",
      " 8.275503   0.02524789 0.01950336 8.284525   0.02565493 0.01986678] (expected [8.334 0.025 0.02  8.332 0.025 0.02  8.331 0.025 0.02  8.329 0.025 0.02\n",
      " 8.327 0.025 0.02  8.326 0.025 0.02  8.324 0.025 0.02  8.323 0.025 0.02\n",
      " 8.321 0.025 0.02  8.319 0.025 0.02  8.318 0.025 0.02  8.316 0.025 0.02\n",
      " 8.315 0.025 0.02  8.313 0.025 0.02  8.312 0.025 0.02  8.31  0.025 0.02\n",
      " 8.308 0.026 0.02  8.307 0.026 0.02  8.305 0.026 0.02  8.304 0.026 0.02\n",
      " 8.302 0.026 0.02  8.3   0.026 0.02  8.299 0.026 0.02  8.297 0.026 0.02\n",
      " 8.296 0.026 0.02  8.294 0.026 0.02  8.292 0.026 0.02  8.291 0.026 0.02\n",
      " 8.289 0.027 0.02  8.288 0.027 0.02  8.286 0.027 0.02  8.285 0.027 0.02\n",
      " 8.283 0.027 0.02  8.281 0.027 0.02  8.28  0.027 0.02  8.278 0.028 0.02\n",
      " 8.277 0.028 0.02  8.275 0.028 0.02  8.273 0.028 0.02  8.272 0.029 0.02\n",
      " 8.27  0.029 0.02  8.269 0.029 0.02  8.267 0.029 0.02  8.265 0.03  0.02\n",
      " 8.264 0.03  0.02  8.262 0.03  0.02  8.261 0.031 0.02  8.259 0.031 0.02\n",
      " 8.257 0.031 0.02  8.256 0.032 0.02 ])\n",
      "[7757398.832 -363523.465       2.313       8.55  7757418.023 -363547.615\n",
      "       2.224       7.703       0.001] -> [7.68352    0.00130333 0.02032702 7.641883   0.00083899 0.02039786\n",
      " 7.6465163  0.00056658 0.02013385 7.6483893  0.00194509 0.02029281\n",
      " 7.6505     0.00100994 0.01988105 7.6568565  0.00122235 0.02029719\n",
      " 7.6596446  0.00039227 0.02037289 7.662617   0.00142402 0.02003271\n",
      " 7.667677   0.00241441 0.01962855 7.669256   0.00201954 0.02052943\n",
      " 7.6761103  0.00163754 0.01999038 7.6771     0.00058164 0.02000098\n",
      " 7.683269   0.00165032 0.02034155 7.684547   0.00150722 0.01954996\n",
      " 7.6919785  0.00146589 0.02018756 7.695269   0.0005441  0.0205392\n",
      " 7.6975493  0.00094914 0.02031845 7.700929   0.00180373 0.02080054\n",
      " 7.7061877  0.00045523 0.02029929 7.7079177  0.00016031 0.01984137\n",
      " 7.711619   0.00095294 0.01972057 7.7176385  0.00099961 0.01966164\n",
      " 7.720926   0.00110845 0.02040421 7.725027   0.00096409 0.01933991\n",
      " 7.726849   0.00044702 0.01945675 7.7329917  0.00127519 0.02017855\n",
      " 7.737667   0.00104059 0.02027552 7.738297   0.00138625 0.02069708\n",
      " 7.7441926  0.00089028 0.02004447 7.7461205  0.00130421 0.02008313\n",
      " 7.749738   0.00169409 0.02011915 7.7536077  0.00105089 0.02062368\n",
      " 7.760129   0.00061737 0.02020869 7.760017   0.0009951  0.01945942\n",
      " 7.7652626  0.00119765 0.01941936 7.7676105  0.00134489 0.01985163\n",
      " 7.770476   0.00189952 0.01999766 7.776159   0.00147761 0.02066216\n",
      " 7.7798986  0.00109136 0.01993258 7.7812815  0.0016046  0.02023147\n",
      " 7.788701   0.00245623 0.02079733 7.793334   0.00313549 0.02034777\n",
      " 7.795774   0.00259195 0.01947185 7.7981896  0.00216164 0.01940961\n",
      " 7.7987413  0.0028218  0.01963487 7.8069115  0.00203289 0.02025949\n",
      " 7.810602   0.00299086 0.02001701 7.8133383  0.00247199 0.01974632\n",
      " 7.816203   0.00330944 0.02070255 7.8224535  0.00220504 0.01950284] (expected [7.703 0.001 0.02  7.707 0.001 0.02  7.712 0.001 0.02  7.716 0.001 0.02\n",
      " 7.72  0.001 0.02  7.725 0.001 0.02  7.729 0.001 0.02  7.734 0.001 0.02\n",
      " 7.738 0.001 0.02  7.742 0.001 0.02  7.747 0.001 0.02  7.751 0.001 0.02\n",
      " 7.755 0.001 0.02  7.76  0.001 0.02  7.764 0.001 0.02  7.769 0.001 0.02\n",
      " 7.773 0.001 0.02  7.777 0.001 0.02  7.782 0.001 0.02  7.786 0.001 0.02\n",
      " 7.791 0.001 0.02  7.795 0.001 0.02  7.799 0.001 0.02  7.804 0.001 0.02\n",
      " 7.808 0.001 0.02  7.813 0.001 0.02  7.817 0.001 0.02  7.821 0.001 0.02\n",
      " 7.826 0.001 0.02  7.83  0.001 0.02  7.835 0.001 0.02  7.839 0.001 0.02\n",
      " 7.843 0.001 0.02  7.848 0.001 0.02  7.852 0.001 0.02  7.857 0.001 0.02\n",
      " 7.861 0.001 0.02  7.865 0.001 0.02  7.87  0.001 0.02  7.874 0.001 0.02\n",
      " 7.878 0.001 0.02  7.883 0.001 0.02  7.887 0.001 0.02  7.892 0.001 0.02\n",
      " 7.896 0.001 0.02  7.9   0.001 0.02  7.905 0.001 0.02  7.909 0.001 0.02\n",
      " 7.914 0.001 0.02  7.918 0.001 0.02 ])\n",
      "[7756536.421 -363779.861       1.18        8.55  7756528.942 -363813.723\n",
      "       1.441       8.68       -0.007] -> [ 8.648965   -0.00748847  0.02032312  8.593876   -0.00899696  0.02150925\n",
      "  8.5948105  -0.00896706  0.02008479  8.58801    -0.00458245  0.02139455\n",
      "  8.591499   -0.00721812  0.01868896  8.588325   -0.00662043  0.02156892\n",
      "  8.590234   -0.00932901  0.02237298  8.5854225  -0.00596195  0.0196064\n",
      "  8.587645   -0.00375348  0.01870826  8.590537   -0.00439189  0.02173356\n",
      "  8.581299   -0.00550023  0.02065581  8.587846   -0.00899826  0.02101593\n",
      "  8.5828     -0.00535823  0.02023461  8.580964   -0.0060997   0.01808261\n",
      "  8.584315   -0.00537994  0.01971883  8.577991   -0.00857803  0.02118644\n",
      "  8.587483   -0.00700641  0.021599    8.58501    -0.00396815  0.02187604\n",
      "  8.579759   -0.00841048  0.02152368  8.5788145  -0.00893942  0.01926094\n",
      "  8.583215   -0.00601663  0.01948993  8.582711   -0.00559088  0.01828561\n",
      "  8.585115   -0.00567044  0.02085053  8.572363   -0.00679334  0.01776277\n",
      "  8.579396   -0.00675549  0.0184348   8.573252   -0.00431146  0.02105259\n",
      "  8.577254   -0.00418436  0.02162115  8.574989   -0.00399152  0.0217767\n",
      "  8.57805    -0.00653502  0.01914867  8.58017    -0.00506145  0.02012574\n",
      "  8.574344   -0.00387561  0.01986536  8.574201   -0.00594503  0.02222824\n",
      "  8.575941   -0.00736262  0.02103469  8.574182   -0.00618547  0.0190888\n",
      "  8.573944   -0.00645809  0.01701276  8.573064   -0.00555292  0.0190782\n",
      "  8.573169   -0.00409814  0.01893005  8.571572   -0.00615226  0.0231559\n",
      "  8.570943   -0.00733435  0.02050165  8.570824   -0.00616522  0.01997779\n",
      "  8.573595   -0.00285508  0.02266856  8.569768   -0.0005482   0.0200972\n",
      "  8.563346   -0.00242199  0.01813856  8.569615   -0.00433783  0.01900239\n",
      "  8.565632   -0.00200707  0.01899615  8.562543   -0.00488578  0.02088645\n",
      "  8.567423   -0.00223367  0.01964829  8.562147   -0.00337069  0.01994379\n",
      "  8.566233   -0.00156729  0.02223463  8.560793   -0.00444076  0.01894637] (expected [ 8.68  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02\n",
      "  8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.009  0.02\n",
      "  8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55\n",
      " -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009\n",
      "  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02 ])\n",
      "[7757309.348 -363499.087      -2.407       6.407 7757333.518 -363490.282\n",
      "       3.096       6.789       0.063] -> [6.7516246  0.06393541 0.0203922  6.714112   0.06429583 0.01986296\n",
      " 6.7130346  0.06421862 0.02037632 6.714601   0.06174846 0.01862007\n",
      " 6.690399   0.06312048 0.02134422 6.7101917  0.06299231 0.01969864\n",
      " 6.697115   0.0635093  0.01890697 6.6980944  0.06255621 0.02043486\n",
      " 6.696756   0.06170458 0.02021852 6.673561   0.0622045  0.01976297\n",
      " 6.710045   0.06274613 0.02008623 6.674609   0.0626265  0.01846962\n",
      " 6.6977534  0.06200032 0.02084127 6.681123   0.06232089 0.02072971\n",
      " 6.691144   0.06180153 0.02126975 6.7009463  0.06254116 0.01991961\n",
      " 6.6646037  0.06192434 0.01919109 6.663426   0.06095931 0.02039833\n",
      " 6.6841207  0.06183478 0.01955387 6.6679854  0.06177959 0.01980429\n",
      " 6.652021   0.06063057 0.01983571 6.6637483  0.06052557 0.02118478\n",
      " 6.650559   0.06046109 0.02037393 6.679942   0.06084244 0.02039348\n",
      " 6.64709    0.05994342 0.02032236 6.6720653  0.05926207 0.01921879\n",
      " 6.664455   0.05888236 0.0193051  6.647466   0.0593219  0.0200149\n",
      " 6.6470604  0.06064299 0.02071782 6.626414   0.05951655 0.02003768\n",
      " 6.635787   0.05980266 0.02034537 6.635339   0.06039565 0.01852893\n",
      " 6.6426735  0.06026457 0.01953453 6.6192966  0.05949992 0.02007317\n",
      " 6.6249437  0.06008597 0.02125828 6.615039   0.05911204 0.02098817\n",
      " 6.6027455  0.05909542 0.02104271 6.616658   0.06002344 0.01874468\n",
      " 6.613754   0.06030071 0.01947895 6.5958104  0.05995737 0.01991723\n",
      " 6.606965   0.05849443 0.01943179 6.617211   0.05763273 0.02095491\n",
      " 6.620795   0.05855547 0.02065229 6.593711   0.05880125 0.01958214\n",
      " 6.578475   0.05770756 0.01979366 6.6092935  0.05872704 0.01973746\n",
      " 6.593334   0.05818869 0.02065203 6.594169   0.05764527 0.0194798\n",
      " 6.5751987  0.05768259 0.01949466 6.601967   0.05686679 0.01971253] (expected [6.789 0.063 0.02  6.787 0.063 0.02  6.785 0.063 0.02  6.783 0.063 0.02\n",
      " 6.781 0.063 0.02  6.779 0.063 0.02  6.777 0.063 0.02  6.775 0.063 0.02\n",
      " 6.773 0.063 0.02  6.771 0.063 0.02  6.769 0.063 0.02  6.767 0.063 0.02\n",
      " 6.765 0.063 0.02  6.763 0.063 0.02  6.761 0.063 0.02  6.759 0.063 0.02\n",
      " 6.757 0.064 0.02  6.755 0.064 0.02  6.753 0.064 0.02  6.751 0.064 0.02\n",
      " 6.75  0.064 0.02  6.748 0.064 0.02  6.746 0.064 0.02  6.744 0.064 0.02\n",
      " 6.742 0.064 0.02  6.74  0.064 0.02  6.738 0.064 0.02  6.736 0.065 0.02\n",
      " 6.734 0.065 0.02  6.732 0.065 0.02  6.73  0.065 0.02  6.728 0.065 0.02\n",
      " 6.726 0.066 0.02  6.724 0.066 0.02  6.722 0.066 0.02  6.72  0.066 0.02\n",
      " 6.718 0.067 0.02  6.716 0.067 0.02  6.714 0.067 0.02  6.712 0.067 0.02\n",
      " 6.71  0.068 0.02  6.708 0.068 0.02  6.706 0.068 0.02  6.705 0.069 0.02\n",
      " 6.703 0.069 0.02  6.701 0.07  0.02  6.699 0.07  0.02  6.697 0.071 0.02\n",
      " 6.695 0.071 0.02  6.693 0.072 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "np.set_printoptions(suppress=True)\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.02\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5p0lEQVR4nO3df3hUZ53//9ecmcwMv5KUIAmhobAahQollEAI7bXYD7katqw1ihYQhWW5QHcLAlnbAvKjWrvB9kOXtmDzwcuqey0sLJ8L2cqy7CcNtdovkR8JWLEFa20JLUwAMRkIkB9zzvePyUwyEGgGzswpyfNxXXMFzrzPPffcvSQv73Of+7gsy7IEAABwmzOc7gAAAIAdCDUAAKBbINQAAIBugVADAAC6BUINAADoFgg1AACgWyDUAACAboFQAwAAugWP0x1IFtM0derUKfXr108ul8vp7gAAgC6wLEsXLlxQdna2DOPGczE9JtScOnVKOTk5TncDAADchJMnT+rOO++8YU2PCTX9+vWTFB6U1NRUh3sDAAC6IhgMKicnJ/p7/EZ6TKiJXHJKTU0l1AAAcJvpytIRFgoDAIBugVADAAC6BUINAADoFgg1AACgWyDUAACAboFQAwAAugVCDQAA6BYINQAAoFsg1AAAgG6BUAMAALoFQg0AAOgWCDUAAKBb6DEPtEyUP565oM37a5WV6tc3Jn3S6e4AANBjMVNziz6sv6Kf/H/v6z+PnHK6KwAA9GiEmlvkMcKPQjcty+GeAADQsxFqbpG7LdS0moQaAACcRKi5RZGZmhChBgAARxFqbpERnakxHe4JAAA9G6HmFkVnakLM1AAA4CRCzS2KrKkJsVAYAABH3VSo2bhxo4YOHSq/36+CggIdOHDghvXbt2/X8OHD5ff7NWrUKO3evTvm/SeffFLDhw9Xnz59dMcdd6ioqEj79++PqTl//rxmzZql1NRUpaena968ebp48eLNdN9WHiM8hKypAQDAWXGHmm3btqm0tFRr1qxRTU2NRo8ereLiYp05c6bT+n379mnmzJmaN2+eDh8+rJKSEpWUlOjo0aPRmk9/+tPasGGDfve73+mNN97Q0KFD9eCDD+rs2bPRmlmzZun3v/+9KioqtGvXLv3qV7/SggULbuIr24u7nwAA+HhwWVZ8100KCgo0btw4bdiwQZJkmqZycnK0aNEiLVu27Jr66dOnq7GxUbt27YoemzBhgvLy8lReXt7pZwSDQaWlpenVV1/V5MmT9fbbb+vuu+/WwYMHlZ+fL0nas2ePHnroIX3wwQfKzs7+yH5H2mxoaFBqamo8X/mG3jvXqAf+9y/Vz+fR775bbFu7AAAgvt/fcc3UNDc3q7q6WkVFRe0NGIaKiopUVVXV6TlVVVUx9ZJUXFx83frm5mZt2rRJaWlpGj16dLSN9PT0aKCRpKKiIhmGcc1lqmTzsKYGAICPhbie/XTu3DmFQiFlZmbGHM/MzNSxY8c6PScQCHRaHwgEYo7t2rVLM2bM0KVLlzRo0CBVVFRowIAB0TYGDhwY23GPR/3797+mnYimpiY1NTVF/x4MBrv2JePE5ScAAD4ePjZ3Pz3wwAM6cuSI9u3bpylTpuiRRx657jqdrigrK1NaWlr0lZOTY2Nv27H5HgAAHw9xhZoBAwbI7Xarrq4u5nhdXZ2ysrI6PScrK6tL9X369NGnPvUpTZgwQT/+8Y/l8Xj04x//ONrG1QGntbVV58+fv+7nLl++XA0NDdHXyZMn4/mqXWZ0CDVxLk8CAAA2iivUeL1ejR07VpWVldFjpmmqsrJShYWFnZ5TWFgYUy9JFRUV163v2G7k8lFhYaHq6+tVXV0dfX/v3r0yTVMFBQWdnu/z+ZSamhrzSoTITI3EbA0AAE6Ka02NJJWWlmrOnDnKz8/X+PHjtX79ejU2Nmru3LmSpNmzZ2vw4MEqKyuTJC1evFiTJk3SunXrNHXqVG3dulWHDh3Spk2bJEmNjY16+umn9fDDD2vQoEE6d+6cNm7cqA8//FBf+cpXJEkjRozQlClTNH/+fJWXl6ulpUULFy7UjBkzunTnUyK5O4Yay4p/QAEAgC3i/h08ffp0nT17VqtXr1YgEFBeXp727NkTXQxcW1srw2ifAJo4caK2bNmilStXasWKFcrNzdXOnTs1cuRISZLb7daxY8f0s5/9TOfOnVNGRobGjRunX//61/rsZz8bbWfz5s1auHChJk+eLMMwNG3aNL3wwgu3+v1vmafDd2WmBgAA58S9T83tKlH71DS1hvSZlXskSW8++aBS/Sm2tQ0AQE+XsH1qcK2YmRoeagkAgGMINbeow5IaNuADAMBBhJpb5HK52KsGAICPAUKNDdhVGAAA5xFqbBAJNaypAQDAOYQaG7h5qCUAAI4j1NigfU2N6XBPAADouQg1NnC33dbNmhoAAJxDqLGBu20UW1lTAwCAYwg1NohswMct3QAAOIdQYwMWCgMA4DxCjQ3YfA8AAOcRamwQ3XyPNTUAADiGUGMDNzM1AAA4jlBjA9bUAADgPEKNDdh8DwAA5xFqbMCaGgAAnEeosQFragAAcB6hxgbRmRpCDQAAjiHU2CCyo7DJQmEAABxDqLEBa2oAAHAeocYGrKkBAMB5hBobsKYGAADnEWps4GHzPQAAHEeosUH08lOIzfcAAHAKocYGHi4/AQDgOEKNDQwWCgMA4DhCjQ2YqQEAwHmEGhu4I5vvEWoAAHAMocYGzNQAAOA8Qo0N2HwPAADnEWpswOZ7AAA4j1Bjg8jlJx5oCQCAcwg1NuCBlgAAOI9QY4PoYxJMdhQGAMAphBobGKypAQDAcYQaG7CmBgAA5xFqbBDZfI81NQAAOIdQYwMP+9QAAOA4Qo0NWFMDAIDzCDU2YKYGAADnEWpswGMSAABwHqHGBjzQEgAA5xFqbGCw+R4AAI67qVCzceNGDR06VH6/XwUFBTpw4MAN67dv367hw4fL7/dr1KhR2r17d/S9lpYWPfHEExo1apT69Omj7OxszZ49W6dOnYppY+jQoXK5XDGvtWvX3kz3bcdMDQAAzos71Gzbtk2lpaVas2aNampqNHr0aBUXF+vMmTOd1u/bt08zZ87UvHnzdPjwYZWUlKikpERHjx6VJF26dEk1NTVatWqVampqtGPHDh0/flwPP/zwNW1973vf0+nTp6OvRYsWxdv9hHCz+R4AAI5zWVZ8v4kLCgo0btw4bdiwQZJkmqZycnK0aNEiLVu27Jr66dOnq7GxUbt27YoemzBhgvLy8lReXt7pZxw8eFDjx4/XiRMnNGTIEEnhmZolS5ZoyZIl8XQ3KhgMKi0tTQ0NDUpNTb2pNq7nv948rUe31KhgWH9t+0ahrW0DANCTxfP7O66ZmubmZlVXV6uoqKi9AcNQUVGRqqqqOj2nqqoqpl6SiouLr1svSQ0NDXK5XEpPT485vnbtWmVkZGjMmDF69tln1draet02mpqaFAwGY16Jwt1PAAA4zxNP8blz5xQKhZSZmRlzPDMzU8eOHev0nEAg0Gl9IBDotP7KlSt64oknNHPmzJhE9q1vfUv33nuv+vfvr3379mn58uU6ffq0nnvuuU7bKSsr03e/+914vt5Nc7OmBgAAx8UVahKtpaVFjzzyiCzL0ksvvRTzXmlpafTP99xzj7xer77xjW+orKxMPp/vmraWL18ec04wGFROTk5C+s3mewAAOC+uUDNgwAC53W7V1dXFHK+rq1NWVlan52RlZXWpPhJoTpw4ob17937kdbOCggK1trbq/fff12c+85lr3vf5fJ2GnUTg8hMAAM6La02N1+vV2LFjVVlZGT1mmqYqKytVWNj5AtnCwsKYekmqqKiIqY8EmnfeeUevvvqqMjIyPrIvR44ckWEYGjhwYDxfISGYqQEAwHlxX34qLS3VnDlzlJ+fr/Hjx2v9+vVqbGzU3LlzJUmzZ8/W4MGDVVZWJklavHixJk2apHXr1mnq1KnaunWrDh06pE2bNkkKB5ovf/nLqqmp0a5duxQKhaLrbfr37y+v16uqqirt379fDzzwgPr166eqqiotXbpUX/va13THHXfYNRY3rf2Blmy+BwCAU+IONdOnT9fZs2e1evVqBQIB5eXlac+ePdHFwLW1tTKM9gmgiRMnasuWLVq5cqVWrFih3Nxc7dy5UyNHjpQkffjhh3rllVckSXl5eTGf9dprr+lzn/ucfD6ftm7dqieffFJNTU0aNmyYli5dGrNmxknM1AAA4Ly496m5XSVyn5rDtX/RF3+4Tzn9e+nXj/8vW9sGAKAnS9g+Neicp21mKhTqEfkQAICPJUKNDdinBgAA5xFqbMAt3QAAOI9QYwNmagAAcB6hxgaRu59MQg0AAI4h1NiAmRoAAJxHqLEBa2oAAHAeocYGHnYUBgDAcYQaG0RmakxL6iF7GQIA8LFDqLGBp8NjIbgEBQCAMwg1NuiQaVgsDACAQwg1NmCmBgAA5xFqbBBZUyNJIdbUAADgCEKNDTwdQw0PtQQAwBGEGhsYhkuutlzDmhoAAJxBqLGJ28UGfAAAOIlQYxM3G/ABAOAoQo1N2h9q6XBHAADooQg1NmGmBgAAZxFqbMJDLQEAcBahxibutg34uPsJAABnEGps4mGmBgAARxFqbMLlJwAAnEWosYnHHVkoTKgBAMAJhBqbsPkeAADOItTYhFu6AQBwFqHGJm423wMAwFGEGpu0r6kh1QAA4ARCjU1YUwMAgLMINTZpX1NDqAEAwAmEGpt42nYUNgk1AAA4glBjE2ZqAABwFqHGJuwoDACAswg1NmGmBgAAZxFqbNL+QEtu6QYAwAmEGpu0X35yuCMAAPRQhBqbRDbfY6YGAABnEGpsYrhYUwMAgJMINTbxcPcTAACOItTYxN22+R6hBgAAZxBqbOLhlm4AABxFqLGJweUnAAAcRaixCTM1AAA4i1Bjk8g+NTzQEgAAZ9xUqNm4caOGDh0qv9+vgoICHThw4Ib127dv1/Dhw+X3+zVq1Cjt3r07+l5LS4ueeOIJjRo1Sn369FF2drZmz56tU6dOxbRx/vx5zZo1S6mpqUpPT9e8efN08eLFm+l+QjBTAwCAs+IONdu2bVNpaanWrFmjmpoajR49WsXFxTpz5kyn9fv27dPMmTM1b948HT58WCUlJSopKdHRo0clSZcuXVJNTY1WrVqlmpoa7dixQ8ePH9fDDz8c086sWbP0+9//XhUVFdq1a5d+9atfacGCBTfxlRPDzeZ7AAA4ymVZVlxTCwUFBRo3bpw2bNggSTJNUzk5OVq0aJGWLVt2Tf306dPV2NioXbt2RY9NmDBBeXl5Ki8v7/QzDh48qPHjx+vEiRMaMmSI3n77bd199906ePCg8vPzJUl79uzRQw89pA8++EDZ2dkf2e9gMKi0tDQ1NDQoNTU1nq/cJc/sOaYf/vJdzb1vqNZ8/rO2tw8AQE8Uz+/vuGZqmpubVV1draKiovYGDENFRUWqqqrq9JyqqqqYekkqLi6+br0kNTQ0yOVyKT09PdpGenp6NNBIUlFRkQzD0P79+ztto6mpScFgMOaVSGy+BwCAs+IKNefOnVMoFFJmZmbM8czMTAUCgU7PCQQCcdVfuXJFTzzxhGbOnBlNZIFAQAMHDoyp83g86t+//3XbKSsrU1paWvSVk5PTpe94s9h8DwAAZ32s7n5qaWnRI488Isuy9NJLL91SW8uXL1dDQ0P0dfLkSZt62bn2B1oSagAAcIInnuIBAwbI7Xarrq4u5nhdXZ2ysrI6PScrK6tL9ZFAc+LECe3duzfmullWVtY1C5FbW1t1/vz5636uz+eTz+fr8ne7VTzQEgAAZ8U1U+P1ejV27FhVVlZGj5mmqcrKShUWFnZ6TmFhYUy9JFVUVMTURwLNO++8o1dffVUZGRnXtFFfX6/q6urosb1798o0TRUUFMTzFRKGNTUAADgrrpkaSSotLdWcOXOUn5+v8ePHa/369WpsbNTcuXMlSbNnz9bgwYNVVlYmSVq8eLEmTZqkdevWaerUqdq6dasOHTqkTZs2SQoHmi9/+cuqqanRrl27FAqFoutk+vfvL6/XqxEjRmjKlCmaP3++ysvL1dLSooULF2rGjBlduvMpGdyEGgAAHBV3qJk+fbrOnj2r1atXKxAIKC8vT3v27IkuBq6trZVhtE8ATZw4UVu2bNHKlSu1YsUK5ebmaufOnRo5cqQk6cMPP9Qrr7wiScrLy4v5rNdee02f+9znJEmbN2/WwoULNXnyZBmGoWnTpumFF164me+cEKypAQDAWXHvU3O7SvQ+Nf/2mxNaufOoij+bqf/z9fyPPgEAAHykhO1Tg+tjTQ0AAM4i1NjEzbOfAABwFKHGJqypAQDAWYQam7CjMAAAziLU2MTN5nsAADiKUGMT9qkBAMBZhBqbcPcTAADOItTYxM1CYQAAHEWosQlragAAcBahxibtl59Mh3sCAEDPRKixCZvvAQDgLEKNTSKb75mEGgAAHEGosUlk8z1magAAcAahxiaRhcLc/QQAgDMINTZhTQ0AAM4i1NiENTUAADiLUGMTZmoAAHAWocYmrKkBAMBZhBqbtM/UsPkeAABOINTYpH1NjcMdAQCghyLU2ISZGgAAnEWosUlkTY1pcQcUAABOINTYxGO0D2XIItQAAJBshBqbuNvW1EjcAQUAgBMINTbxGIQaAACcRKixibtDqGEDPgAAko9QY5PIQmGJmRoAAJxAqLGJYbgUyTXc1g0AQPIRamwUWVdDpgEAIPkINTZiAz4AAJxDqLERD7UEAMA5hBobtc/UEGoAAEg2Qo2NPO7wcDJTAwBA8hFqbBSZqSHUAACQfIQaG3kINQAAOIZQYyPDxZoaAACcQqixkccdmanhlm4AAJKNUGOj9jU1DncEAIAeiFBjIw+b7wEA4BhCjY0MNt8DAMAxhBobRdbUsFAYAIDkI9TYyG20bb4XItQAAJBshBobRfepsQg1AAAkG6HGRjzQEgAA59xUqNm4caOGDh0qv9+vgoICHThw4Ib127dv1/Dhw+X3+zVq1Cjt3r075v0dO3bowQcfVEZGhlwul44cOXJNG5/73OfkcrliXt/85jdvpvsJwwMtAQBwTtyhZtu2bSotLdWaNWtUU1Oj0aNHq7i4WGfOnOm0ft++fZo5c6bmzZunw4cPq6SkRCUlJTp69Gi0prGxUffff79+8IMf3PCz58+fr9OnT0dfzzzzTLzdTyg23wMAwDlxh5rnnntO8+fP19y5c3X33XervLxcvXv31ssvv9xp/fPPP68pU6boscce04gRI/TUU0/p3nvv1YYNG6I1X//617V69WoVFRXd8LN79+6trKys6Cs1NTXe7icUm+8BAOCcuEJNc3OzqqurY8KHYRgqKipSVVVVp+dUVVVdE1aKi4uvW38jmzdv1oABAzRy5EgtX75cly5dum5tU1OTgsFgzCvR2h9oSaoBACDZPPEUnzt3TqFQSJmZmTHHMzMzdezYsU7PCQQCndYHAoG4OvrVr35Vd911l7Kzs/Xmm2/qiSee0PHjx7Vjx45O68vKyvTd7343rs+4VTzQEgAA58QVapy0YMGC6J9HjRqlQYMGafLkyXr33Xf1yU9+8pr65cuXq7S0NPr3YDConJychPaxfU0NoQYAgGSLK9QMGDBAbrdbdXV1Mcfr6uqUlZXV6TlZWVlx1XdVQUGBJOmPf/xjp6HG5/PJ5/Pd0mfEK7r5HqEGAICki2tNjdfr1dixY1VZWRk9ZpqmKisrVVhY2Ok5hYWFMfWSVFFRcd36rorc9j1o0KBbasdO7WtqCDUAACRb3JefSktLNWfOHOXn52v8+PFav369GhsbNXfuXEnS7NmzNXjwYJWVlUmSFi9erEmTJmndunWaOnWqtm7dqkOHDmnTpk3RNs+fP6/a2lqdOnVKknT8+HFJit7l9O6772rLli166KGHlJGRoTfffFNLly7VX//1X+uee+655UGwC2tqAABwTtyhZvr06Tp79qxWr16tQCCgvLw87dmzJ7oYuLa2VobRPgE0ceJEbdmyRStXrtSKFSuUm5urnTt3auTIkdGaV155JRqKJGnGjBmSpDVr1ujJJ5+U1+vVq6++Gg1QOTk5mjZtmlauXHnTXzwRmKkBAMA5LsvqGQ8qCgaDSktLU0NDQ8L2t1nx899py/5aLS36tBYX5SbkMwAA6Eni+f3Ns59sxAMtAQBwDqHGRm423wMAwDGEGhu5WSgMAIBjCDU2ckc23wsRagAASDZCjY1YUwMAgHMINTZiR2EAAJxDqLERa2oAAHAOocZGHtbUAADgGEKNjSK3dDNTAwBA8hFqbBRZKGyyUBgAgKQj1NiIB1oCAOAcQo2Nomtq2FEYAICkI9TYKLqmhoXCAAAkHaHGRqypAQDAOYQaG0U232NNDQAAyUeosZG7bTTZURgAgOQj1NgoOlPDmhoAAJKOUGOj6AMtmakBACDpCDU2cvOUbgAAHEOosREPtAQAwDmEGhu52XwPAADHEGps5GHzPQAAHEOosZGbzfcAAHAMocZGHjbfAwDAMYQaG7H5HgAAziHU2IjN9wAAcA6hxkY80BIAAOcQamwUWSjMmhoAAJKPUGMjN49JAADAMYQaG0VnakJsvgcAQLIRamzEAy0BAHAOocZGPNASAADnEGpsFNl8j5kaAACSj1Bjo7ZMw91PAAA4gFBjo8hMjWVJJsEGAICkItTYKLKmRmJdDQAAyUaosZGnY6hhpgYAgKQi1Nio40wN62oAAEguQo2NYi4/8VBLAACSilBjI7er40wNuwoDAJBMhBobGYZLkckaFgoDAJBchBqb8VBLAACcQaixWftDLQk1AAAk002Fmo0bN2ro0KHy+/0qKCjQgQMHbli/fft2DR8+XH6/X6NGjdLu3btj3t+xY4cefPBBZWRkyOVy6ciRI9e0ceXKFT366KPKyMhQ3759NW3aNNXV1d1M9xOKRyUAAOCMuEPNtm3bVFpaqjVr1qimpkajR49WcXGxzpw502n9vn37NHPmTM2bN0+HDx9WSUmJSkpKdPTo0WhNY2Oj7r//fv3gBz+47ucuXbpUv/jFL7R9+3a9/vrrOnXqlL70pS/F2/2E46GWAAA4w2VZ8f32LSgo0Lhx47RhwwZJkmmaysnJ0aJFi7Rs2bJr6qdPn67Gxkbt2rUremzChAnKy8tTeXl5TO3777+vYcOG6fDhw8rLy4seb2ho0Cc+8Qlt2bJFX/7ylyVJx44d04gRI1RVVaUJEyZ8ZL+DwaDS0tLU0NCg1NTUeL5yXMY+VaE/Nzbr/y39a306s1/CPgcAgJ4gnt/fcc3UNDc3q7q6WkVFRe0NGIaKiopUVVXV6TlVVVUx9ZJUXFx83frOVFdXq6WlJaad4cOHa8iQIXG1kwwGa2oAAHCEJ57ic+fOKRQKKTMzM+Z4Zmamjh071uk5gUCg0/pAINDlzw0EAvJ6vUpPT+9yO01NTWpqaor+PRgMdvnzboWHu58AAHBEt737qaysTGlpadFXTk5OUj43evcTm+8BAJBUcYWaAQMGyO12X3PXUV1dnbKysjo9JysrK67667XR3Nys+vr6LrezfPlyNTQ0RF8nT57s8ufdishMjclCYQAAkiquUOP1ejV27FhVVlZGj5mmqcrKShUWFnZ6TmFhYUy9JFVUVFy3vjNjx45VSkpKTDvHjx9XbW3tddvx+XxKTU2NeSUDa2oAAHBGXGtqJKm0tFRz5sxRfn6+xo8fr/Xr16uxsVFz586VJM2ePVuDBw9WWVmZJGnx4sWaNGmS1q1bp6lTp2rr1q06dOiQNm3aFG3z/Pnzqq2t1alTpySFA4sUnqHJyspSWlqa5s2bp9LSUvXv31+pqalatGiRCgsLu3TnUzKxpgYAAGfEHWqmT5+us2fPavXq1QoEAsrLy9OePXuii4Fra2tlGO0TQBMnTtSWLVu0cuVKrVixQrm5udq5c6dGjhwZrXnllVeioUiSZsyYIUlas2aNnnzySUnSv/zLv8gwDE2bNk1NTU0qLi7WD3/4w5v60onkbvvurYQaAACSKu59am5Xydqn5vMvvqHffdign8wdpwc+MzBhnwMAQE+QsH1q8NGiOwqzpgYAgKQi1Nis/ZZuQg0AAMlEqLGZm4XCAAA4glBjMw8PtAQAwBGEGpu1z9SwozAAAMlEqLGZm833AABwBKHGZmy+BwCAMwg1NuPuJwAAnEGosZmnbUdhHmgJAEByEWpsxgMtAQBwBqHGZqypAQDAGYQam7GmBgAAZxBqbBaZqWFNDQAAyUWosRn71AAA4AxCjc3YURgAAGcQamzGmhoAAJxBqLEZdz8BAOAMQo3N3G2b7xFqAABILkKNzdxtI8rlJwAAkotQYzNmagAAcAahxmYeFgoDAOAIQo3NInc/mYQaAACSilBjM2ZqAABwBqHGZmy+BwCAMwg1NmPzPQAAnEGosRmb7wEA4AxCjc24pRsAAGcQamwW2XyPUAMAQHIRamwWmalhTQ0AAMlFqLEZa2oAAHAGocZmbkINAACOINTYjFADAIAzCDU2a9+nhs33AABIJkKNzVhTAwCAMwg1NotefrIINQAAJBOhxmaeyC3dIUINAADJRKixmcHmewAAOIJQYzMPj0kAAMARhBqb8ZRuAACcQaixGXc/AQDgDEKNzdh8DwAAZxBqbMblJwAAnEGosVn75Sd2FAYAIJkINTbj8hMAAM64qVCzceNGDR06VH6/XwUFBTpw4MAN67dv367hw4fL7/dr1KhR2r17d8z7lmVp9erVGjRokHr16qWioiK98847MTVDhw6Vy+WKea1du/Zmup9Q3NINAIAz4g4127ZtU2lpqdasWaOamhqNHj1axcXFOnPmTKf1+/bt08yZMzVv3jwdPnxYJSUlKikp0dGjR6M1zzzzjF544QWVl5dr//796tOnj4qLi3XlypWYtr73ve/p9OnT0deiRYvi7X7CRTbfY00NAADJFXeoee655zR//nzNnTtXd999t8rLy9W7d2+9/PLLndY///zzmjJlih577DGNGDFCTz31lO69915t2LBBUniWZv369Vq5cqW+8IUv6J577tG//uu/6tSpU9q5c2dMW/369VNWVlb01adPn/i/cYIxUwMAgDPiCjXNzc2qrq5WUVFRewOGoaKiIlVVVXV6TlVVVUy9JBUXF0fr33vvPQUCgZiatLQ0FRQUXNPm2rVrlZGRoTFjxujZZ59Va2vrdfva1NSkYDAY80oG7n4CAMAZnniKz507p1AopMzMzJjjmZmZOnbsWKfnBAKBTusDgUD0/cix69VI0re+9S3de++96t+/v/bt26fly5fr9OnTeu655zr93LKyMn33u9+N5+vZInL3kySZpiWjw98BAEDixBVqnFRaWhr98z333COv16tvfOMbKisrk8/nu6Z++fLlMecEg0Hl5OQkvJ8dQ0yraclLqAEAICniuvw0YMAAud1u1dXVxRyvq6tTVlZWp+dkZWXdsD7yM542JamgoECtra16//33O33f5/MpNTU15pUMHWdqWFcDAEDyxBVqvF6vxo4dq8rKyugx0zRVWVmpwsLCTs8pLCyMqZekioqKaP2wYcOUlZUVUxMMBrV///7rtilJR44ckWEYGjhwYDxfIeHcMTM1bMAHAECyxH35qbS0VHPmzFF+fr7Gjx+v9evXq7GxUXPnzpUkzZ49W4MHD1ZZWZkkafHixZo0aZLWrVunqVOnauvWrTp06JA2bdokSXK5XFqyZIm+//3vKzc3V8OGDdOqVauUnZ2tkpISSeHFxvv379cDDzygfv36qaqqSkuXLtXXvvY13XHHHTYNhT1i19Q42BEAAHqYuEPN9OnTdfbsWa1evVqBQEB5eXnas2dPdKFvbW2tDKN9AmjixInasmWLVq5cqRUrVig3N1c7d+7UyJEjozWPP/64GhsbtWDBAtXX1+v+++/Xnj175Pf7JYUvJW3dulVPPvmkmpqaNGzYMC1dujRmzczHBTM1AAA4w2VZVo9Y+BEMBpWWlqaGhoaEr6/5q+X/JdOSDqyYrIGp/oR+FgAA3Vk8v7959lMCRDbgY68aAACSh1CTADzUEgCA5CPUJICHUAMAQNIRahLA4FEJAAAkHaEmAZipAQAg+Qg1CdD+UEtu6QYAIFkINQkQmakh0wAAkDyEmgQwmKkBACDpCDUJwJoaAACSj1CTAG7ufgIAIOkINQkQ2VHYJNQAAJA0hJoEYKYGAIDkI9QkAI9JAAAg+Qg1CcBMDQAAyUeoSYD2u5+4pRsAgGQh1CRA++UnhzsCAEAPQqhJAB6TAABA8hFqEsDrCQ9rY1PI4Z4AANBzEGoS4DOZ/SRJR081ONwTAAB6DkJNAowZki5JOlxb72g/AADoSQg1CTBmyB2SpOOBoBqbWh3uDQAAPQOhJgEyU/0alOaXaUlvfsAlKAAAkoFQkyCRS1BHTtY72g8AAHoKQk2CjMkJX4I6XPsXh3sCAEDPQKhJkOhi4ZP1siwelwAAQKIRahJk5OA0eQyXzl5o0of1l53uDgAA3R6hJkH8KW6NGJQqiXU1AAAkA6EmgdivBgCA5CHUJFB7qGGxMAAAiUaoSaC8tjugjp4KqrmVh1sCAJBIhJoEGprRW+m9U9Tcaurt00GnuwMAQLdGqEkgl8ulMTnpkm58CcqyLB1477we2/5bfX/XW7rSwtO9AQCIl8fpDnR3Y4bcodeOn9Xhk/X6u6veO9/YrB01H+jfD9Tq3bON0eMHT/xFm74+Vpmp/qT2FQCA2xkzNQmW1zZTc/Vt3S+/8Z4m/HOlvv9fb+vds43q7XXrS2MGK713in57sl6ff/ENFhgDABAHZmoSbHRbqDnx50v688Um9e/j1Yt7/6jnKv4gSfpsdqq+WjBED4/OVj9/ik78uVHz//WQ/lB3UdP/z2/09BdH6oHhA3XxSqsuNrWqsalVlqT+fbzq38erO3p75TZczn1BAAA+Jgg1CZbWK0WfGthXfzxzUYdr63XoxF9U/vq7kqRvP/hpLfxfuTH1d2X00Y5/vE9Ltx1RxVt1euz/vnnD9l2u8GdkpfqVnd5Lg9LCPz/R1ydfiiGfx5DXY8jncSutV4oG9PUpo69XKW4m6QAA3YvL6iEPJgoGg0pLS1NDQ4NSU1OT+tnf3v5b/d/qDzQoza/TDVckSav+9m7Nu3/Ydc8xTUvrX/2Dyl//k5pDpvp43err96iPzyNZ0vlLzaq/1HLTfUrvnaI7enuV4nbJYxhK8RhKMVzq6/eof2+v0nt71b9PitJ6pSjFbcgwXPIYLrkNl3qluJXe26v03ilK75Wi1EiNK7w4GgAAu8Tz+5tQkwSb95/Qd35+VFJ4ZuXpklH6asGQLp3b3GrK3RYmrtYaMlV/uUV/vtis0w2Xdbrhik7VX9ap+iv6c2OTmltNNbeaamo11dQa0l8uteh8Y7NCZmL/k7sNl3weQ2m9wqEotVeKUv0p8npccsklV1v4SXG7lOqPvO9Rqj9FKR1qJCnFbaivz6N+fo/6+cN1Xo8hl1ySKzyeblc4aBlchgOAbiee399cfkqCcUP7S5IMl7TukdH64pg7u3yu13P9y0Qet6EBfX0a0Nenz2T161J7pmmp/nKLzl1sUv2lFrWGTDWHTLWGLLWETF1oatVfGpvDM0GNLaq/HA5BIdNSa9vPS80hNVxuUf2lZjVcbtHVGSlSc6k5FJ2ZSjSXS+Hw4/Oor98jn8cdPe6SZBgu9fa61dcXnu3q5/PIl+KWSwoXSDLawlEfn0d9fW719aXIn2K0tdFW5JL8nnA7vX3hn/4UdzSERWKVz+O+4X87AID9CDVJ8OnMfnpx5hhlpfmjAccphuGKLjK2g2lautjcKrMt8IQsS5YlXW4OKXilRQ2Xw6/g5VaFTFOmFd6Xx7Sk5pCpC1fC7wWvtCh4uUWtZvh8s62dVtPUhSutunAlXHOxqVWdzS1alqJ1arDlq92yFLdLfXwe9fF65E8xZFx1ac7rMdTb61Zvr0d9fG71SvHo6skmjztc08frVi+vR729185IedouCfbyutvac8ttxAYqt8ulXl5D/pTw5/VKccvjjm3HcHU+IwgAtwtCTZJ8fnS2011ICMMIX0JKFrMtOEnhIGMpHKYuNrXqYluouXClVS0hU5asaAAKmZYut4R0oe0usotXWtXUGoq2I0mmJV1uadXFppAuXmlRY1NIV66psXSlJaTGppAam8N3o13val5LyFL9pZZbWvuUbCluV1vwcbcFn9hw5FL4CfT+lHBA6pXiDi86d8XWeD2GeqW4Y2quXm7l9Rjye4y29txtlxWv7k/4fV+KIb8n/PPqGo87vCDen+KOLoy/OkCy3gvoGQg1uK0YhkvX/lqTens9Gti1K3C2sixLzSGz7c/tx5taTDU2t+pSc6sam8KX4qRwCGv7g5pDpi41h9TY1KrLLeGaSFCLaGm1dKmlVZebw0HqSktI5lVTVS0hS5dbWnWpOaTLbZf9rq6JhLrLzSE13eA5ZC0hSy2hthmvbsbnCYcfX1v4uTr4RNaC+druFvR6jGtmxQyX2oKTO1p79eyW0bZeLNJGZzUul0tet0vethDmdbvlNlzRy6WRdjxtNb6ra6KXO9tq3OF2UtyGPG6XDFf4gqnL1T4D5zFcBDt0e4Qa4Ba4XK7o+p2O/ClupfVO3gxWPCIB5+oF46Zp6UprOPhEAlBrJzVNraautLTVtITUclVIshRe4H65JaQrLeHaSPCL1ljhmiutIV1pDs+IXf3QV8uSWkxLTS2h6GdeHcgsy1JrKNynqz/jak1ti+bVDQNbV3nbQk+KOxy0woFH8hhGNPi4O7wioSi89swltys8MxapS3EbbeGpPZBFzg3XhGvDV0PbayKBzWO4ou25OgQxl1wyXJLb7ZK7QygzDFfM5xmutjrDkNtoD3CR4y5X+3c0XOE7PQ1DHUJfOOS5XIp+hsfoEAyvWivX/t2M9jHq0Ge51NaftjF0RcaRMJkshBqgh3EbLvX1db//6YdMq+1uv9A1665aTUtNrbHh6OqajudH7hqMrO2K1lhW9L1IbTT3tRWGLEstofa2mlpNmW1FkVLTklragljkLsVW07ympjXyfihSE+mP1TarJ7WEzLaX9ZF3NjaHTIUnDXm+nBMioc7lig09hqttFrpD2IqEo0hQiwSocEMd2nG52s5tr+8Y+CJtGR0CltEhrLk61EX709ZebGBtD4eutqDo6hBUI8HtkwP76usT7kryyLa7qX/ZNm7cqGeffVaBQECjR4/Wiy++qPHjx1+3fvv27Vq1apXef/995ebm6gc/+IEeeuih6PuWZWnNmjX60Y9+pPr6et1333166aWXlJvbvjHd+fPntWjRIv3iF7+QYRiaNm2ann/+efXt2/dmvgKAbsZtuNTLG14w3VOF71IMB7bIpUzTkkIhSy1mW/hpDV8yNS0remdjZJF/yAzPfEXbUfjf50h7kZqWkBmtjXxGZIF/x3Yjd0yaptXWVlufOrzXEgp/VuSSaSSsWVZ7G6ZpqcW0YvpiWlb0xoNWM/y5raG2NXcd+2IpeiNDpG+m1XaRt+NntZ0f6VdrKDZkRtps7fDd4hX5brI+OoDerv7605+4vULNtm3bVFpaqvLychUUFGj9+vUqLi7W8ePHNXDgwGvq9+3bp5kzZ6qsrEx/+7d/qy1btqikpEQ1NTUaOXKkJOmZZ57RCy+8oJ/97GcaNmyYVq1apeLiYr311lvy+8MPdZw1a5ZOnz6tiooKtbS0aO7cuVqwYIG2bNlyi0MAAN1D+P/R99xQl2ztYa09tEXCVCSMtc+uta+XM81wQDRjAtK14TBSFwliavuMyPZy5lVBMnKOaVkdgmF7jWWFg2/HPqtDQIz0yewQujqGYzPa58gdqu3fO/L9hmb0Sc7gX0fcm+8VFBRo3Lhx2rBhgyTJNE3l5ORo0aJFWrZs2TX106dPV2Njo3bt2hU9NmHCBOXl5am8vFyWZSk7O1v/9E//pG9/+9uSpIaGBmVmZuqnP/2pZsyYobffflt33323Dh48qPz8fEnSnj179NBDD+mDDz5QdvZH31nk5OZ7AADg5sTz+zuu3cGam5tVXV2toqKi9gYMQ0VFRaqqqur0nKqqqph6SSouLo7Wv/feewoEAjE1aWlpKigoiNZUVVUpPT09GmgkqaioSIZhaP/+/Z1+blNTk4LBYMwLAAB0X3GFmnPnzikUCikzMzPmeGZmpgKBQKfnBAKBG9ZHfn5UzdWXtjwej/r373/dzy0rK1NaWlr0lZOT08VvCQAAbkfddh/35cuXq6GhIfo6efKk010CAAAJFFeoGTBggNxut+rq6mKO19XVKSsrq9NzsrKyblgf+flRNWfOnIl5v7W1VefPn7/u5/p8PqWmpsa8AABA9xVXqPF6vRo7dqwqKyujx0zTVGVlpQoLCzs9p7CwMKZekioqKqL1w4YNU1ZWVkxNMBjU/v37ozWFhYWqr69XdXV1tGbv3r0yTVMFBQXxfAUAANBNxX1Ld2lpqebMmaP8/HyNHz9e69evV2Njo+bOnStJmj17tgYPHqyysjJJ0uLFizVp0iStW7dOU6dO1datW3Xo0CFt2rRJUnjDniVLluj73/++cnNzo7d0Z2dnq6SkRJI0YsQITZkyRfPnz1d5eblaWlq0cOFCzZgxo0t3PgEAgO4v7lAzffp0nT17VqtXr1YgEFBeXp727NkTXehbW1sro8MTgidOnKgtW7Zo5cqVWrFihXJzc7Vz587oHjWS9Pjjj6uxsVELFixQfX297r//fu3Zsye6R40kbd68WQsXLtTkyZOjm++98MILt/LdAQBANxL3PjW3K/apAQDg9pOwfWoAAAA+rgg1AACgWyDUAACAboFQAwAAugVCDQAA6BbivqX7dhW5yYsHWwIAcPuI/N7uys3aPSbUXLhwQZJ4sCUAALehCxcuKC0t7YY1PWafGtM0derUKfXr108ul8vWtoPBoHJycnTy5En2wEkwxjp5GOvkYayTh7FOHrvG2rIsXbhwQdnZ2TGb+3amx8zUGIahO++8M6GfwYMzk4exTh7GOnkY6+RhrJPHjrH+qBmaCBYKAwCAboFQAwAAugVCjQ18Pp/WrFkjn8/ndFe6PcY6eRjr5GGsk4exTh4nxrrHLBQGAADdGzM1AACgWyDUAACAboFQAwAAugVCDQAA6BYINbdo48aNGjp0qPx+vwoKCnTgwAGnu3TbKysr07hx49SvXz8NHDhQJSUlOn78eEzNlStX9OijjyojI0N9+/bVtGnTVFdX51CPu4+1a9fK5XJpyZIl0WOMtX0+/PBDfe1rX1NGRoZ69eqlUaNG6dChQ9H3LcvS6tWrNWjQIPXq1UtFRUV65513HOzx7SkUCmnVqlUaNmyYevXqpU9+8pN66qmnYp4dxFjfvF/96lf6/Oc/r+zsbLlcLu3cuTPm/a6M7fnz5zVr1iylpqYqPT1d8+bN08WLF2+9cxZu2tatWy2v12u9/PLL1u9//3tr/vz5Vnp6ulVXV+d0125rxcXF1k9+8hPr6NGj1pEjR6yHHnrIGjJkiHXx4sVozTe/+U0rJyfHqqystA4dOmRNmDDBmjhxooO9vv0dOHDAGjp0qHXPPfdYixcvjh5nrO1x/vx566677rL+7u/+ztq/f7/1pz/9yfqf//kf649//GO0Zu3atVZaWpq1c+dO67e//a318MMPW8OGDbMuX77sYM9vP08//bSVkZFh7dq1y3rvvfes7du3W3379rWef/75aA1jffN2795tfec737F27NhhSbJ+/vOfx7zflbGdMmWKNXr0aOs3v/mN9etf/9r61Kc+Zc2cOfOW+0aouQXjx4+3Hn300ejfQ6GQlZ2dbZWVlTnYq+7nzJkzliTr9ddftyzLsurr662UlBRr+/bt0Zq3337bkmRVVVU51c3b2oULF6zc3FyroqLCmjRpUjTUMNb2eeKJJ6z777//uu+bpmllZWVZzz77bPRYfX295fP5rH//939PRhe7jalTp1p///d/H3PsS1/6kjVr1izLshhrO10daroytm+99ZYlyTp48GC05r//+78tl8tlffjhh7fUHy4/3aTm5mZVV1erqKgoeswwDBUVFamqqsrBnnU/DQ0NkqT+/ftLkqqrq9XS0hIz9sOHD9eQIUMY+5v06KOPaurUqTFjKjHWdnrllVeUn5+vr3zlKxo4cKDGjBmjH/3oR9H333vvPQUCgZixTktLU0FBAWMdp4kTJ6qyslJ/+MMfJEm//e1v9cYbb+hv/uZvJDHWidSVsa2qqlJ6erry8/OjNUVFRTIMQ/v377+lz+8xD7S027lz5xQKhZSZmRlzPDMzU8eOHXOoV92PaZpasmSJ7rvvPo0cOVKSFAgE5PV6lZ6eHlObmZmpQCDgQC9vb1u3blVNTY0OHjx4zXuMtX3+9Kc/6aWXXlJpaalWrFihgwcP6lvf+pa8Xq/mzJkTHc/O/k1hrOOzbNkyBYNBDR8+XG63W6FQSE8//bRmzZolSYx1AnVlbAOBgAYOHBjzvsfjUf/+/W95/Ak1+Fh79NFHdfToUb3xxhtOd6VbOnnypBYvXqyKigr5/X6nu9Otmaap/Px8/fM//7MkacyYMTp69KjKy8s1Z84ch3vXvfzHf/yHNm/erC1btuizn/2sjhw5oiVLlig7O5ux7ua4/HSTBgwYILfbfc1dIHV1dcrKynKoV93LwoULtWvXLr322mu68847o8ezsrLU3Nys+vr6mHrGPn7V1dU6c+aM7r33Xnk8Hnk8Hr3++ut64YUX5PF4lJmZyVjbZNCgQbr77rtjjo0YMUK1tbWSFB1P/k25dY899piWLVumGTNmaNSoUfr617+upUuXqqysTBJjnUhdGdusrCydOXMm5v3W1ladP3/+lsefUHOTvF6vxo4dq8rKyugx0zRVWVmpwsJCB3t2+7MsSwsXLtTPf/5z7d27V8OGDYt5f+zYsUpJSYkZ++PHj6u2tpaxj9PkyZP1u9/9TkeOHIm+8vPzNWvWrOifGWt73HfffddsTfCHP/xBd911lyRp2LBhysrKihnrYDCo/fv3M9ZxunTpkgwj9teb2+2WaZqSGOtE6srYFhYWqr6+XtXV1dGavXv3yjRNFRQU3FoHbmmZcQ+3detWy+fzWT/96U+tt956y1qwYIGVnp5uBQIBp7t2W/uHf/gHKy0tzfrlL39pnT59Ovq6dOlStOab3/ymNWTIEGvv3r3WoUOHrMLCQquwsNDBXncfHe9+sizG2i4HDhywPB6P9fTTT1vvvPOOtXnzZqt3797Wv/3bv0Vr1q5da6Wnp1v/+Z//ab355pvWF77wBW4zvglz5syxBg8eHL2le8eOHdaAAQOsxx9/PFrDWN+8CxcuWIcPH7YOHz5sSbKee+456/Dhw9aJEycsy+ra2E6ZMsUaM2aMtX//fuuNN96wcnNzuaX74+DFF1+0hgwZYnm9Xmv8+PHWb37zG6e7dNuT1OnrJz/5SbTm8uXL1j/+4z9ad9xxh9W7d2/ri1/8onX69GnnOt2NXB1qGGv7/OIXv7BGjhxp+Xw+a/jw4damTZti3jdN01q1apWVmZlp+Xw+a/Lkydbx48cd6u3tKxgMWosXL7aGDBli+f1+66/+6q+s73znO1ZTU1O0hrG+ea+99lqn/0bPmTPHsqyuje2f//xna+bMmVbfvn2t1NRUa+7cudaFCxduuW8uy+qwxSIAAMBtijU1AACgWyDUAACAboFQAwAAugVCDQAA6BYINQAAoFsg1AAAgG6BUAMAALoFQg0AAOgWCDUAAKBbINQAAIBugVADAAC6BUINAADoFv5/kzdAGhhJYlkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75696163e+06 -3.64057635e+05 -1.38000000e-01  8.54600000e+00\n",
      "  7.75692823e+06 -3.64053126e+05 -1.32000000e-01  8.49100000e+00\n",
      " -2.00000000e-03] -> [ 8.4910440e+00 -2.1275878e-03  2.0009704e-02] (expected [ 8.491e+00 -2.000e-03  2.000e-02])\n",
      "[ 7.75720516e+06 -3.63589039e+05 -2.53100000e+00  8.55000000e+00\n",
      "  7.75723371e+06 -3.63569516e+05 -2.49900000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609583e+00 -6.1482787e-03  2.0036645e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75717733e+06 -3.63615552e+05  1.04800000e+00  4.16700000e+00\n",
      "  7.75716855e+06 -3.63636256e+05  1.09200000e+00  5.54400000e+00\n",
      "  6.30000000e-02] -> [5.5442753  0.06288677 0.02018113] (expected [5.544 0.063 0.02 ])\n",
      "[ 7.75719467e+06 -3.63595825e+05 -2.57200000e+00  8.52500000e+00\n",
      "  7.75722353e+06 -3.63576869e+05 -2.54100000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609735e+00 -6.1470866e-03  2.0041056e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75663871e+06 -3.63686725e+05 -2.46600000e+00  8.55000000e+00\n",
      "  7.75666680e+06 -3.63666710e+05 -2.61800000e+00  8.69300000e+00\n",
      "  2.20000000e-02] -> [8.693061   0.02189618 0.01997633] (expected [8.693 0.022 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU COM 3 SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,3))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 3)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 3)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 3)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end]  # Modify this line\n",
    "            y_batch = y_train[start:end]  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75655038e+06 -3.63917271e+05 -2.31000000e-01  5.70200000e+00\n",
      "  7.75653753e+06 -3.63908823e+05 -8.46000000e-01  4.40600000e+00\n",
      "  7.50000000e-02] -> [4.3999896] (expected [4.406])\n",
      "[ 7.75766160e+06 -3.63610685e+05 -2.50900000e+00  8.55000000e+00\n",
      "  7.75768651e+06 -3.63592380e+05 -2.50700000e+00  7.70300000e+00\n",
      " -2.00000000e-03] -> [7.704249] (expected [7.703])\n",
      "[ 7.75754790e+06 -3.63656925e+05 -3.13600000e+00  8.55000000e+00\n",
      "  7.75757851e+06 -3.63654357e+05 -2.96700000e+00  7.70300000e+00\n",
      " -1.50000000e-02] -> [7.705766] (expected [7.703])\n",
      "[ 7.75769361e+06 -3.63590014e+05  6.39000000e-01  8.55000000e+00\n",
      "  7.75766713e+06 -3.63610291e+05  6.52000000e-01  8.52900000e+00\n",
      "  3.00000000e-03] -> [8.52703] (expected [8.529])\n",
      "[ 7.75685868e+06 -3.64044085e+05 -1.26000000e-01  8.55000000e+00\n",
      "  7.75682885e+06 -3.64038885e+05 -1.75000000e-01  7.65400000e+00\n",
      "  1.00000000e-03] -> [7.647367] (expected [7.654])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU (uma saida)\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,1))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 1)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Criando o modelo \n",
    "l0 = tf.keras.layers.Dense(units = 9, input_shape = [9])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 64)\n",
    "#l3 = tf.keras.layers.Dense(units = 93)\n",
    "l3 = tf.keras.layers.Dense(units = 3)\n",
    "\n",
    "\"\"\"Modelo inicial: \n",
    "l0 = tf.keras.layers.Dense(units = 4, input_shape = [4])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 128)\n",
    "l3 = tf.keras.layers.Dense(units = 3) \"\"\"\n",
    "\n",
    "model = tf.keras.Sequential([l0,l1,l2,l3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compilando o modelo\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizers.RMSprop(lr=1e-4))#tf.keras.optimizers.Adam(0.1)), loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Treinar o modelo\n",
    "history = model.fit(inputMatrix,outputMatrix,epochs=500,verbose=False)#epochs inicial=500\n",
    "print(\"Finished training the model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
