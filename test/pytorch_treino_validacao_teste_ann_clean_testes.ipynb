{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "#Importar bibliotecas\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar vari√°veis\n",
    "dataset_input = \"bin/dataset_input_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\"\n",
    "dataset_output = \"bin/dataset_output_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75775097e+06 -3.63847325e+05 -2.48500000e+00  2.50000000e+00\n",
      "  7.75775911e+06 -3.63841075e+05 -2.48500000e+00  2.90200000e+00\n",
      " -0.00000000e+00] -> [ 2.9397252e+00 -2.3047924e-03  2.0966640e-02  2.9720433e+00\n",
      " -2.6154909e-03  1.9926040e-02  2.9604981e+00 -2.1946505e-03\n",
      "  2.0696519e-02  2.9628859e+00 -3.6121085e-03  2.0968683e-02\n",
      "  2.9365561e+00 -2.8319731e-03  1.9573994e-02  2.9441931e+00\n",
      " -2.8028302e-03  1.9509077e-02  2.9375508e+00 -3.3364445e-03\n",
      "  1.9414768e-02  2.9367454e+00 -3.0968785e-03  2.0138573e-02\n",
      "  2.9219844e+00 -2.5715115e-03  1.9720219e-02  2.9214840e+00\n",
      " -2.5290102e-03  2.0405781e-02  2.9070289e+00 -3.3864044e-03\n",
      "  1.9110646e-02  2.9217083e+00 -3.8477331e-03  1.9473320e-02\n",
      "  2.9132512e+00 -3.9473400e-03  1.9838329e-02  2.8971634e+00\n",
      " -4.0678978e-03  2.0167034e-02  2.8905468e+00 -4.0164590e-03\n",
      "  2.0878654e-02  2.8951602e+00 -3.6973134e-03  2.0209044e-02\n",
      "  2.8841181e+00 -2.8151814e-03  2.0413183e-02  2.8943346e+00\n",
      " -4.9759299e-03  2.0079246e-02  2.8749690e+00 -4.8078895e-03\n",
      "  2.0748233e-02  2.8824086e+00 -3.6349744e-03  2.0849898e-02\n",
      "  2.8824382e+00 -4.9284375e-03  1.9791167e-02  2.8756773e+00\n",
      " -5.3956248e-03  2.0057023e-02  2.8672979e+00 -5.7721213e-03\n",
      "  2.0183813e-02  2.8540988e+00 -4.2335941e-03  1.9812379e-02\n",
      "  2.8531437e+00 -5.3978413e-03  2.0334754e-02  2.8531671e+00\n",
      " -4.8360340e-03  1.9214511e-02  2.8354177e+00 -5.9865117e-03\n",
      "  1.9709297e-02  2.8469546e+00 -6.0077310e-03  1.9803897e-02\n",
      "  2.8324780e+00 -5.0314218e-03  1.8863626e-02  2.8241422e+00\n",
      " -5.0429255e-03  1.9120716e-02  2.8242829e+00 -3.7319399e-03\n",
      "  1.9818794e-02  2.8281336e+00 -5.2742586e-03  2.1239458e-02\n",
      "  2.8206024e+00 -4.3247193e-03  1.9223440e-02  2.8118896e+00\n",
      " -4.1854028e-03  1.9182157e-02  2.8113236e+00 -6.2973052e-03\n",
      "  1.8800166e-02  2.7948489e+00 -4.2813420e-03  2.0583969e-02\n",
      "  2.7870936e+00 -4.6494529e-03  2.1386314e-02  2.7962773e+00\n",
      " -2.3495257e-03  2.0454546e-02  2.7809346e+00 -3.5049617e-03\n",
      "  1.9478217e-02  2.7729084e+00 -4.7614276e-03  2.1791764e-02\n",
      "  2.7747879e+00 -4.1897595e-03  1.9163869e-02  2.7702494e+00\n",
      " -3.6979765e-03  1.9672435e-02  2.7718196e+00 -2.4117529e-03\n",
      "  1.9438190e-02  2.7599578e+00 -2.8711632e-03  1.9550480e-02\n",
      "  2.7662549e+00 -2.9222667e-03  2.0171011e-02  2.7595050e+00\n",
      " -2.4383441e-03  2.0423537e-02  2.7518756e+00 -2.3965016e-03\n",
      "  1.9804947e-02  2.7534835e+00 -2.9281080e-03  1.9082837e-02\n",
      "  2.7501199e+00 -3.4224242e-04  2.0262338e-02  2.7303045e+00\n",
      " -2.8864592e-03  1.9236963e-02] (expected [ 2.902e+00 -0.000e+00  2.000e-02  2.900e+00 -0.000e+00  2.000e-02\n",
      "  2.898e+00 -0.000e+00  2.000e-02  2.896e+00 -1.000e-03  2.000e-02\n",
      "  2.894e+00 -1.000e-03  2.000e-02  2.892e+00 -1.000e-03  2.000e-02\n",
      "  2.890e+00 -1.000e-03  2.000e-02  2.888e+00 -1.000e-03  2.000e-02\n",
      "  2.885e+00 -1.000e-03  2.000e-02  2.883e+00 -1.000e-03  2.000e-02\n",
      "  2.881e+00 -1.000e-03  2.000e-02  2.879e+00 -1.000e-03  2.000e-02\n",
      "  2.877e+00 -1.000e-03  2.000e-02  2.875e+00 -2.000e-03  2.000e-02\n",
      "  2.873e+00 -2.000e-03  2.000e-02  2.871e+00 -2.000e-03  2.000e-02\n",
      "  2.869e+00 -2.000e-03  2.000e-02  2.867e+00 -2.000e-03  2.000e-02\n",
      "  2.865e+00 -2.000e-03  2.000e-02  2.863e+00 -2.000e-03  2.000e-02\n",
      "  2.861e+00 -2.000e-03  2.000e-02  2.859e+00 -2.000e-03  2.000e-02\n",
      "  2.857e+00 -2.000e-03  2.000e-02  2.855e+00 -2.000e-03  2.000e-02\n",
      "  2.853e+00 -2.000e-03  2.000e-02  2.851e+00 -3.000e-03  2.000e-02\n",
      "  2.849e+00 -3.000e-03  2.000e-02  2.847e+00 -3.000e-03  2.000e-02\n",
      "  2.845e+00 -3.000e-03  2.000e-02  2.843e+00 -3.000e-03  2.000e-02\n",
      "  2.841e+00 -3.000e-03  2.000e-02  2.839e+00 -3.000e-03  2.000e-02\n",
      "  2.837e+00 -3.000e-03  2.000e-02  2.835e+00 -3.000e-03  2.000e-02\n",
      "  2.833e+00 -3.000e-03  2.000e-02  2.831e+00 -3.000e-03  2.000e-02\n",
      "  2.829e+00 -3.000e-03  2.000e-02  2.827e+00 -3.000e-03  2.000e-02\n",
      "  2.825e+00 -3.000e-03  2.000e-02  2.823e+00 -3.000e-03  2.000e-02\n",
      "  2.821e+00 -3.000e-03  2.000e-02  2.819e+00 -3.000e-03  2.000e-02\n",
      "  2.817e+00 -3.000e-03  2.000e-02  2.815e+00 -3.000e-03  2.000e-02\n",
      "  2.813e+00 -3.000e-03  2.000e-02  2.811e+00 -3.000e-03  2.000e-02\n",
      "  2.809e+00 -3.000e-03  2.000e-02  2.807e+00 -3.000e-03  2.000e-02\n",
      "  2.805e+00 -3.000e-03  2.000e-02  2.803e+00 -3.000e-03  2.000e-02])\n",
      "[ 7.75667604e+06 -3.63661884e+05 -2.73100000e+00  8.55000000e+00\n",
      "  7.75670946e+06 -3.63652581e+05 -3.01400000e+00  8.69300000e+00\n",
      "  1.90000000e-02] -> [8.69172    0.01784432 0.02096539 8.654386   0.01804133 0.01931067\n",
      " 8.65204    0.01831137 0.02123451 8.653172   0.01766842 0.02051342\n",
      " 8.64389    0.01819182 0.02003837 8.647608   0.0188789  0.02024546\n",
      " 8.6472435  0.01783805 0.01896752 8.64614    0.01833811 0.01946653\n",
      " 8.641935   0.01879699 0.01905971 8.642813   0.01841678 0.01948571\n",
      " 8.637575   0.01813499 0.01947215 8.642258   0.01796095 0.01979796\n",
      " 8.640351   0.01777653 0.0206381  8.635675   0.01777303 0.01964305\n",
      " 8.635652   0.01800692 0.01983766 8.636249   0.0180197  0.01989429\n",
      " 8.634016   0.01852257 0.02060055 8.636439   0.01720755 0.02003226\n",
      " 8.631058   0.0170449  0.02115873 8.633795   0.01788475 0.02099951\n",
      " 8.632956   0.01668549 0.02015714 8.631986   0.01622012 0.01924843\n",
      " 8.630677   0.01566666 0.02041336 8.625152   0.01621819 0.01990962\n",
      " 8.624811   0.01529954 0.01989687 8.624509   0.01574208 0.01990414\n",
      " 8.6206     0.01461959 0.01953381 8.625209   0.01509595 0.0208341\n",
      " 8.62081    0.01520096 0.01900858 8.61836    0.01448838 0.01883187\n",
      " 8.617711   0.01566174 0.01953136 8.619467   0.01462922 0.02064198\n",
      " 8.6168995  0.01528652 0.0188628  8.6153965  0.01618162 0.01973815\n",
      " 8.614622   0.01406483 0.01982155 8.6093445  0.01490444 0.02067302\n",
      " 8.608489   0.01546294 0.02053611 8.610778   0.01608166 0.02096524\n",
      " 8.6057415  0.01561916 0.02039449 8.604337   0.01440439 0.02074248\n",
      " 8.603874   0.01465607 0.01975002 8.604069   0.01584758 0.02049689\n",
      " 8.604602   0.01563832 0.02021207 8.601095   0.01475816 0.01974861\n",
      " 8.601725   0.01484066 0.01923316 8.600682   0.01501911 0.02050084\n",
      " 8.5992365  0.01623877 0.02049989 8.599528   0.01601377 0.02020662\n",
      " 8.598716   0.01645566 0.01981837 8.592672   0.01588531 0.01982633] (expected [8.693 0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02\n",
      " 8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02\n",
      " 8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02\n",
      " 8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02\n",
      " 8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.021 0.02  8.55  0.021 0.02 ])\n",
      "[ 7.75787215e+06 -3.63570884e+05 -7.23000000e-01  8.55000000e+00\n",
      "  7.75784805e+06 -3.63549462e+05 -7.22000000e-01  8.12500000e+00\n",
      " -2.00000000e-03] -> [ 8.1708298e+00  1.0594130e-03  1.9673279e-02  8.1367073e+00\n",
      "  8.4598921e-04  2.0855499e-02  8.1403408e+00 -2.1088868e-04\n",
      "  2.0052670e-02  8.1440153e+00  2.6009604e-03  1.7253764e-02\n",
      "  8.1458673e+00  2.2726133e-03  2.0428665e-02  8.1496305e+00\n",
      "  6.6264346e-04  2.0627290e-02  8.1510582e+00  2.1750480e-03\n",
      "  2.0275608e-02  8.1550932e+00  1.7453730e-03  1.9853007e-02\n",
      "  8.1567345e+00  6.9451053e-05  2.0087950e-02  8.1602154e+00\n",
      " -3.5534799e-04  2.0430680e-02  8.1637688e+00  2.8663017e-03\n",
      "  2.2040870e-02  8.1678019e+00  4.0309131e-04  2.0690000e-02\n",
      "  8.1683397e+00  2.3273379e-04  2.0397928e-02  8.1732626e+00\n",
      "  2.4402142e-04  1.9507628e-02  8.1749611e+00  1.9335747e-03\n",
      "  1.9648712e-02  8.1790228e+00  5.2549690e-04  1.9624278e-02\n",
      "  8.1799021e+00 -1.7310921e-03  1.9782774e-02  8.1843529e+00\n",
      "  1.0773391e-03  1.9658512e-02  8.1875763e+00  1.9836426e-03\n",
      "  1.9820487e-02  8.1893778e+00 -4.0934980e-04  1.8857673e-02\n",
      "  8.1945896e+00  5.6785578e-04  2.0494323e-02  8.1942539e+00\n",
      "  1.5058741e-04  2.0370362e-02  8.1985102e+00  8.1139058e-04\n",
      "  2.0033974e-02  8.1998129e+00  4.2800792e-05  2.0218138e-02\n",
      "  8.2036123e+00  1.1968464e-03  1.9615892e-02  8.2084532e+00\n",
      " -9.2301890e-04  2.0810485e-02  8.2085772e+00  2.1135807e-04\n",
      "  2.0298056e-02  8.2121096e+00 -4.9066544e-04  2.0591751e-02\n",
      "  8.2140665e+00 -1.3572127e-03  2.1175332e-02  8.2186909e+00\n",
      " -5.8527291e-04  2.0271204e-02  8.2208652e+00 -3.0007102e-03\n",
      "  2.0116646e-02  8.2246952e+00 -8.5773319e-04  1.8061576e-02\n",
      "  8.2248688e+00 -2.0205230e-03  2.0138342e-02  8.2294083e+00\n",
      " -1.7550830e-03  2.0553898e-02  8.2314835e+00  1.2793988e-03\n",
      "  2.2876170e-02  8.2360878e+00 -7.0089102e-04  1.9105654e-02\n",
      "  8.2375116e+00 -4.1740388e-04  1.7049480e-02  8.2402830e+00\n",
      " -1.7930567e-03  1.9281050e-02  8.2445936e+00 -4.6026707e-04\n",
      "  2.0402953e-02  8.2448835e+00  8.4123015e-04  1.8625326e-02\n",
      "  8.2475262e+00  5.0425529e-04  2.2314690e-02  8.2508545e+00\n",
      " -3.7132204e-04  1.9878905e-02  8.2536812e+00 -8.3914399e-04\n",
      "  1.9171489e-02  8.2578402e+00  4.2086095e-04  2.0390667e-02\n",
      "  8.2602959e+00  7.2878599e-04  1.9680196e-02  8.2625771e+00\n",
      "  7.3640794e-04  1.9774860e-02  8.2654428e+00  1.1023134e-04\n",
      "  1.9736417e-02  8.2686977e+00  7.6285005e-04  2.0709448e-02\n",
      "  8.2730961e+00  5.0259382e-04  1.9774921e-02  8.2744856e+00\n",
      "  1.8534213e-03  2.0681065e-02] (expected [ 8.125e+00 -2.000e-03  2.000e-02  8.127e+00 -2.000e-03  2.000e-02\n",
      "  8.129e+00 -2.000e-03  2.000e-02  8.132e+00 -3.000e-03  2.000e-02\n",
      "  8.134e+00 -3.000e-03  2.000e-02  8.136e+00 -3.000e-03  2.000e-02\n",
      "  8.138e+00 -3.000e-03  2.000e-02  8.140e+00 -3.000e-03  2.000e-02\n",
      "  8.142e+00 -3.000e-03  2.000e-02  8.145e+00 -3.000e-03  2.000e-02\n",
      "  8.147e+00 -3.000e-03  2.000e-02  8.149e+00 -3.000e-03  2.000e-02\n",
      "  8.151e+00 -3.000e-03  2.000e-02  8.153e+00 -3.000e-03  2.000e-02\n",
      "  8.155e+00 -3.000e-03  2.000e-02  8.158e+00 -3.000e-03  2.000e-02\n",
      "  8.160e+00 -3.000e-03  2.000e-02  8.162e+00 -3.000e-03  2.000e-02\n",
      "  8.164e+00 -3.000e-03  2.000e-02  8.166e+00 -3.000e-03  2.000e-02\n",
      "  8.168e+00 -3.000e-03  2.000e-02  8.171e+00 -3.000e-03  2.000e-02\n",
      "  8.173e+00 -3.000e-03  2.000e-02  8.175e+00 -3.000e-03  2.000e-02\n",
      "  8.177e+00 -3.000e-03  2.000e-02  8.179e+00 -3.000e-03  2.000e-02\n",
      "  8.181e+00 -3.000e-03  2.000e-02  8.184e+00 -3.000e-03  2.000e-02\n",
      "  8.186e+00 -3.000e-03  2.000e-02  8.188e+00 -3.000e-03  2.000e-02\n",
      "  8.190e+00 -3.000e-03  2.000e-02  8.192e+00 -3.000e-03  2.000e-02\n",
      "  8.194e+00 -3.000e-03  2.000e-02  8.197e+00 -3.000e-03  2.000e-02\n",
      "  8.199e+00 -3.000e-03  2.000e-02  8.201e+00 -3.000e-03  2.000e-02\n",
      "  8.203e+00 -3.000e-03  2.000e-02  8.205e+00 -3.000e-03  2.000e-02\n",
      "  8.207e+00 -3.000e-03  2.000e-02  8.209e+00 -3.000e-03  2.000e-02\n",
      "  8.212e+00 -3.000e-03  2.000e-02  8.214e+00 -3.000e-03  2.000e-02\n",
      "  8.216e+00 -3.000e-03  2.000e-02  8.218e+00 -3.000e-03  2.000e-02\n",
      "  8.220e+00 -3.000e-03  2.000e-02  8.222e+00 -3.000e-03  2.000e-02\n",
      "  8.225e+00 -3.000e-03  2.000e-02  8.227e+00 -3.000e-03  2.000e-02\n",
      "  8.229e+00 -3.000e-03  2.000e-02  8.231e+00 -3.000e-03  2.000e-02])\n",
      "[ 7.75718435e+06 -3.63606473e+05  7.23000000e-01  4.16700000e+00\n",
      "  7.75717426e+06 -3.63622204e+05  1.20100000e+00  4.70000000e+00\n",
      " -1.90000000e-02] -> [ 4.73221    -0.02000982  0.02042656  4.7333612  -0.02047942  0.0207624\n",
      "  4.727585   -0.0207193   0.0202626   4.7243404  -0.02002621  0.01906908\n",
      "  4.715634   -0.01957183  0.01977063  4.7133512  -0.02077762  0.01973954\n",
      "  4.7080564  -0.01984288  0.02000584  4.704841   -0.01998928  0.02026353\n",
      "  4.6978626  -0.02067392  0.02018064  4.6941833  -0.02063893  0.02089649\n",
      "  4.687956   -0.01927238  0.02058878  4.687792   -0.02114911  0.01993695\n",
      "  4.6819735  -0.02121373  0.01976484  4.675275   -0.02124906  0.02002065\n",
      "  4.6696095  -0.02016029  0.02079682  4.6673555  -0.0206568   0.02005003\n",
      "  4.6609597  -0.02138012  0.02010178  4.6601696  -0.02111192  0.01985898\n",
      "  4.6522217  -0.02028435  0.02020106  4.6501293  -0.02093695  0.01973827\n",
      "  4.6471677  -0.02110278  0.01996754  4.6414423  -0.02156797  0.02061537\n",
      "  4.6361465  -0.02123386  0.019997    4.629696   -0.02046632  0.01993353\n",
      "  4.626337   -0.02043523  0.02019477  4.623017   -0.02134589  0.01971662\n",
      "  4.614759   -0.02112019  0.02011826  4.6135736  -0.02176845  0.01982136\n",
      "  4.6067457  -0.02143373  0.01998503  4.601706   -0.02064295  0.01971247\n",
      "  4.598143   -0.02140436  0.02010505  4.595648   -0.02104368  0.01980501\n",
      "  4.590045   -0.02113859  0.01971926  4.584542   -0.0211527   0.01955779\n",
      "  4.5808907  -0.02021046  0.020641    4.5740356  -0.01997882  0.01975987\n",
      "  4.5682106  -0.02030032  0.01932757  4.566715   -0.01934198  0.01959391\n",
      "  4.560228   -0.01932502  0.01952462  4.5541224  -0.01903811  0.02067763\n",
      "  4.5510683  -0.01880985  0.02068176  4.546234   -0.01926802  0.01934634\n",
      "  4.5430818  -0.01821044  0.01876305  4.536992   -0.01766095  0.01986472\n",
      "  4.5353365  -0.0175055   0.02029806  4.5298905  -0.01707513  0.02007929\n",
      "  4.524496   -0.01767126  0.01941182  4.521406   -0.01761875  0.01938324\n",
      "  4.5173507  -0.01582407  0.02024824  4.509112   -0.01639067  0.01966457] (expected [ 4.7   -0.019  0.02   4.697 -0.019  0.02   4.695 -0.019  0.02   4.692\n",
      " -0.019  0.02   4.69  -0.019  0.02   4.688 -0.019  0.02   4.685 -0.019\n",
      "  0.02   4.683 -0.02   0.02   4.68  -0.02   0.02   4.678 -0.02   0.02\n",
      "  4.675 -0.02   0.02   4.673 -0.02   0.02   4.67  -0.02   0.02   4.668\n",
      " -0.02   0.02   4.665 -0.021  0.02   4.663 -0.021  0.02   4.66  -0.021\n",
      "  0.02   4.658 -0.021  0.02   4.655 -0.021  0.02   4.653 -0.021  0.02\n",
      "  4.651 -0.022  0.02   4.648 -0.022  0.02   4.646 -0.022  0.02   4.643\n",
      " -0.022  0.02   4.641 -0.023  0.02   4.638 -0.023  0.02   4.636 -0.023\n",
      "  0.02   4.633 -0.023  0.02   4.631 -0.024  0.02   4.628 -0.024  0.02\n",
      "  4.626 -0.024  0.02   4.623 -0.025  0.02   4.621 -0.025  0.02   4.618\n",
      " -0.026  0.02   4.616 -0.026  0.02   4.613 -0.026  0.02   4.611 -0.027\n",
      "  0.02   4.609 -0.027  0.02   4.606 -0.028  0.02   4.604 -0.028  0.02\n",
      "  4.601 -0.029  0.02   4.599 -0.029  0.02   4.596 -0.03   0.02   4.594\n",
      " -0.03   0.02   4.591 -0.031  0.02   4.589 -0.032  0.02   4.586 -0.032\n",
      "  0.02   4.584 -0.033  0.02   4.581 -0.034  0.02   4.579 -0.035  0.02 ])\n",
      "[ 7.75732591e+06 -3.63490353e+05 -2.96200000e+00  6.62700000e+00\n",
      "  7.75735289e+06 -3.63494523e+05  2.81100000e+00  7.32800000e+00\n",
      "  2.10000000e-02] -> [7.3421807  0.02179849 0.02048188 7.3221893  0.02168532 0.01981552\n",
      " 7.314342   0.02155887 0.02075434 7.3160033  0.0218507  0.01969636\n",
      " 7.2968297  0.02209116 0.02014566 7.3022676  0.02207621 0.02029744\n",
      " 7.296774   0.02180599 0.01951171 7.295557   0.02209869 0.01956404\n",
      " 7.284775   0.02174718 0.01951795 7.2842236  0.0215465  0.0197258\n",
      " 7.2739654  0.02202037 0.02018645 7.2832127  0.0213397  0.02003173\n",
      " 7.2759404  0.02117971 0.02038595 7.2658668  0.02113295 0.01957093\n",
      " 7.261059   0.02162516 0.01983265 7.2636795  0.02131834 0.01978467\n",
      " 7.2550144  0.02098448 0.0204184  7.261103   0.02091686 0.01994607\n",
      " 7.2484546  0.0209744  0.02064196 7.251875   0.02089526 0.02030714\n",
      " 7.2519226  0.02020735 0.02013568 7.2454915  0.01982191 0.01963237\n",
      " 7.2403164  0.01967698 0.02018349 7.229786   0.0198505  0.01995445\n",
      " 7.228438   0.01953094 0.0198468  7.22873    0.01936926 0.02020776\n",
      " 7.215757   0.01897681 0.01988214 7.223147   0.01904368 0.02070667\n",
      " 7.2124505  0.01900338 0.01972622 7.207052   0.01887445 0.01933088\n",
      " 7.2058053  0.01886513 0.0197654  7.2078643  0.01871095 0.0199458\n",
      " 7.200741   0.01879068 0.01932784 7.1956396  0.01925198 0.01994831\n",
      " 7.1937475  0.01877265 0.02055826 7.18314    0.0190168  0.02019797\n",
      " 7.1771264  0.01922411 0.01954334 7.1820703  0.01950774 0.02034797\n",
      " 7.1717668  0.01940799 0.02035443 7.165028   0.01897737 0.02005488\n",
      " 7.1650534  0.01908445 0.0203537  7.162148   0.01953591 0.02025161\n",
      " 7.1622143  0.01936874 0.01978858 7.154628   0.01924019 0.02000681\n",
      " 7.156672   0.01931703 0.01942586 7.151732   0.01951271 0.02017958\n",
      " 7.1462917  0.0199097  0.02027855 7.146672   0.01982704 0.0203511\n",
      " 7.1444836  0.02045799 0.01983351 7.1302657  0.01966406 0.02004937] (expected [7.328 0.021 0.02  7.325 0.021 0.02  7.321 0.021 0.02  7.317 0.021 0.02\n",
      " 7.314 0.021 0.02  7.31  0.021 0.02  7.307 0.021 0.02  7.303 0.021 0.02\n",
      " 7.3   0.021 0.02  7.296 0.021 0.02  7.292 0.021 0.02  7.289 0.021 0.02\n",
      " 7.285 0.021 0.02  7.282 0.021 0.02  7.278 0.021 0.02  7.274 0.021 0.02\n",
      " 7.271 0.021 0.02  7.267 0.021 0.02  7.264 0.021 0.02  7.26  0.022 0.02\n",
      " 7.257 0.022 0.02  7.253 0.022 0.02  7.249 0.022 0.02  7.246 0.022 0.02\n",
      " 7.242 0.022 0.02  7.239 0.022 0.02  7.235 0.022 0.02  7.231 0.022 0.02\n",
      " 7.228 0.022 0.02  7.224 0.022 0.02  7.221 0.022 0.02  7.217 0.022 0.02\n",
      " 7.214 0.023 0.02  7.21  0.023 0.02  7.206 0.023 0.02  7.203 0.023 0.02\n",
      " 7.199 0.023 0.02  7.196 0.023 0.02  7.192 0.023 0.02  7.188 0.023 0.02\n",
      " 7.185 0.023 0.02  7.181 0.023 0.02  7.178 0.024 0.02  7.174 0.024 0.02\n",
      " 7.171 0.024 0.02  7.167 0.024 0.02  7.163 0.024 0.02  7.16  0.024 0.02\n",
      " 7.156 0.024 0.02  7.153 0.025 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "#CONFIGURAR PARA VARIAS SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,150))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 150)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 150)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 150)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end]  # Modify this line\n",
    "            y_batch = y_train[start:end]  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 1)\n"
     ]
    }
   ],
   "source": [
    "print(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757750.975 -363847.325      -2.485       2.5   7757759.112 -363841.075\n",
      "       -2.485       2.902      -0.   ]]\n",
      "[[ 1.26659207 -0.27974198 -1.24881179 -2.58876423  1.27859044 -0.25543732\n",
      "  -1.24577649 -2.4471998   0.05157178]]\n",
      "[7757750.975 -363847.325      -2.485       2.5   7757759.112 -363841.075\n",
      "      -2.485       2.902      -0.   ] -> [ 2.9397252  -0.00230479  0.02096664  2.9720433  -0.00261549  0.01992604\n",
      "  2.960498   -0.00219465  0.02069652  2.9628859  -0.00361211  0.02096868\n",
      "  2.936556   -0.00283197  0.01957399  2.9441931  -0.00280283  0.01950908\n",
      "  2.9375508  -0.00333644  0.01941477  2.9367454  -0.00309688  0.02013857\n",
      "  2.9219844  -0.00257151  0.01972022  2.921484   -0.00252901  0.02040578\n",
      "  2.907029   -0.0033864   0.01911065  2.9217083  -0.00384773  0.01947332\n",
      "  2.9132512  -0.00394734  0.01983833  2.8971634  -0.0040679   0.02016703\n",
      "  2.8905468  -0.00401646  0.02087865  2.8951602  -0.00369731  0.02020904\n",
      "  2.884118   -0.00281518  0.02041318  2.8943346  -0.00497593  0.02007925\n",
      "  2.874969   -0.00480789  0.02074823  2.8824086  -0.00363497  0.0208499\n",
      "  2.8824382  -0.00492844  0.01979117  2.8756773  -0.00539562  0.02005702\n",
      "  2.867298   -0.00577212  0.02018381  2.8540988  -0.00423359  0.01981238\n",
      "  2.8531437  -0.00539784  0.02033475  2.853167   -0.00483603  0.01921451\n",
      "  2.8354177  -0.00598651  0.0197093   2.8469546  -0.00600773  0.0198039\n",
      "  2.832478   -0.00503142  0.01886363  2.8241422  -0.00504293  0.01912072\n",
      "  2.824283   -0.00373194  0.01981879  2.8281336  -0.00527426  0.02123946\n",
      "  2.8206024  -0.00432472  0.01922344  2.8118896  -0.0041854   0.01918216\n",
      "  2.8113236  -0.00629731  0.01880017  2.794849   -0.00428134  0.02058397\n",
      "  2.7870936  -0.00464945  0.02138631  2.7962773  -0.00234953  0.02045455\n",
      "  2.7809346  -0.00350496  0.01947822  2.7729084  -0.00476143  0.02179176\n",
      "  2.774788   -0.00418976  0.01916387  2.7702494  -0.00369798  0.01967243\n",
      "  2.7718196  -0.00241175  0.01943819  2.7599578  -0.00287116  0.01955048\n",
      "  2.766255   -0.00292227  0.02017101  2.759505   -0.00243834  0.02042354\n",
      "  2.7518756  -0.0023965   0.01980495  2.7534835  -0.00292811  0.01908284\n",
      "  2.75012    -0.00034224  0.02026234  2.7303045  -0.00288646  0.01923696] (expected [ 2.902 -0.     0.02   2.9   -0.     0.02   2.898 -0.     0.02   2.896\n",
      " -0.001  0.02   2.894 -0.001  0.02   2.892 -0.001  0.02   2.89  -0.001\n",
      "  0.02   2.888 -0.001  0.02   2.885 -0.001  0.02   2.883 -0.001  0.02\n",
      "  2.881 -0.001  0.02   2.879 -0.001  0.02   2.877 -0.001  0.02   2.875\n",
      " -0.002  0.02   2.873 -0.002  0.02   2.871 -0.002  0.02   2.869 -0.002\n",
      "  0.02   2.867 -0.002  0.02   2.865 -0.002  0.02   2.863 -0.002  0.02\n",
      "  2.861 -0.002  0.02   2.859 -0.002  0.02   2.857 -0.002  0.02   2.855\n",
      " -0.002  0.02   2.853 -0.002  0.02   2.851 -0.003  0.02   2.849 -0.003\n",
      "  0.02   2.847 -0.003  0.02   2.845 -0.003  0.02   2.843 -0.003  0.02\n",
      "  2.841 -0.003  0.02   2.839 -0.003  0.02   2.837 -0.003  0.02   2.835\n",
      " -0.003  0.02   2.833 -0.003  0.02   2.831 -0.003  0.02   2.829 -0.003\n",
      "  0.02   2.827 -0.003  0.02   2.825 -0.003  0.02   2.823 -0.003  0.02\n",
      "  2.821 -0.003  0.02   2.819 -0.003  0.02   2.817 -0.003  0.02   2.815\n",
      " -0.003  0.02   2.813 -0.003  0.02   2.811 -0.003  0.02   2.809 -0.003\n",
      "  0.02   2.807 -0.003  0.02   2.805 -0.003  0.02   2.803 -0.003  0.02 ])\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(1):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        print(X_sample)\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        print(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757750.975 -363847.325      -2.485       2.5   7757759.112 -363841.075\n",
      "       -2.485       2.902      -0.   ]]\n",
      "[[ 1.26659207 -0.27974198 -1.24881179 -2.58876423  1.27859044 -0.25543732\n",
      "  -1.24577649 -2.4471998   0.05157178]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dummy_input = X_test_raw[i: i+1]\n",
    "    print(dummy_input)\n",
    "    dummy_input = scaler.transform(dummy_input)\n",
    "    print(dummy_input)\n",
    "    dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "    traced_script_module = torch.jit.trace(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"model_clean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757219.02030919 -363790.45257479       0.02507255       7.59847813\n",
      " 7757221.91891166 -363789.01252881       0.02444362       7.47429562\n",
      "      -0.00269055]\n",
      "[419.98896269 203.30314877   2.00996865   1.96946407 420.14477201\n",
      " 203.81701318   2.01436103   1.86837855   0.05217095]\n"
     ]
    }
   ],
   "source": [
    "mean = scaler.mean_\n",
    "std_dev = scaler.scale_\n",
    "print(mean)\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_test_cpp = np.array([7757481.724, -363634.012, 2.313, 8.372, 7757506.813, -363650.764, 2.799, 7.703, -0.037])\n",
    "X_test_cpp = scaler.transform(X_test_cpp)\n",
    "print(X_test_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0573,  1.5971, -0.0614, -0.1519,  2.0956,  0.6641,  0.5896, -0.4267,\n",
      "          1.4114]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=24, bias=True)\n",
       "  (1): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (2): Linear(in_features=12, out_features=6, bias=True)\n",
       "  (3): Linear(in_features=6, out_features=150, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n",
      "          1.2702]])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have a trained model 'model'\n",
    "#dummy_input = torch.randn(1, 9)  # Adjust as necessary\n",
    "dummy_input = X_test_raw[i: i+1]\n",
    "dummy_input = scaler.transform(dummy_input)\n",
    "dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "print(dummy_input)\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Dados/caiopinho/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.ones(1, 9, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Convert the model to Torch Script\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, dummy_input)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Save the Torch Script module\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m script_module\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/jit/_trace.py:778\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    773\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrace doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support compiling individual module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms functions.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    774\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use trace_module\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m     )\n\u001b[1;32m    777\u001b[0m name \u001b[39m=\u001b[39m _qualified_name(func)\n\u001b[0;32m--> 778\u001b[0m traced \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_function_from_trace(\n\u001b[1;32m    779\u001b[0m     name, func, example_inputs, var_lookup_fn, strict, _force_outplace\n\u001b[1;32m    780\u001b[0m )\n\u001b[1;32m    782\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m check_trace:\n",
      "\u001b[0;31mTypeError\u001b[0m: _create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"model.onnx\")\n",
    "\n",
    "# Convert the model to Torch Script\n",
    "script_module = torch.jit.trace(model, dummy_input)\n",
    "\n",
    "# Save the Torch Script module\n",
    "script_module.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "       -2.487       4.803       0.001]]\n",
      "[[ 1.16240348 -0.45512402 -1.25481378  0.4579256   1.19118628 -0.4031037\n",
      "  -1.25742504 -1.43256721  0.07519625]]\n",
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001]\n"
     ]
    }
   ],
   "source": [
    "X_sample2 = X_test_raw[0: 1]\n",
    "print(X_sample2)\n",
    "\n",
    "X_sample2 = scaler.transform(X_sample2)\n",
    "print(X_sample2)\n",
    "X_sample2 = X_test_raw[0]\n",
    "print(X_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001] -> [ 4.8010063  -0.00074159  0.01997822  4.8005514  -0.00091523  0.02000268\n",
      "  4.814805   -0.00176182  0.01970529  4.8287263  -0.000778    0.02051836\n",
      "  4.8326116  -0.00174367  0.01992373  4.856453   -0.00167146  0.01983681\n",
      "  4.864167   -0.00193731  0.01993301  4.879089   -0.00164818  0.02014743\n",
      "  4.8937235  -0.00073487  0.02012613  4.8967085  -0.00159477  0.01993886\n",
      "  4.9280586  -0.00181691  0.01975316  4.925619   -0.00195716  0.02010386\n",
      "  4.950785   -0.00190242  0.02001777  4.957052   -0.00186971  0.0202428\n",
      "  4.97818    -0.00249793  0.01988537  4.995721   -0.00255796  0.02014657\n",
      "  4.994455   -0.0025937   0.01995826  5.008133   -0.00280979  0.02011759\n",
      "  5.0308924  -0.00291541  0.01984772  5.0377316  -0.00323275  0.02050596\n",
      "  5.0456805  -0.00307235  0.0199565   5.065904   -0.00340613  0.01975301\n",
      "  5.074639   -0.00332363  0.01996499  5.1010294  -0.00328155  0.01999776\n",
      "  5.1006637  -0.00362112  0.01982425  5.1268015  -0.00374103  0.01991623\n",
      "  5.138431   -0.00395512  0.01991449  5.14359    -0.00391159  0.01998987\n",
      "  5.1597624  -0.00423715  0.0200338   5.164531   -0.00380588  0.01998207\n",
      "  5.1826973  -0.00437438  0.02011609  5.1961102  -0.00469906  0.02033865\n",
      "  5.2155013  -0.00415806  0.02007735  5.2181277  -0.00392795  0.01971572\n",
      "  5.235365   -0.0039203   0.02010624  5.2443867  -0.00465819  0.01985199\n",
      "  5.254088   -0.00413277  0.02006014  5.2746816  -0.0038663   0.0199084\n",
      "  5.2876625  -0.00470388  0.0199628   5.2932086  -0.00375362  0.02029131\n",
      "  5.3144155  -0.0036635   0.02001484  5.3334975  -0.00344844  0.01998478\n",
      "  5.3484445  -0.00428118  0.01996177  5.3510637  -0.00424473  0.0199277\n",
      "  5.3572283  -0.00406776  0.02008447  5.3868194  -0.00447915  0.02004181\n",
      "  5.3942337  -0.00368278  0.01986287  5.4088097  -0.00456195  0.02005492\n",
      "  5.414704   -0.00376444  0.02006499  5.440771   -0.0048934   0.01993128] (expected [4.803 0.001 0.02  4.819 0.001 0.02  4.835 0.001 0.02  4.851 0.001 0.02\n",
      " 4.867 0.001 0.02  4.883 0.001 0.02  4.899 0.001 0.02  4.915 0.001 0.02\n",
      " 4.931 0.001 0.02  4.947 0.001 0.02  4.963 0.001 0.02  4.979 0.001 0.02\n",
      " 4.995 0.001 0.02  5.011 0.001 0.02  5.027 0.001 0.02  5.043 0.001 0.02\n",
      " 5.059 0.001 0.02  5.075 0.001 0.02  5.091 0.001 0.02  5.107 0.001 0.02\n",
      " 5.123 0.001 0.02  5.139 0.001 0.02  5.155 0.001 0.02  5.171 0.    0.02\n",
      " 5.187 0.    0.02  5.203 0.    0.02  5.219 0.    0.02  5.235 0.    0.02\n",
      " 5.251 0.    0.02  5.267 0.    0.02  5.283 0.    0.02  5.299 0.    0.02\n",
      " 5.315 0.    0.02  5.331 0.    0.02  5.347 0.    0.02  5.363 0.    0.02\n",
      " 5.379 0.    0.02  5.395 0.    0.02  5.411 0.    0.02  5.427 0.    0.02\n",
      " 5.443 0.    0.02  5.459 0.    0.02  5.475 0.    0.02  5.491 0.    0.02\n",
      " 5.507 0.    0.02  5.523 0.    0.02  5.539 0.    0.02  5.555 0.    0.02\n",
      " 5.571 0.    0.02  5.587 0.001 0.02 ])\n",
      "[7757801.761 -363519.424       3.074       8.016 7757831.521 -363531.805\n",
      "       2.493       8.334       0.025] -> [8.332953   0.02570583 0.02057826 8.279287   0.0260936  0.01937635\n",
      " 8.279661   0.02568588 0.02047574 8.281424   0.02454777 0.01915007\n",
      " 8.274772   0.02515006 0.02098195 8.281982   0.02503929 0.01914372\n",
      " 8.278026   0.02583499 0.0184833  8.280119   0.02489562 0.02037758\n",
      " 8.2803     0.02479535 0.02028337 8.273154   0.02475645 0.01960913\n",
      " 8.286489   0.02491888 0.01928371 8.275139   0.02615823 0.01904969\n",
      " 8.283588   0.0249912  0.020569   8.279796   0.02533591 0.02059739\n",
      " 8.283659   0.02476165 0.02070565 8.287676   0.02572682 0.02014912\n",
      " 8.276308   0.02517223 0.01923848 8.27715    0.02432403 0.01998729\n",
      " 8.284091   0.0255501  0.01925227 8.280431   0.02544269 0.02009993\n",
      " 8.276081   0.0244431  0.01982384 8.280431   0.02421162 0.0209767\n",
      " 8.276962   0.02461271 0.02015173 8.288047   0.02541332 0.02063011\n",
      " 8.277835   0.02415167 0.02029199 8.287139   0.0238065  0.01952587\n",
      " 8.285027   0.02313591 0.01905958 8.280449   0.02377018 0.01999696\n",
      " 8.28143    0.02516142 0.02103802 8.275567   0.02468783 0.02011264\n",
      " 8.279786   0.02446736 0.0203737  8.279707   0.02499932 0.01933622\n",
      " 8.283042   0.02523439 0.01940995 8.276601   0.02493435 0.01961403\n",
      " 8.27914    0.02568574 0.02154677 8.276657   0.02521071 0.02053792\n",
      " 8.274283   0.02505938 0.02104003 8.278971   0.02595724 0.01849017\n",
      " 8.2789345  0.02633464 0.01930214 8.273977   0.02619009 0.02057384\n",
      " 8.278184   0.02495228 0.0193009  8.282623   0.02417462 0.0207606\n",
      " 8.285052   0.02478037 0.02051708 8.276708   0.02573486 0.01951893\n",
      " 8.273311   0.02499515 0.0200881  8.283986   0.02586628 0.01974319\n",
      " 8.279172   0.02529712 0.02044044 8.281159   0.02531607 0.01932614\n",
      " 8.275503   0.02524789 0.01950336 8.284525   0.02565493 0.01986678] (expected [8.334 0.025 0.02  8.332 0.025 0.02  8.331 0.025 0.02  8.329 0.025 0.02\n",
      " 8.327 0.025 0.02  8.326 0.025 0.02  8.324 0.025 0.02  8.323 0.025 0.02\n",
      " 8.321 0.025 0.02  8.319 0.025 0.02  8.318 0.025 0.02  8.316 0.025 0.02\n",
      " 8.315 0.025 0.02  8.313 0.025 0.02  8.312 0.025 0.02  8.31  0.025 0.02\n",
      " 8.308 0.026 0.02  8.307 0.026 0.02  8.305 0.026 0.02  8.304 0.026 0.02\n",
      " 8.302 0.026 0.02  8.3   0.026 0.02  8.299 0.026 0.02  8.297 0.026 0.02\n",
      " 8.296 0.026 0.02  8.294 0.026 0.02  8.292 0.026 0.02  8.291 0.026 0.02\n",
      " 8.289 0.027 0.02  8.288 0.027 0.02  8.286 0.027 0.02  8.285 0.027 0.02\n",
      " 8.283 0.027 0.02  8.281 0.027 0.02  8.28  0.027 0.02  8.278 0.028 0.02\n",
      " 8.277 0.028 0.02  8.275 0.028 0.02  8.273 0.028 0.02  8.272 0.029 0.02\n",
      " 8.27  0.029 0.02  8.269 0.029 0.02  8.267 0.029 0.02  8.265 0.03  0.02\n",
      " 8.264 0.03  0.02  8.262 0.03  0.02  8.261 0.031 0.02  8.259 0.031 0.02\n",
      " 8.257 0.031 0.02  8.256 0.032 0.02 ])\n",
      "[7757398.832 -363523.465       2.313       8.55  7757418.023 -363547.615\n",
      "       2.224       7.703       0.001] -> [7.68352    0.00130333 0.02032702 7.641883   0.00083899 0.02039786\n",
      " 7.6465163  0.00056658 0.02013385 7.6483893  0.00194509 0.02029281\n",
      " 7.6505     0.00100994 0.01988105 7.6568565  0.00122235 0.02029719\n",
      " 7.6596446  0.00039227 0.02037289 7.662617   0.00142402 0.02003271\n",
      " 7.667677   0.00241441 0.01962855 7.669256   0.00201954 0.02052943\n",
      " 7.6761103  0.00163754 0.01999038 7.6771     0.00058164 0.02000098\n",
      " 7.683269   0.00165032 0.02034155 7.684547   0.00150722 0.01954996\n",
      " 7.6919785  0.00146589 0.02018756 7.695269   0.0005441  0.0205392\n",
      " 7.6975493  0.00094914 0.02031845 7.700929   0.00180373 0.02080054\n",
      " 7.7061877  0.00045523 0.02029929 7.7079177  0.00016031 0.01984137\n",
      " 7.711619   0.00095294 0.01972057 7.7176385  0.00099961 0.01966164\n",
      " 7.720926   0.00110845 0.02040421 7.725027   0.00096409 0.01933991\n",
      " 7.726849   0.00044702 0.01945675 7.7329917  0.00127519 0.02017855\n",
      " 7.737667   0.00104059 0.02027552 7.738297   0.00138625 0.02069708\n",
      " 7.7441926  0.00089028 0.02004447 7.7461205  0.00130421 0.02008313\n",
      " 7.749738   0.00169409 0.02011915 7.7536077  0.00105089 0.02062368\n",
      " 7.760129   0.00061737 0.02020869 7.760017   0.0009951  0.01945942\n",
      " 7.7652626  0.00119765 0.01941936 7.7676105  0.00134489 0.01985163\n",
      " 7.770476   0.00189952 0.01999766 7.776159   0.00147761 0.02066216\n",
      " 7.7798986  0.00109136 0.01993258 7.7812815  0.0016046  0.02023147\n",
      " 7.788701   0.00245623 0.02079733 7.793334   0.00313549 0.02034777\n",
      " 7.795774   0.00259195 0.01947185 7.7981896  0.00216164 0.01940961\n",
      " 7.7987413  0.0028218  0.01963487 7.8069115  0.00203289 0.02025949\n",
      " 7.810602   0.00299086 0.02001701 7.8133383  0.00247199 0.01974632\n",
      " 7.816203   0.00330944 0.02070255 7.8224535  0.00220504 0.01950284] (expected [7.703 0.001 0.02  7.707 0.001 0.02  7.712 0.001 0.02  7.716 0.001 0.02\n",
      " 7.72  0.001 0.02  7.725 0.001 0.02  7.729 0.001 0.02  7.734 0.001 0.02\n",
      " 7.738 0.001 0.02  7.742 0.001 0.02  7.747 0.001 0.02  7.751 0.001 0.02\n",
      " 7.755 0.001 0.02  7.76  0.001 0.02  7.764 0.001 0.02  7.769 0.001 0.02\n",
      " 7.773 0.001 0.02  7.777 0.001 0.02  7.782 0.001 0.02  7.786 0.001 0.02\n",
      " 7.791 0.001 0.02  7.795 0.001 0.02  7.799 0.001 0.02  7.804 0.001 0.02\n",
      " 7.808 0.001 0.02  7.813 0.001 0.02  7.817 0.001 0.02  7.821 0.001 0.02\n",
      " 7.826 0.001 0.02  7.83  0.001 0.02  7.835 0.001 0.02  7.839 0.001 0.02\n",
      " 7.843 0.001 0.02  7.848 0.001 0.02  7.852 0.001 0.02  7.857 0.001 0.02\n",
      " 7.861 0.001 0.02  7.865 0.001 0.02  7.87  0.001 0.02  7.874 0.001 0.02\n",
      " 7.878 0.001 0.02  7.883 0.001 0.02  7.887 0.001 0.02  7.892 0.001 0.02\n",
      " 7.896 0.001 0.02  7.9   0.001 0.02  7.905 0.001 0.02  7.909 0.001 0.02\n",
      " 7.914 0.001 0.02  7.918 0.001 0.02 ])\n",
      "[7756536.421 -363779.861       1.18        8.55  7756528.942 -363813.723\n",
      "       1.441       8.68       -0.007] -> [ 8.648965   -0.00748847  0.02032312  8.593876   -0.00899696  0.02150925\n",
      "  8.5948105  -0.00896706  0.02008479  8.58801    -0.00458245  0.02139455\n",
      "  8.591499   -0.00721812  0.01868896  8.588325   -0.00662043  0.02156892\n",
      "  8.590234   -0.00932901  0.02237298  8.5854225  -0.00596195  0.0196064\n",
      "  8.587645   -0.00375348  0.01870826  8.590537   -0.00439189  0.02173356\n",
      "  8.581299   -0.00550023  0.02065581  8.587846   -0.00899826  0.02101593\n",
      "  8.5828     -0.00535823  0.02023461  8.580964   -0.0060997   0.01808261\n",
      "  8.584315   -0.00537994  0.01971883  8.577991   -0.00857803  0.02118644\n",
      "  8.587483   -0.00700641  0.021599    8.58501    -0.00396815  0.02187604\n",
      "  8.579759   -0.00841048  0.02152368  8.5788145  -0.00893942  0.01926094\n",
      "  8.583215   -0.00601663  0.01948993  8.582711   -0.00559088  0.01828561\n",
      "  8.585115   -0.00567044  0.02085053  8.572363   -0.00679334  0.01776277\n",
      "  8.579396   -0.00675549  0.0184348   8.573252   -0.00431146  0.02105259\n",
      "  8.577254   -0.00418436  0.02162115  8.574989   -0.00399152  0.0217767\n",
      "  8.57805    -0.00653502  0.01914867  8.58017    -0.00506145  0.02012574\n",
      "  8.574344   -0.00387561  0.01986536  8.574201   -0.00594503  0.02222824\n",
      "  8.575941   -0.00736262  0.02103469  8.574182   -0.00618547  0.0190888\n",
      "  8.573944   -0.00645809  0.01701276  8.573064   -0.00555292  0.0190782\n",
      "  8.573169   -0.00409814  0.01893005  8.571572   -0.00615226  0.0231559\n",
      "  8.570943   -0.00733435  0.02050165  8.570824   -0.00616522  0.01997779\n",
      "  8.573595   -0.00285508  0.02266856  8.569768   -0.0005482   0.0200972\n",
      "  8.563346   -0.00242199  0.01813856  8.569615   -0.00433783  0.01900239\n",
      "  8.565632   -0.00200707  0.01899615  8.562543   -0.00488578  0.02088645\n",
      "  8.567423   -0.00223367  0.01964829  8.562147   -0.00337069  0.01994379\n",
      "  8.566233   -0.00156729  0.02223463  8.560793   -0.00444076  0.01894637] (expected [ 8.68  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02\n",
      "  8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.009  0.02\n",
      "  8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55\n",
      " -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009\n",
      "  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02 ])\n",
      "[7757309.348 -363499.087      -2.407       6.407 7757333.518 -363490.282\n",
      "       3.096       6.789       0.063] -> [6.7516246  0.06393541 0.0203922  6.714112   0.06429583 0.01986296\n",
      " 6.7130346  0.06421862 0.02037632 6.714601   0.06174846 0.01862007\n",
      " 6.690399   0.06312048 0.02134422 6.7101917  0.06299231 0.01969864\n",
      " 6.697115   0.0635093  0.01890697 6.6980944  0.06255621 0.02043486\n",
      " 6.696756   0.06170458 0.02021852 6.673561   0.0622045  0.01976297\n",
      " 6.710045   0.06274613 0.02008623 6.674609   0.0626265  0.01846962\n",
      " 6.6977534  0.06200032 0.02084127 6.681123   0.06232089 0.02072971\n",
      " 6.691144   0.06180153 0.02126975 6.7009463  0.06254116 0.01991961\n",
      " 6.6646037  0.06192434 0.01919109 6.663426   0.06095931 0.02039833\n",
      " 6.6841207  0.06183478 0.01955387 6.6679854  0.06177959 0.01980429\n",
      " 6.652021   0.06063057 0.01983571 6.6637483  0.06052557 0.02118478\n",
      " 6.650559   0.06046109 0.02037393 6.679942   0.06084244 0.02039348\n",
      " 6.64709    0.05994342 0.02032236 6.6720653  0.05926207 0.01921879\n",
      " 6.664455   0.05888236 0.0193051  6.647466   0.0593219  0.0200149\n",
      " 6.6470604  0.06064299 0.02071782 6.626414   0.05951655 0.02003768\n",
      " 6.635787   0.05980266 0.02034537 6.635339   0.06039565 0.01852893\n",
      " 6.6426735  0.06026457 0.01953453 6.6192966  0.05949992 0.02007317\n",
      " 6.6249437  0.06008597 0.02125828 6.615039   0.05911204 0.02098817\n",
      " 6.6027455  0.05909542 0.02104271 6.616658   0.06002344 0.01874468\n",
      " 6.613754   0.06030071 0.01947895 6.5958104  0.05995737 0.01991723\n",
      " 6.606965   0.05849443 0.01943179 6.617211   0.05763273 0.02095491\n",
      " 6.620795   0.05855547 0.02065229 6.593711   0.05880125 0.01958214\n",
      " 6.578475   0.05770756 0.01979366 6.6092935  0.05872704 0.01973746\n",
      " 6.593334   0.05818869 0.02065203 6.594169   0.05764527 0.0194798\n",
      " 6.5751987  0.05768259 0.01949466 6.601967   0.05686679 0.01971253] (expected [6.789 0.063 0.02  6.787 0.063 0.02  6.785 0.063 0.02  6.783 0.063 0.02\n",
      " 6.781 0.063 0.02  6.779 0.063 0.02  6.777 0.063 0.02  6.775 0.063 0.02\n",
      " 6.773 0.063 0.02  6.771 0.063 0.02  6.769 0.063 0.02  6.767 0.063 0.02\n",
      " 6.765 0.063 0.02  6.763 0.063 0.02  6.761 0.063 0.02  6.759 0.063 0.02\n",
      " 6.757 0.064 0.02  6.755 0.064 0.02  6.753 0.064 0.02  6.751 0.064 0.02\n",
      " 6.75  0.064 0.02  6.748 0.064 0.02  6.746 0.064 0.02  6.744 0.064 0.02\n",
      " 6.742 0.064 0.02  6.74  0.064 0.02  6.738 0.064 0.02  6.736 0.065 0.02\n",
      " 6.734 0.065 0.02  6.732 0.065 0.02  6.73  0.065 0.02  6.728 0.065 0.02\n",
      " 6.726 0.066 0.02  6.724 0.066 0.02  6.722 0.066 0.02  6.72  0.066 0.02\n",
      " 6.718 0.067 0.02  6.716 0.067 0.02  6.714 0.067 0.02  6.712 0.067 0.02\n",
      " 6.71  0.068 0.02  6.708 0.068 0.02  6.706 0.068 0.02  6.705 0.069 0.02\n",
      " 6.703 0.069 0.02  6.701 0.07  0.02  6.699 0.07  0.02  6.697 0.071 0.02\n",
      " 6.695 0.071 0.02  6.693 0.072 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "np.set_printoptions(suppress=True)\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.02\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75696163e+06 -3.64057635e+05 -1.38000000e-01  8.54600000e+00\n",
      "  7.75692823e+06 -3.64053126e+05 -1.32000000e-01  8.49100000e+00\n",
      " -2.00000000e-03] -> [ 8.4910440e+00 -2.1275878e-03  2.0009704e-02] (expected [ 8.491e+00 -2.000e-03  2.000e-02])\n",
      "[ 7.75720516e+06 -3.63589039e+05 -2.53100000e+00  8.55000000e+00\n",
      "  7.75723371e+06 -3.63569516e+05 -2.49900000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609583e+00 -6.1482787e-03  2.0036645e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75717733e+06 -3.63615552e+05  1.04800000e+00  4.16700000e+00\n",
      "  7.75716855e+06 -3.63636256e+05  1.09200000e+00  5.54400000e+00\n",
      "  6.30000000e-02] -> [5.5442753  0.06288677 0.02018113] (expected [5.544 0.063 0.02 ])\n",
      "[ 7.75719467e+06 -3.63595825e+05 -2.57200000e+00  8.52500000e+00\n",
      "  7.75722353e+06 -3.63576869e+05 -2.54100000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609735e+00 -6.1470866e-03  2.0041056e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75663871e+06 -3.63686725e+05 -2.46600000e+00  8.55000000e+00\n",
      "  7.75666680e+06 -3.63666710e+05 -2.61800000e+00  8.69300000e+00\n",
      "  2.20000000e-02] -> [8.693061   0.02189618 0.01997633] (expected [8.693 0.022 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU COM 3 SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,3))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 3)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 3)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 3)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end]  # Modify this line\n",
    "            y_batch = y_train[start:end]  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75655038e+06 -3.63917271e+05 -2.31000000e-01  5.70200000e+00\n",
      "  7.75653753e+06 -3.63908823e+05 -8.46000000e-01  4.40600000e+00\n",
      "  7.50000000e-02] -> [4.3999896] (expected [4.406])\n",
      "[ 7.75766160e+06 -3.63610685e+05 -2.50900000e+00  8.55000000e+00\n",
      "  7.75768651e+06 -3.63592380e+05 -2.50700000e+00  7.70300000e+00\n",
      " -2.00000000e-03] -> [7.704249] (expected [7.703])\n",
      "[ 7.75754790e+06 -3.63656925e+05 -3.13600000e+00  8.55000000e+00\n",
      "  7.75757851e+06 -3.63654357e+05 -2.96700000e+00  7.70300000e+00\n",
      " -1.50000000e-02] -> [7.705766] (expected [7.703])\n",
      "[ 7.75769361e+06 -3.63590014e+05  6.39000000e-01  8.55000000e+00\n",
      "  7.75766713e+06 -3.63610291e+05  6.52000000e-01  8.52900000e+00\n",
      "  3.00000000e-03] -> [8.52703] (expected [8.529])\n",
      "[ 7.75685868e+06 -3.64044085e+05 -1.26000000e-01  8.55000000e+00\n",
      "  7.75682885e+06 -3.64038885e+05 -1.75000000e-01  7.65400000e+00\n",
      "  1.00000000e-03] -> [7.647367] (expected [7.654])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU (uma saida)\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,1))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 1)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Criando o modelo \n",
    "l0 = tf.keras.layers.Dense(units = 9, input_shape = [9])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 64)\n",
    "#l3 = tf.keras.layers.Dense(units = 93)\n",
    "l3 = tf.keras.layers.Dense(units = 3)\n",
    "\n",
    "\"\"\"Modelo inicial: \n",
    "l0 = tf.keras.layers.Dense(units = 4, input_shape = [4])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 128)\n",
    "l3 = tf.keras.layers.Dense(units = 3) \"\"\"\n",
    "\n",
    "model = tf.keras.Sequential([l0,l1,l2,l3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compilando o modelo\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizers.RMSprop(lr=1e-4))#tf.keras.optimizers.Adam(0.1)), loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Treinar o modelo\n",
    "history = model.fit(inputMatrix,outputMatrix,epochs=500,verbose=False)#epochs inicial=500\n",
    "print(\"Finished training the model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
