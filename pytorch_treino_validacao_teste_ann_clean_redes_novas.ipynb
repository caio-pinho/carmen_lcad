{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "#Importar bibliotecas\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar vari√°veis\n",
    "dataset_input = \"bin/dataset_input_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\"\n",
    "dataset_output = \"bin/dataset_output_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch: 0 MSE: 0.00019\n",
      "Epoch: 1 MSE: 0.00019\n",
      "Epoch: 2 MSE: 0.00019\n",
      "Epoch: 3 MSE: 0.00019\n",
      "Epoch: 4 MSE: 0.00019\n",
      "Epoch: 5 MSE: 0.00019\n",
      "Epoch: 6 MSE: 0.00019\n",
      "Epoch: 7 MSE: 0.00019\n",
      "Epoch: 8 MSE: 0.00019\n",
      "Epoch: 9 MSE: 0.00019\n",
      "Epoch: 10 MSE: 0.00019\n",
      "Epoch: 11 MSE: 0.00019\n",
      "Epoch: 12 MSE: 0.00019\n",
      "Epoch: 13 MSE: 0.00019\n",
      "Epoch: 14 MSE: 0.00019\n",
      "Epoch: 15 MSE: 0.00019\n",
      "Epoch: 16 MSE: 0.00019\n",
      "Epoch: 17 MSE: 0.00019\n",
      "Epoch: 18 MSE: 0.00019\n",
      "Epoch: 19 MSE: 0.00019\n",
      "Epoch: 20 MSE: 0.00019\n",
      "Epoch: 21 MSE: 0.00019\n",
      "Epoch: 22 MSE: 0.00019\n",
      "Epoch: 23 MSE: 0.00019\n",
      "Epoch: 24 MSE: 0.00019\n",
      "Epoch: 25 MSE: 0.00019\n",
      "Epoch: 26 MSE: 0.00019\n",
      "Epoch: 27 MSE: 0.00019\n",
      "Epoch: 28 MSE: 0.00019\n",
      "Epoch: 29 MSE: 0.00019\n",
      "Epoch: 30 MSE: 0.00019\n",
      "Epoch: 31 MSE: 0.00019\n",
      "Epoch: 32 MSE: 0.00019\n",
      "Epoch: 33 MSE: 0.00019\n",
      "Epoch: 34 MSE: 0.00019\n",
      "Epoch: 35 MSE: 0.00019\n",
      "Epoch: 36 MSE: 0.00019\n",
      "Epoch: 37 MSE: 0.00019\n",
      "Epoch: 38 MSE: 0.00019\n",
      "Epoch: 39 MSE: 0.00019\n",
      "Epoch: 40 MSE: 0.00019\n",
      "Epoch: 41 MSE: 0.00019\n",
      "Epoch: 42 MSE: 0.00019\n",
      "Epoch: 43 MSE: 0.00019\n",
      "Epoch: 44 MSE: 0.00019\n",
      "Epoch: 45 MSE: 0.00019\n",
      "Epoch: 46 MSE: 0.00019\n",
      "Epoch: 47 MSE: 0.00019\n",
      "Epoch: 48 MSE: 0.00019\n",
      "Epoch: 49 MSE: 0.00019\n",
      "Epoch: 50 MSE: 0.00019\n",
      "Epoch: 51 MSE: 0.00019\n",
      "Epoch: 52 MSE: 0.00019\n",
      "Epoch: 53 MSE: 0.00019\n",
      "Epoch: 54 MSE: 0.00019\n",
      "Epoch: 55 MSE: 0.00019\n",
      "Epoch: 56 MSE: 0.00019\n",
      "Epoch: 57 MSE: 0.00019\n",
      "Epoch: 58 MSE: 0.00019\n",
      "Epoch: 59 MSE: 0.00019\n",
      "Epoch: 60 MSE: 0.00019\n",
      "Epoch: 61 MSE: 0.00019\n",
      "Epoch: 62 MSE: 0.00019\n",
      "Epoch: 63 MSE: 0.00019\n",
      "Epoch: 64 MSE: 0.00019\n",
      "Epoch: 65 MSE: 0.00019\n",
      "Epoch: 66 MSE: 0.00019\n",
      "Epoch: 67 MSE: 0.00019\n",
      "Epoch: 68 MSE: 0.00019\n",
      "Epoch: 69 MSE: 0.00019\n",
      "Epoch: 70 MSE: 0.00019\n",
      "Epoch: 71 MSE: 0.00019\n",
      "Epoch: 72 MSE: 0.00019\n",
      "Epoch: 73 MSE: 0.00019\n",
      "Epoch: 74 MSE: 0.00019\n",
      "Epoch: 75 MSE: 0.00019\n",
      "Epoch: 76 MSE: 0.00019\n",
      "Epoch: 77 MSE: 0.00019\n",
      "Epoch: 78 MSE: 0.00019\n",
      "Epoch: 79 MSE: 0.00019\n",
      "Epoch: 80 MSE: 0.00019\n",
      "Epoch: 81 MSE: 0.00019\n",
      "Epoch: 82 MSE: 0.00019\n",
      "Epoch: 83 MSE: 0.00018\n",
      "Epoch: 84 MSE: 0.00018\n",
      "Epoch: 85 MSE: 0.00018\n",
      "Epoch: 86 MSE: 0.00018\n",
      "Epoch: 87 MSE: 0.00018\n",
      "Epoch: 88 MSE: 0.00018\n",
      "Epoch: 89 MSE: 0.00018\n",
      "Epoch: 90 MSE: 0.00018\n",
      "Epoch: 91 MSE: 0.00018\n",
      "Epoch: 92 MSE: 0.00018\n",
      "Epoch: 93 MSE: 0.00018\n",
      "Epoch: 94 MSE: 0.00018\n",
      "Epoch: 95 MSE: 0.00018\n",
      "Epoch: 96 MSE: 0.00018\n",
      "Epoch: 97 MSE: 0.00018\n",
      "Epoch: 98 MSE: 0.00018\n",
      "Epoch: 99 MSE: 0.00018\n",
      "MSE: 0.00018\n",
      "RMSE: 0.01360\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757819.5   -363524.875       2.687       7.901 7757828.5   -363530.219\n",
      "        2.569       7.668       0.03 ]] -> [0.03043141 0.0306934  0.03074715 0.0302771  0.03031329 0.03085132\n",
      " 0.03023133 0.03053149 0.03030905 0.0303616  0.03080256 0.03062267\n",
      " 0.03049408 0.03081338 0.03046143 0.03060659 0.03024209 0.03086517\n",
      " 0.03057601 0.03050715 0.03038454 0.03061497 0.03027409 0.03059655\n",
      " 0.0304869  0.03049032 0.03018822 0.03041727 0.03036158 0.03006897\n",
      " 0.02998222 0.03010665 0.0301393  0.02969894 0.02970815 0.02960788\n",
      " 0.02970931 0.02982218 0.02934422 0.0296714  0.02953584 0.02937738\n",
      " 0.02894977 0.02929311 0.02927732 0.02837493 0.02872268 0.02817759\n",
      " 0.02859727 0.02845249]\n",
      "Sample 1\n",
      "[7757396.111 -363520.537       2.356       8.55  7757417.441 -363546.879\n",
      "       2.22        8.607      -0.   ] -> [0.00049606 0.0007511  0.00082348 0.00047256 0.00054544 0.00088143\n",
      " 0.00061488 0.00084181 0.0007385  0.00082736 0.00105964 0.0010839\n",
      " 0.00101436 0.00115316 0.00106698 0.00113052 0.0008514  0.0013657\n",
      " 0.00128647 0.00130317 0.00125796 0.00133112 0.00139301 0.00143346\n",
      " 0.00147809 0.0014846  0.00143103 0.00161188 0.00147741 0.00148551\n",
      " 0.00145745 0.00150834 0.00164836 0.00135669 0.0014495  0.00142106\n",
      " 0.00150987 0.00164201 0.0014317  0.00170142 0.00172538 0.00162082\n",
      " 0.00158992 0.00173316 0.00175148 0.00128679 0.00158778 0.00136068\n",
      " 0.00148389 0.00148092] (expected [-0.    -0.     0.     0.     0.     0.     0.     0.     0.     0.001\n",
      "  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001\n",
      "  0.001  0.001  0.001  0.001  0.002  0.002  0.002  0.002  0.002  0.002\n",
      "  0.002  0.002  0.002  0.002  0.002  0.002  0.002  0.002  0.002  0.002\n",
      "  0.002  0.002  0.002  0.003  0.003  0.003  0.003  0.003  0.003  0.003])\n",
      "Sample 2\n",
      "[7757532.458 -363659.317      -0.104       8.55  7757500.497 -363649.531\n",
      "      -0.512       8.529       0.034] -> [0.03423969 0.03423368 0.03422001 0.03379913 0.03377709 0.03395107\n",
      " 0.0336225  0.03357942 0.03354616 0.03348406 0.03376839 0.03369704\n",
      " 0.03357004 0.03385557 0.03360965 0.03374628 0.03342527 0.03370398\n",
      " 0.03349767 0.03328392 0.03319407 0.03332353 0.03319779 0.03319013\n",
      " 0.03319538 0.03315813 0.03290725 0.03284189 0.03292641 0.03268678\n",
      " 0.03257038 0.03245297 0.03233655 0.03203522 0.03192635 0.03202723\n",
      " 0.03200835 0.03175584 0.03146783 0.03156934 0.03163339 0.03113873\n",
      " 0.03096835 0.03085446 0.03096382 0.03038225 0.03025563 0.03000739\n",
      " 0.03004611 0.02985742] (expected [0.034 0.034 0.034 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035\n",
      " 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035\n",
      " 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035 0.035\n",
      " 0.035 0.035 0.035 0.036 0.036 0.036 0.036 0.036 0.036 0.036 0.036 0.036\n",
      " 0.036 0.036])\n",
      "Sample 3\n",
      "[7757957.793 -363643.528       2.346       6.575 7757966.92  -363668.24\n",
      "       1.52        6.929       0.077] -> [0.07699564 0.07689802 0.07689014 0.07627515 0.07625474 0.0763607\n",
      " 0.07589301 0.0758375  0.07563972 0.07552214 0.07569999 0.07563864\n",
      " 0.07535918 0.07556532 0.07517508 0.07534185 0.07500294 0.07532763\n",
      " 0.0747631  0.07486602 0.07448374 0.07451876 0.07421277 0.07432353\n",
      " 0.07424746 0.07397888 0.07357524 0.07387592 0.07371435 0.07335883\n",
      " 0.07302956 0.07302234 0.07281841 0.07232347 0.07240181 0.0721854\n",
      " 0.07219382 0.07202233 0.07131682 0.0715712  0.07130522 0.07079129\n",
      " 0.07024027 0.07056688 0.07045808 0.06962226 0.06946453 0.06886791\n",
      " 0.06927826 0.06892512] (expected [0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077\n",
      " 0.077 0.077 0.077 0.077 0.077 0.077 0.078 0.078 0.078 0.078 0.078 0.078\n",
      " 0.078 0.078 0.078 0.078 0.078 0.078 0.078 0.078 0.078 0.078 0.078 0.078\n",
      " 0.078 0.078 0.078 0.078 0.078 0.079 0.079 0.079 0.079 0.079 0.079 0.079\n",
      " 0.079 0.079])\n",
      "Sample 4\n",
      "[7756638.108 -363957.311      -0.709       8.55  7756610.337 -363937.999\n",
      "      -0.563       8.57        0.002] -> [0.00232407 0.00214892 0.00210711 0.00178109 0.00174303 0.00154065\n",
      " 0.00165366 0.00138977 0.00142586 0.00133868 0.00140511 0.0015047\n",
      " 0.00134962 0.00146287 0.0015939  0.00152234 0.00139348 0.00129478\n",
      " 0.00133026 0.00113164 0.00127172 0.00113717 0.00141812 0.00103883\n",
      " 0.00114803 0.00124032 0.00135568 0.00094439 0.001011   0.00121233\n",
      " 0.00113805 0.00083001 0.00087263 0.00074808 0.00069148 0.00095359\n",
      " 0.00103667 0.0006719  0.00070782 0.00063463 0.00117721 0.00054433\n",
      " 0.00100747 0.00037697 0.00074537 0.00082    0.00035711 0.0007299\n",
      " 0.00015986 0.00020442] (expected [ 0.002  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.\n",
      "  0.     0.     0.    -0.    -0.    -0.    -0.    -0.001 -0.001 -0.001\n",
      " -0.001 -0.001 -0.001 -0.001 -0.001 -0.002 -0.002 -0.002 -0.002 -0.002\n",
      " -0.002 -0.002 -0.002 -0.002 -0.003 -0.003 -0.003 -0.003 -0.003 -0.003\n",
      " -0.003 -0.003 -0.004 -0.004 -0.004 -0.004 -0.004 -0.004 -0.004 -0.004])\n",
      "Sample 5\n",
      "[7756976.04  -363682.125       3.023       8.55  7757010.652 -363686.688\n",
      "       3.016       8.693      -0.001] -> [-0.00036971 -0.00022757 -0.00013879 -0.0005068  -0.00044571 -0.00017808\n",
      " -0.00040148 -0.00022306 -0.00038128 -0.00028458 -0.00004626 -0.00003966\n",
      " -0.00017553 -0.00003827  0.00003947 -0.00005672 -0.00023255  0.00013199\n",
      "  0.00008418  0.00011618  0.00017987  0.00018185  0.00026101  0.00026655\n",
      "  0.00023097  0.00035531  0.00036519  0.00035378  0.00020746  0.00034454\n",
      "  0.00029994  0.00021513  0.00047799  0.00015466  0.00022811  0.00022145\n",
      "  0.00034855  0.00043793  0.00020819  0.00037275  0.00059206  0.00034955\n",
      "  0.00048175  0.00036973  0.00054426  0.0001883   0.00026261  0.00018697\n",
      "  0.00008153  0.00014341] (expected [-0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.    -0.\n",
      " -0.    -0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001 -0.001])\n"
     ]
    }
   ],
   "source": [
    "#CONFIGURAR PARA VARIAS SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "#import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "#y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,150))\n",
    "#APENAS PHI\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(1,150, 3))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "#X_train = X_train_raw\n",
    "#X_test = X_test_raw\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "#y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 150)\n",
    "#APENAS PHI\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 50)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "#y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 150)\n",
    "#APENAS PHI\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 50)\n",
    "\"\"\"\n",
    "# Define the model (clean)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 50)\n",
    ")\n",
    "\n",
    "# Define the model (clean+1camada)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 24),\n",
    "    torch.nn.Linear(24, 48),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(48, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 150)\n",
    ")\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 2400),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2400, 1200),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1200, 600),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(600, 150)\n",
    ")\n",
    "\n",
    "# Define the model - maior3\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 2400),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2400, 1200),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1200, 600),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(600, 300),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(300, 150)\n",
    ")\n",
    "\n",
    "# Define the model - clean v2\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 240),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(240, 120),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(120, 60),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(60, 30),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(30, 150)\n",
    ")\n",
    "\n",
    "\n",
    "# Define the model - maior4\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 150),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(150, 300),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(300, 600),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(600, 1200),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1200, 150)\n",
    ")\n",
    "\"\"\"\n",
    "# Define the model (clean saindo somente phi, mais complexa1)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 50),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 100),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 50),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 50)\n",
    ")\n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "#loss_fn = torch.nn.L1Loss()  # mean absolute error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)#inicial: 0.0001\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "# Check if CUDA is available and set PyTorch to use GPU or CPU accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device) \n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end].to(device)  # Modify this line\n",
    "            y_batch = y_train[start:end].to(device)  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test.to(device))\n",
    "    mse = loss_fn(y_pred, y_test.to(device))\n",
    "    mse = float(mse)\n",
    "\n",
    "    print(\"Epoch: %d MSE: %.5f\" % (epoch,mse))\n",
    "\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.5f\" % best_mse)\n",
    "print(\"RMSE: %.5f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    "\n",
    "from playsound import playsound\n",
    "playsound('/mnt/Dados/caiopinho/Downloads/bell-ringing-05.mp3') \n",
    " \n",
    "model.eval()\n",
    "\n",
    "values = [[7757819.500, -363524.875, 2.687, 7.901, 7757828.500, -363530.219, 2.569, 7.668, 0.030]]\n",
    "arr = np.array(values)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test out inference with specific example\n",
    "    for i in range(1):\n",
    "        X_sample = arr[i:i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32).to(device)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{arr} -> {y_pred[0].cpu().numpy()}\") \n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    np.set_printoptions(suppress=True)\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        print(f\"Sample {i+1}\")\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32).to(device)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].cpu().numpy()} (expected {y_test[i].cpu().numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "values = [[7757819.500, -363524.875, 2.687, 7.901, 7757828.500, -363530.219, 2.569, 7.668, 0.030]]\n",
    "arr = np.array(values)\n",
    "\n",
    "print(arr)\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(1):\n",
    "        X_sample = arr[i:i+1]\n",
    "        print(type(X_sample))\n",
    "        print(X_sample)\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        print(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32).to(device)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].cpu().numpy()} (expected {y_test[i].cpu().numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "values = [[7757857.500, -363554.156, 2.437, 8.550, 7757865.500, -363561.062, 2.411, 0.000, 0.000]]\n",
    "arr = np.array(values)\n",
    "\n",
    "print(arr)\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(1):\n",
    "        X_sample = arr[i:i+1]\n",
    "        print(type(X_sample))\n",
    "        print(X_sample)\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        print(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7756976.04  -363682.125       3.023       8.55  7757010.652 -363686.688\n",
      "        3.016       8.693      -0.001]]\n",
      "[[-0.58768741  0.52995802  1.49273882  0.48334908 -0.51162974  0.4988334\n",
      "   1.48559325  0.65581588  0.02689979]]\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "with torch.no_grad():\n",
    "    dummy_input = X_test_raw[i: i+1]\n",
    "    print(dummy_input)\n",
    "    dummy_input = scaler.transform(dummy_input)\n",
    "    print(dummy_input)\n",
    "    dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "    traced_script_module = torch.jit.trace(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"model_clean_apenas_phi_mais_complexo1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757221.59101824 -363789.70468912       0.01397832       7.59322021\n",
      " 7757224.61858782 -363788.19118057       0.01552358       7.48635167\n",
      "      -0.00234306]\n",
      "[417.82589187 202.99662383   2.01577238   1.97947987 418.20592315\n",
      " 203.48112318   2.01971598   1.83991937   0.0499284 ]\n"
     ]
    }
   ],
   "source": [
    "mean = scaler.mean_\n",
    "std_dev = scaler.scale_\n",
    "print(mean)\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757225.05264482 -363788.90212366       0.02647504       7.60650176\n",
      " 7757227.86445566 -363787.52767805       0.02886931       7.49126291\n",
      "      -0.00282856]\n",
      "[418.6078148  203.42717893   2.01170859   1.96145779 418.95064762\n",
      " 203.91455788   2.0160845    1.85034947   0.0512243 ]\n"
     ]
    }
   ],
   "source": [
    "#maior1\n",
    "mean = scaler.mean_\n",
    "std_dev = scaler.scale_\n",
    "print(mean)\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_test_cpp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m7757481.724\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m363634.012\u001b[39m, \u001b[39m2.313\u001b[39m, \u001b[39m8.372\u001b[39m, \u001b[39m7757506.813\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m363650.764\u001b[39m, \u001b[39m2.799\u001b[39m, \u001b[39m7.703\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.037\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_test_cpp \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(X_test_cpp)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(X_test_cpp)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:1003\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    989\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \n\u001b[1;32m    991\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39m        Transformed array.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1003\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1005\u001b[0m     copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m   1006\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1007\u001b[0m         X,\n\u001b[1;32m   1008\u001b[0m         reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1013\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[1;32m   1460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1461\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_test_cpp = np.array([7757481.724, -363634.012, 2.313, 8.372, 7757506.813, -363650.764, 2.799, 7.703, -0.037])\n",
    "X_test_cpp = scaler.transform(X_test_cpp)\n",
    "print(X_test_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0573,  1.5971, -0.0614, -0.1519,  2.0956,  0.6641,  0.5896, -0.4267,\n",
      "          1.4114]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=24, bias=True)\n",
       "  (1): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (2): Linear(in_features=12, out_features=6, bias=True)\n",
       "  (3): Linear(in_features=6, out_features=150, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n",
      "          1.2702]])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have a trained model 'model'\n",
    "#dummy_input = torch.randn(1, 9)  # Adjust as necessary\n",
    "dummy_input = X_test_raw[i: i+1]\n",
    "dummy_input = scaler.transform(dummy_input)\n",
    "dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "print(dummy_input)\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Dados/caiopinho/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.ones(1, 9, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Convert the model to Torch Script\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, dummy_input)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Save the Torch Script module\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m script_module\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/jit/_trace.py:778\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    773\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrace doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support compiling individual module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms functions.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    774\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use trace_module\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m     )\n\u001b[1;32m    777\u001b[0m name \u001b[39m=\u001b[39m _qualified_name(func)\n\u001b[0;32m--> 778\u001b[0m traced \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_function_from_trace(\n\u001b[1;32m    779\u001b[0m     name, func, example_inputs, var_lookup_fn, strict, _force_outplace\n\u001b[1;32m    780\u001b[0m )\n\u001b[1;32m    782\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m check_trace:\n",
      "\u001b[0;31mTypeError\u001b[0m: _create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"model.onnx\")\n",
    "\n",
    "# Convert the model to Torch Script\n",
    "script_module = torch.jit.trace(model, dummy_input)\n",
    "\n",
    "# Save the Torch Script module\n",
    "script_module.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "       -2.487       4.803       0.001]]\n",
      "[[ 1.16240348 -0.45512402 -1.25481378  0.4579256   1.19118628 -0.4031037\n",
      "  -1.25742504 -1.43256721  0.07519625]]\n",
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001]\n"
     ]
    }
   ],
   "source": [
    "X_sample2 = X_test_raw[0: 1]\n",
    "print(X_sample2)\n",
    "\n",
    "X_sample2 = scaler.transform(X_sample2)\n",
    "print(X_sample2)\n",
    "X_sample2 = X_test_raw[0]\n",
    "print(X_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001] -> [ 4.8010063  -0.00074159  0.01997822  4.8005514  -0.00091523  0.02000268\n",
      "  4.814805   -0.00176182  0.01970529  4.8287263  -0.000778    0.02051836\n",
      "  4.8326116  -0.00174367  0.01992373  4.856453   -0.00167146  0.01983681\n",
      "  4.864167   -0.00193731  0.01993301  4.879089   -0.00164818  0.02014743\n",
      "  4.8937235  -0.00073487  0.02012613  4.8967085  -0.00159477  0.01993886\n",
      "  4.9280586  -0.00181691  0.01975316  4.925619   -0.00195716  0.02010386\n",
      "  4.950785   -0.00190242  0.02001777  4.957052   -0.00186971  0.0202428\n",
      "  4.97818    -0.00249793  0.01988537  4.995721   -0.00255796  0.02014657\n",
      "  4.994455   -0.0025937   0.01995826  5.008133   -0.00280979  0.02011759\n",
      "  5.0308924  -0.00291541  0.01984772  5.0377316  -0.00323275  0.02050596\n",
      "  5.0456805  -0.00307235  0.0199565   5.065904   -0.00340613  0.01975301\n",
      "  5.074639   -0.00332363  0.01996499  5.1010294  -0.00328155  0.01999776\n",
      "  5.1006637  -0.00362112  0.01982425  5.1268015  -0.00374103  0.01991623\n",
      "  5.138431   -0.00395512  0.01991449  5.14359    -0.00391159  0.01998987\n",
      "  5.1597624  -0.00423715  0.0200338   5.164531   -0.00380588  0.01998207\n",
      "  5.1826973  -0.00437438  0.02011609  5.1961102  -0.00469906  0.02033865\n",
      "  5.2155013  -0.00415806  0.02007735  5.2181277  -0.00392795  0.01971572\n",
      "  5.235365   -0.0039203   0.02010624  5.2443867  -0.00465819  0.01985199\n",
      "  5.254088   -0.00413277  0.02006014  5.2746816  -0.0038663   0.0199084\n",
      "  5.2876625  -0.00470388  0.0199628   5.2932086  -0.00375362  0.02029131\n",
      "  5.3144155  -0.0036635   0.02001484  5.3334975  -0.00344844  0.01998478\n",
      "  5.3484445  -0.00428118  0.01996177  5.3510637  -0.00424473  0.0199277\n",
      "  5.3572283  -0.00406776  0.02008447  5.3868194  -0.00447915  0.02004181\n",
      "  5.3942337  -0.00368278  0.01986287  5.4088097  -0.00456195  0.02005492\n",
      "  5.414704   -0.00376444  0.02006499  5.440771   -0.0048934   0.01993128] (expected [4.803 0.001 0.02  4.819 0.001 0.02  4.835 0.001 0.02  4.851 0.001 0.02\n",
      " 4.867 0.001 0.02  4.883 0.001 0.02  4.899 0.001 0.02  4.915 0.001 0.02\n",
      " 4.931 0.001 0.02  4.947 0.001 0.02  4.963 0.001 0.02  4.979 0.001 0.02\n",
      " 4.995 0.001 0.02  5.011 0.001 0.02  5.027 0.001 0.02  5.043 0.001 0.02\n",
      " 5.059 0.001 0.02  5.075 0.001 0.02  5.091 0.001 0.02  5.107 0.001 0.02\n",
      " 5.123 0.001 0.02  5.139 0.001 0.02  5.155 0.001 0.02  5.171 0.    0.02\n",
      " 5.187 0.    0.02  5.203 0.    0.02  5.219 0.    0.02  5.235 0.    0.02\n",
      " 5.251 0.    0.02  5.267 0.    0.02  5.283 0.    0.02  5.299 0.    0.02\n",
      " 5.315 0.    0.02  5.331 0.    0.02  5.347 0.    0.02  5.363 0.    0.02\n",
      " 5.379 0.    0.02  5.395 0.    0.02  5.411 0.    0.02  5.427 0.    0.02\n",
      " 5.443 0.    0.02  5.459 0.    0.02  5.475 0.    0.02  5.491 0.    0.02\n",
      " 5.507 0.    0.02  5.523 0.    0.02  5.539 0.    0.02  5.555 0.    0.02\n",
      " 5.571 0.    0.02  5.587 0.001 0.02 ])\n",
      "[7757801.761 -363519.424       3.074       8.016 7757831.521 -363531.805\n",
      "       2.493       8.334       0.025] -> [8.332953   0.02570583 0.02057826 8.279287   0.0260936  0.01937635\n",
      " 8.279661   0.02568588 0.02047574 8.281424   0.02454777 0.01915007\n",
      " 8.274772   0.02515006 0.02098195 8.281982   0.02503929 0.01914372\n",
      " 8.278026   0.02583499 0.0184833  8.280119   0.02489562 0.02037758\n",
      " 8.2803     0.02479535 0.02028337 8.273154   0.02475645 0.01960913\n",
      " 8.286489   0.02491888 0.01928371 8.275139   0.02615823 0.01904969\n",
      " 8.283588   0.0249912  0.020569   8.279796   0.02533591 0.02059739\n",
      " 8.283659   0.02476165 0.02070565 8.287676   0.02572682 0.02014912\n",
      " 8.276308   0.02517223 0.01923848 8.27715    0.02432403 0.01998729\n",
      " 8.284091   0.0255501  0.01925227 8.280431   0.02544269 0.02009993\n",
      " 8.276081   0.0244431  0.01982384 8.280431   0.02421162 0.0209767\n",
      " 8.276962   0.02461271 0.02015173 8.288047   0.02541332 0.02063011\n",
      " 8.277835   0.02415167 0.02029199 8.287139   0.0238065  0.01952587\n",
      " 8.285027   0.02313591 0.01905958 8.280449   0.02377018 0.01999696\n",
      " 8.28143    0.02516142 0.02103802 8.275567   0.02468783 0.02011264\n",
      " 8.279786   0.02446736 0.0203737  8.279707   0.02499932 0.01933622\n",
      " 8.283042   0.02523439 0.01940995 8.276601   0.02493435 0.01961403\n",
      " 8.27914    0.02568574 0.02154677 8.276657   0.02521071 0.02053792\n",
      " 8.274283   0.02505938 0.02104003 8.278971   0.02595724 0.01849017\n",
      " 8.2789345  0.02633464 0.01930214 8.273977   0.02619009 0.02057384\n",
      " 8.278184   0.02495228 0.0193009  8.282623   0.02417462 0.0207606\n",
      " 8.285052   0.02478037 0.02051708 8.276708   0.02573486 0.01951893\n",
      " 8.273311   0.02499515 0.0200881  8.283986   0.02586628 0.01974319\n",
      " 8.279172   0.02529712 0.02044044 8.281159   0.02531607 0.01932614\n",
      " 8.275503   0.02524789 0.01950336 8.284525   0.02565493 0.01986678] (expected [8.334 0.025 0.02  8.332 0.025 0.02  8.331 0.025 0.02  8.329 0.025 0.02\n",
      " 8.327 0.025 0.02  8.326 0.025 0.02  8.324 0.025 0.02  8.323 0.025 0.02\n",
      " 8.321 0.025 0.02  8.319 0.025 0.02  8.318 0.025 0.02  8.316 0.025 0.02\n",
      " 8.315 0.025 0.02  8.313 0.025 0.02  8.312 0.025 0.02  8.31  0.025 0.02\n",
      " 8.308 0.026 0.02  8.307 0.026 0.02  8.305 0.026 0.02  8.304 0.026 0.02\n",
      " 8.302 0.026 0.02  8.3   0.026 0.02  8.299 0.026 0.02  8.297 0.026 0.02\n",
      " 8.296 0.026 0.02  8.294 0.026 0.02  8.292 0.026 0.02  8.291 0.026 0.02\n",
      " 8.289 0.027 0.02  8.288 0.027 0.02  8.286 0.027 0.02  8.285 0.027 0.02\n",
      " 8.283 0.027 0.02  8.281 0.027 0.02  8.28  0.027 0.02  8.278 0.028 0.02\n",
      " 8.277 0.028 0.02  8.275 0.028 0.02  8.273 0.028 0.02  8.272 0.029 0.02\n",
      " 8.27  0.029 0.02  8.269 0.029 0.02  8.267 0.029 0.02  8.265 0.03  0.02\n",
      " 8.264 0.03  0.02  8.262 0.03  0.02  8.261 0.031 0.02  8.259 0.031 0.02\n",
      " 8.257 0.031 0.02  8.256 0.032 0.02 ])\n",
      "[7757398.832 -363523.465       2.313       8.55  7757418.023 -363547.615\n",
      "       2.224       7.703       0.001] -> [7.68352    0.00130333 0.02032702 7.641883   0.00083899 0.02039786\n",
      " 7.6465163  0.00056658 0.02013385 7.6483893  0.00194509 0.02029281\n",
      " 7.6505     0.00100994 0.01988105 7.6568565  0.00122235 0.02029719\n",
      " 7.6596446  0.00039227 0.02037289 7.662617   0.00142402 0.02003271\n",
      " 7.667677   0.00241441 0.01962855 7.669256   0.00201954 0.02052943\n",
      " 7.6761103  0.00163754 0.01999038 7.6771     0.00058164 0.02000098\n",
      " 7.683269   0.00165032 0.02034155 7.684547   0.00150722 0.01954996\n",
      " 7.6919785  0.00146589 0.02018756 7.695269   0.0005441  0.0205392\n",
      " 7.6975493  0.00094914 0.02031845 7.700929   0.00180373 0.02080054\n",
      " 7.7061877  0.00045523 0.02029929 7.7079177  0.00016031 0.01984137\n",
      " 7.711619   0.00095294 0.01972057 7.7176385  0.00099961 0.01966164\n",
      " 7.720926   0.00110845 0.02040421 7.725027   0.00096409 0.01933991\n",
      " 7.726849   0.00044702 0.01945675 7.7329917  0.00127519 0.02017855\n",
      " 7.737667   0.00104059 0.02027552 7.738297   0.00138625 0.02069708\n",
      " 7.7441926  0.00089028 0.02004447 7.7461205  0.00130421 0.02008313\n",
      " 7.749738   0.00169409 0.02011915 7.7536077  0.00105089 0.02062368\n",
      " 7.760129   0.00061737 0.02020869 7.760017   0.0009951  0.01945942\n",
      " 7.7652626  0.00119765 0.01941936 7.7676105  0.00134489 0.01985163\n",
      " 7.770476   0.00189952 0.01999766 7.776159   0.00147761 0.02066216\n",
      " 7.7798986  0.00109136 0.01993258 7.7812815  0.0016046  0.02023147\n",
      " 7.788701   0.00245623 0.02079733 7.793334   0.00313549 0.02034777\n",
      " 7.795774   0.00259195 0.01947185 7.7981896  0.00216164 0.01940961\n",
      " 7.7987413  0.0028218  0.01963487 7.8069115  0.00203289 0.02025949\n",
      " 7.810602   0.00299086 0.02001701 7.8133383  0.00247199 0.01974632\n",
      " 7.816203   0.00330944 0.02070255 7.8224535  0.00220504 0.01950284] (expected [7.703 0.001 0.02  7.707 0.001 0.02  7.712 0.001 0.02  7.716 0.001 0.02\n",
      " 7.72  0.001 0.02  7.725 0.001 0.02  7.729 0.001 0.02  7.734 0.001 0.02\n",
      " 7.738 0.001 0.02  7.742 0.001 0.02  7.747 0.001 0.02  7.751 0.001 0.02\n",
      " 7.755 0.001 0.02  7.76  0.001 0.02  7.764 0.001 0.02  7.769 0.001 0.02\n",
      " 7.773 0.001 0.02  7.777 0.001 0.02  7.782 0.001 0.02  7.786 0.001 0.02\n",
      " 7.791 0.001 0.02  7.795 0.001 0.02  7.799 0.001 0.02  7.804 0.001 0.02\n",
      " 7.808 0.001 0.02  7.813 0.001 0.02  7.817 0.001 0.02  7.821 0.001 0.02\n",
      " 7.826 0.001 0.02  7.83  0.001 0.02  7.835 0.001 0.02  7.839 0.001 0.02\n",
      " 7.843 0.001 0.02  7.848 0.001 0.02  7.852 0.001 0.02  7.857 0.001 0.02\n",
      " 7.861 0.001 0.02  7.865 0.001 0.02  7.87  0.001 0.02  7.874 0.001 0.02\n",
      " 7.878 0.001 0.02  7.883 0.001 0.02  7.887 0.001 0.02  7.892 0.001 0.02\n",
      " 7.896 0.001 0.02  7.9   0.001 0.02  7.905 0.001 0.02  7.909 0.001 0.02\n",
      " 7.914 0.001 0.02  7.918 0.001 0.02 ])\n",
      "[7756536.421 -363779.861       1.18        8.55  7756528.942 -363813.723\n",
      "       1.441       8.68       -0.007] -> [ 8.648965   -0.00748847  0.02032312  8.593876   -0.00899696  0.02150925\n",
      "  8.5948105  -0.00896706  0.02008479  8.58801    -0.00458245  0.02139455\n",
      "  8.591499   -0.00721812  0.01868896  8.588325   -0.00662043  0.02156892\n",
      "  8.590234   -0.00932901  0.02237298  8.5854225  -0.00596195  0.0196064\n",
      "  8.587645   -0.00375348  0.01870826  8.590537   -0.00439189  0.02173356\n",
      "  8.581299   -0.00550023  0.02065581  8.587846   -0.00899826  0.02101593\n",
      "  8.5828     -0.00535823  0.02023461  8.580964   -0.0060997   0.01808261\n",
      "  8.584315   -0.00537994  0.01971883  8.577991   -0.00857803  0.02118644\n",
      "  8.587483   -0.00700641  0.021599    8.58501    -0.00396815  0.02187604\n",
      "  8.579759   -0.00841048  0.02152368  8.5788145  -0.00893942  0.01926094\n",
      "  8.583215   -0.00601663  0.01948993  8.582711   -0.00559088  0.01828561\n",
      "  8.585115   -0.00567044  0.02085053  8.572363   -0.00679334  0.01776277\n",
      "  8.579396   -0.00675549  0.0184348   8.573252   -0.00431146  0.02105259\n",
      "  8.577254   -0.00418436  0.02162115  8.574989   -0.00399152  0.0217767\n",
      "  8.57805    -0.00653502  0.01914867  8.58017    -0.00506145  0.02012574\n",
      "  8.574344   -0.00387561  0.01986536  8.574201   -0.00594503  0.02222824\n",
      "  8.575941   -0.00736262  0.02103469  8.574182   -0.00618547  0.0190888\n",
      "  8.573944   -0.00645809  0.01701276  8.573064   -0.00555292  0.0190782\n",
      "  8.573169   -0.00409814  0.01893005  8.571572   -0.00615226  0.0231559\n",
      "  8.570943   -0.00733435  0.02050165  8.570824   -0.00616522  0.01997779\n",
      "  8.573595   -0.00285508  0.02266856  8.569768   -0.0005482   0.0200972\n",
      "  8.563346   -0.00242199  0.01813856  8.569615   -0.00433783  0.01900239\n",
      "  8.565632   -0.00200707  0.01899615  8.562543   -0.00488578  0.02088645\n",
      "  8.567423   -0.00223367  0.01964829  8.562147   -0.00337069  0.01994379\n",
      "  8.566233   -0.00156729  0.02223463  8.560793   -0.00444076  0.01894637] (expected [ 8.68  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02\n",
      "  8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.009  0.02\n",
      "  8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55\n",
      " -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009\n",
      "  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02 ])\n",
      "[7757309.348 -363499.087      -2.407       6.407 7757333.518 -363490.282\n",
      "       3.096       6.789       0.063] -> [6.7516246  0.06393541 0.0203922  6.714112   0.06429583 0.01986296\n",
      " 6.7130346  0.06421862 0.02037632 6.714601   0.06174846 0.01862007\n",
      " 6.690399   0.06312048 0.02134422 6.7101917  0.06299231 0.01969864\n",
      " 6.697115   0.0635093  0.01890697 6.6980944  0.06255621 0.02043486\n",
      " 6.696756   0.06170458 0.02021852 6.673561   0.0622045  0.01976297\n",
      " 6.710045   0.06274613 0.02008623 6.674609   0.0626265  0.01846962\n",
      " 6.6977534  0.06200032 0.02084127 6.681123   0.06232089 0.02072971\n",
      " 6.691144   0.06180153 0.02126975 6.7009463  0.06254116 0.01991961\n",
      " 6.6646037  0.06192434 0.01919109 6.663426   0.06095931 0.02039833\n",
      " 6.6841207  0.06183478 0.01955387 6.6679854  0.06177959 0.01980429\n",
      " 6.652021   0.06063057 0.01983571 6.6637483  0.06052557 0.02118478\n",
      " 6.650559   0.06046109 0.02037393 6.679942   0.06084244 0.02039348\n",
      " 6.64709    0.05994342 0.02032236 6.6720653  0.05926207 0.01921879\n",
      " 6.664455   0.05888236 0.0193051  6.647466   0.0593219  0.0200149\n",
      " 6.6470604  0.06064299 0.02071782 6.626414   0.05951655 0.02003768\n",
      " 6.635787   0.05980266 0.02034537 6.635339   0.06039565 0.01852893\n",
      " 6.6426735  0.06026457 0.01953453 6.6192966  0.05949992 0.02007317\n",
      " 6.6249437  0.06008597 0.02125828 6.615039   0.05911204 0.02098817\n",
      " 6.6027455  0.05909542 0.02104271 6.616658   0.06002344 0.01874468\n",
      " 6.613754   0.06030071 0.01947895 6.5958104  0.05995737 0.01991723\n",
      " 6.606965   0.05849443 0.01943179 6.617211   0.05763273 0.02095491\n",
      " 6.620795   0.05855547 0.02065229 6.593711   0.05880125 0.01958214\n",
      " 6.578475   0.05770756 0.01979366 6.6092935  0.05872704 0.01973746\n",
      " 6.593334   0.05818869 0.02065203 6.594169   0.05764527 0.0194798\n",
      " 6.5751987  0.05768259 0.01949466 6.601967   0.05686679 0.01971253] (expected [6.789 0.063 0.02  6.787 0.063 0.02  6.785 0.063 0.02  6.783 0.063 0.02\n",
      " 6.781 0.063 0.02  6.779 0.063 0.02  6.777 0.063 0.02  6.775 0.063 0.02\n",
      " 6.773 0.063 0.02  6.771 0.063 0.02  6.769 0.063 0.02  6.767 0.063 0.02\n",
      " 6.765 0.063 0.02  6.763 0.063 0.02  6.761 0.063 0.02  6.759 0.063 0.02\n",
      " 6.757 0.064 0.02  6.755 0.064 0.02  6.753 0.064 0.02  6.751 0.064 0.02\n",
      " 6.75  0.064 0.02  6.748 0.064 0.02  6.746 0.064 0.02  6.744 0.064 0.02\n",
      " 6.742 0.064 0.02  6.74  0.064 0.02  6.738 0.064 0.02  6.736 0.065 0.02\n",
      " 6.734 0.065 0.02  6.732 0.065 0.02  6.73  0.065 0.02  6.728 0.065 0.02\n",
      " 6.726 0.066 0.02  6.724 0.066 0.02  6.722 0.066 0.02  6.72  0.066 0.02\n",
      " 6.718 0.067 0.02  6.716 0.067 0.02  6.714 0.067 0.02  6.712 0.067 0.02\n",
      " 6.71  0.068 0.02  6.708 0.068 0.02  6.706 0.068 0.02  6.705 0.069 0.02\n",
      " 6.703 0.069 0.02  6.701 0.07  0.02  6.699 0.07  0.02  6.697 0.071 0.02\n",
      " 6.695 0.071 0.02  6.693 0.072 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "np.set_printoptions(suppress=True)\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.02\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75696163e+06 -3.64057635e+05 -1.38000000e-01  8.54600000e+00\n",
      "  7.75692823e+06 -3.64053126e+05 -1.32000000e-01  8.49100000e+00\n",
      " -2.00000000e-03] -> [ 8.4910440e+00 -2.1275878e-03  2.0009704e-02] (expected [ 8.491e+00 -2.000e-03  2.000e-02])\n",
      "[ 7.75720516e+06 -3.63589039e+05 -2.53100000e+00  8.55000000e+00\n",
      "  7.75723371e+06 -3.63569516e+05 -2.49900000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609583e+00 -6.1482787e-03  2.0036645e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75717733e+06 -3.63615552e+05  1.04800000e+00  4.16700000e+00\n",
      "  7.75716855e+06 -3.63636256e+05  1.09200000e+00  5.54400000e+00\n",
      "  6.30000000e-02] -> [5.5442753  0.06288677 0.02018113] (expected [5.544 0.063 0.02 ])\n",
      "[ 7.75719467e+06 -3.63595825e+05 -2.57200000e+00  8.52500000e+00\n",
      "  7.75722353e+06 -3.63576869e+05 -2.54100000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609735e+00 -6.1470866e-03  2.0041056e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75663871e+06 -3.63686725e+05 -2.46600000e+00  8.55000000e+00\n",
      "  7.75666680e+06 -3.63666710e+05 -2.61800000e+00  8.69300000e+00\n",
      "  2.20000000e-02] -> [8.693061   0.02189618 0.01997633] (expected [8.693 0.022 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU COM 3 SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,3))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 3)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 3)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 3)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end]  # Modify this line\n",
    "            y_batch = y_train[start:end]  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75655038e+06 -3.63917271e+05 -2.31000000e-01  5.70200000e+00\n",
      "  7.75653753e+06 -3.63908823e+05 -8.46000000e-01  4.40600000e+00\n",
      "  7.50000000e-02] -> [4.3999896] (expected [4.406])\n",
      "[ 7.75766160e+06 -3.63610685e+05 -2.50900000e+00  8.55000000e+00\n",
      "  7.75768651e+06 -3.63592380e+05 -2.50700000e+00  7.70300000e+00\n",
      " -2.00000000e-03] -> [7.704249] (expected [7.703])\n",
      "[ 7.75754790e+06 -3.63656925e+05 -3.13600000e+00  8.55000000e+00\n",
      "  7.75757851e+06 -3.63654357e+05 -2.96700000e+00  7.70300000e+00\n",
      " -1.50000000e-02] -> [7.705766] (expected [7.703])\n",
      "[ 7.75769361e+06 -3.63590014e+05  6.39000000e-01  8.55000000e+00\n",
      "  7.75766713e+06 -3.63610291e+05  6.52000000e-01  8.52900000e+00\n",
      "  3.00000000e-03] -> [8.52703] (expected [8.529])\n",
      "[ 7.75685868e+06 -3.64044085e+05 -1.26000000e-01  8.55000000e+00\n",
      "  7.75682885e+06 -3.64038885e+05 -1.75000000e-01  7.65400000e+00\n",
      "  1.00000000e-03] -> [7.647367] (expected [7.654])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU (uma saida)\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,1))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 1)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Criando o modelo \n",
    "l0 = tf.keras.layers.Dense(units = 9, input_shape = [9])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 64)\n",
    "#l3 = tf.keras.layers.Dense(units = 93)\n",
    "l3 = tf.keras.layers.Dense(units = 3)\n",
    "\n",
    "\"\"\"Modelo inicial: \n",
    "l0 = tf.keras.layers.Dense(units = 4, input_shape = [4])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 128)\n",
    "l3 = tf.keras.layers.Dense(units = 3) \"\"\"\n",
    "\n",
    "model = tf.keras.Sequential([l0,l1,l2,l3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compilando o modelo\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizers.RMSprop(lr=1e-4))#tf.keras.optimizers.Adam(0.1)), loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Treinar o modelo\n",
    "history = model.fit(inputMatrix,outputMatrix,epochs=500,verbose=False)#epochs inicial=500\n",
    "print(\"Finished training the model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
