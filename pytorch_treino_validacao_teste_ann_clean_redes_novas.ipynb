{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "#Importar bibliotecas\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar vari√°veis\n",
    "dataset_input = \"bin/dataset_input_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\"\n",
    "dataset_output = \"bin/dataset_output_consolidado_todos_comandos_sem_linhas_erro_e_50_comandos.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.06\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXrklEQVR4nO3deXiTVdoG8DtLk3RLujdt6QYUytpigVLAwdFqVVyqDoO4gAzq6KADMuoAIvCNOnUZFR2ZQZ1xF2EYFRGxDhQ3pLTQln2HQgttutKkTdck7/dHmkDoQtOmTZrev+vKhSTnTU9ekdye85xzRIIgCCAiIiLq58TO7gARERGRIzDUEBERkVtgqCEiIiK3wFBDREREboGhhoiIiNwCQw0RERG5BYYaIiIicgsMNUREROQWpM7uQF8xmUwoKSmBr68vRCKRs7tDREREXSAIAmpraxEeHg6xuPOxmAETakpKShAZGensbhAREVE3FBcXY9CgQZ22GTChxtfXF4D5piiVSif3hoiIiLpCp9MhMjLS+j3emQETaixTTkqlkqGGiIion+lK6QgLhYmIiMgtMNQQERGRW2CoISIiIrfQrVCzevVqxMTEQKFQIDk5Gbm5uZ2237BhA+Lj46FQKDBmzBhs2bLF5vUvvvgCN9xwAwIDAyESibB3794O30sQBNx0000QiUTYuHFjd7pPREREbsjuULN+/XosWrQIK1asQH5+PhISEpCWloby8vJ22+/cuROzZs3CvHnzUFBQgPT0dKSnp+PgwYPWNnq9HlOnTsVLL710xZ+/atUq7jNDREREbYgEQRDsuSA5ORkTJkzAW2+9BcC8qV1kZCQef/xxLF68uE37mTNnQq/XY/PmzdbnJk2ahMTERKxZs8am7ZkzZxAbG4uCggIkJia2ea+9e/filltuwZ49exAWFoYvv/wS6enpXeq3TqeDSqWCVqvl6iciIqJ+wp7vb7tGapqbm5GXl4fU1NSLbyAWIzU1FdnZ2e1ek52dbdMeANLS0jps35H6+nrcc889WL16NdRq9RXbNzU1QafT2TyIiIjIfdkVaiorK2E0GhEaGmrzfGhoKDQaTbvXaDQau9p35IknnsDkyZNx++23d6l9RkYGVCqV9cHdhImIiNxbv1j9tGnTJmzfvh2rVq3q8jVLliyBVqu1PoqLi3uvg0REROR0doWaoKAgSCQSlJWV2TxfVlbW4ZSQWq22q317tm/fjlOnTsHPzw9SqRRSqXkj5LvuugvXXHNNu9fI5XLr7sHcRZiIiMj92RVqZDIZkpKSkJWVZX3OZDIhKysLKSkp7V6TkpJi0x4Atm7d2mH79ixevBj79+/H3r17rQ8AeP311/H+++/b8xGIiIjITdl99tOiRYswZ84cjB8/HhMnTsSqVaug1+sxd+5cAMDs2bMRERGBjIwMAMCCBQswbdo0vPrqq5g+fTrWrVuHPXv24J133rG+Z3V1NYqKilBSUgIAOHbsGADzKM+lj8tFRUUhNjbW/k9NREREbsfuUDNz5kxUVFRg+fLl0Gg0SExMRGZmprUYuKioCGLxxQGgyZMnY+3atVi2bBmWLl2KuLg4bNy4EaNHj7a22bRpkzUUAcDdd98NAFixYgVWrlzZ3c/WJ45pavF5/jkEeMvwyLQhzu4OERHRgGX3PjX9VW/tU/PDsXI88P5uxKt9kbnwVw57XyIiIurFfWqorXA/TwBASU2Dk3tCREQ0sDHU9FCYSgEA0DUaoG8yOLk3REREAxdDTQ/5KjzgKzeXJpVqOVpDRETkLAw1DnBxCqrRyT0hIiIauBhqHCDMzzwFxboaIiIi52GocYAwVetIjZYjNURERM7CUOMAEa0jNaUcqSEiInIahhoHsIzUlHKkhoiIyGkYahyANTVERETOx1DjABGW1U/aBgyQDZqJiIhcDkONA6hbN+BrbDGhpr7Fyb0hIiIamBhqHEAulSDIRwYAOM8pKCIiIqdgqHEQFgsTERE5F0ONg4RblnXzqAQiIiKnYKhxEOsGfDwqgYiIyCkYahwknMu6iYiInIqhxkEsh1py+omIiMg5GGochNNPREREzsVQ4yCW6acyXSOMJm7AR0RE1NcYahwkxFcBiVgEg0lARW2Ts7tDREQ04DDUOIhELIJa2VoszLoaIiKiPsdQ40BhrccllLKuhoiIqM8x1DhQmOVgSy7rJiIi6nMMNQ5k3auG009ERER9jqHGgcIt5z9x+omIiKjPMdQ4kLWmhiM1REREfY6hxoEsuwqf50gNERFRn2OocSBLqKmsa0KTwejk3hAREQ0sDDUO5O/lAbnUfEvLtBc34GtsMeKxtflY/f1JZ3WNiIjI7THUOJBIJLKO1ly6AmpD3jls3l+KN7adgMFoclb3iIiI3BpDjYNZl3W37lVjNAn498+nAQDNRhOKquud1jciIiJ3xlDjYJbTuku15mLhbUfKcKbqYpA5WV7nlH4RERG5O4YaBwtX2Y7U/Kt1lEYiFgEATjDUEBER9QqGGgez1NSUahuxt7gGu89cgIdEhHuTowBwpIaIiKi3MNQ42KXnP73bOkpza0I4pgwNAgCcKK91Wt+IiIjcmdTZHXA3lumnwko9jpeZA8yDUwdD4WHOj6fK9TCZBIhbp6OIiIjIMThS42CWkZomgwkmAbg6Lggjw5WICvCCTCJGQ4sR53mKNxERkcMx1DiYj1wKpeLiANiDVw8GAEglYsQGeQNgXQ0REVFvYKjpBZZi4eGhvvhVXJD1+aGhPgBYV0NERNQbGGp6wahwFQDg0WuGQCS6WDsTF2IONRypISIicjwWCveC5beOxH2TojAuyt/m+bgQXwDcq4aIiKg3cKSmF6g8PdoEGgAYahmpKauDIAh93S0iIiK3xlDTh2KCvCARi1DbZEB5bdOVLyAiIqIuY6jpQ3KpBNGBXgCAE2WcgiIiInIkhpo+ZikW5gooIiIix2Ko6WNDraGGIzVERESOxFDTxywroLism4iIyLEYavrYUO5VQ0RE1CsYavrYkGAfiERAtb4ZVXVcAUVEROQoDDV9zFMmQaR/6woojtYQERE5DEONE3AKioiIyPG6FWpWr16NmJgYKBQKJCcnIzc3t9P2GzZsQHx8PBQKBcaMGYMtW7bYvP7FF1/ghhtuQGBgIEQiEfbu3WvzenV1NR5//HEMHz4cnp6eiIqKwh//+EdotdrudN/peAYUERGR49kdatavX49FixZhxYoVyM/PR0JCAtLS0lBeXt5u+507d2LWrFmYN28eCgoKkJ6ejvT0dBw8eNDaRq/XY+rUqXjppZfafY+SkhKUlJTgb3/7Gw4ePIgPPvgAmZmZmDdvnr3ddwlDuVcNERGRw4kEOw8hSk5OxoQJE/DWW28BAEwmEyIjI/H4449j8eLFbdrPnDkTer0emzdvtj43adIkJCYmYs2aNTZtz5w5g9jYWBQUFCAxMbHTfmzYsAH33Xcf9Ho9pNIrn8up0+mgUqmg1WqhVCq78El7z97iGqSv/gUhvnLkPpPq1L4QERG5Mnu+v+0aqWlubkZeXh5SUy9+EYvFYqSmpiI7O7vda7Kzs23aA0BaWlqH7bvK8uG6EmhcjWWkpry2CdqGFif3hoiIyD3YFWoqKythNBoRGhpq83xoaCg0Gk2712g0Grvad7Ufzz33HB5++OEO2zQ1NUGn09k8XIWPXIowlQIA62qIiIgcpd+tftLpdJg+fTpGjhyJlStXdtguIyMDKpXK+oiMjOy7TnaBta6mjHU1REREjmBXqAkKCoJEIkFZWZnN82VlZVCr1e1eo1ar7WrfmdraWtx4443w9fXFl19+CQ8Pjw7bLlmyBFqt1vooLi62++f1pmGh5uMSjvO0biIiIoewK9TIZDIkJSUhKyvL+pzJZEJWVhZSUlLavSYlJcWmPQBs3bq1w/Yd0el0uOGGGyCTybBp0yYoFIpO28vlciiVSpuHKxluDTUcqSEiInIEu6tsFy1ahDlz5mD8+PGYOHEiVq1aBb1ej7lz5wIAZs+ejYiICGRkZAAAFixYgGnTpuHVV1/F9OnTsW7dOuzZswfvvPOO9T2rq6tRVFSEkpISAMCxY8cAmEd51Gq1NdDU19fjk08+samRCQ4OhkQi6dldcILhanOoOaphqCEiInIEu0PNzJkzUVFRgeXLl0Oj0SAxMRGZmZnWYuCioiKIxRcHgCZPnoy1a9di2bJlWLp0KeLi4rBx40aMHj3a2mbTpk3WUAQAd999NwBgxYoVWLlyJfLz85GTkwMAGDp0qE1/CgsLERMTY+/HcLq4UPMZUJV1Taiqa0Kgj9zZXSIiIurX7N6npr9ypX1qLKa98j3OVtVj7YPJmDw0yNndISIicjm9tk8NOZalroZTUERERD3HUONE8WoWCxMRETkKQ40TDVebh9E4UkNERNRzDDVONFxt3oDveFktTKYBUdpERETUaxhqnCgm0BsyqRj1zUacu9Dg7O4QERH1aww1TiSViDE02Dxac4x1NURERD3CUONklk34jmlc58BNIiKi/oihxsm4szAREZFjMNQ42cWRGoYaIiKinmCocTLLXjWnK/VoMhid3BsiIqL+i6HGydRKBXwVUhhNAk5X6J3dHSIion6LocbJRCKRdbSGU1BERETdx1DjAlgsTERE1HMMNS7AclwCl3UTERF1H0ONC7Cc1s3pJyIiou5jqHEBllBTom2ErrHFyb0hIiLqnxhqXIDKywNhKgUA4DhHa4iIiLqFocZFsFiYiIioZxhqXATraoiIiHqGocZFWI9L4GndRERE3cJQ4yIuPQNKEAQn94aIiKj/YahxEUNDfODpIYG2oQX7z2md3R0iIqJ+h6HGRcilElw3IgQA8PW+Eif3hoiIqP9hqHEhtyaEAwA27y+FycQpKCIiInsw1LiQa4YHw1chhUbXiD1nLzi7O0RERP0KQ40LkUslSBulBsApKCIiInsx1LgYyxTUlgOlMBhNTu4NERFR/8FQ42ImDwlEgLcMVfpm7DxV5ezuEBER9RsMNS7GQyLGTaM5BUVERGQvhhoXZJmCyjykQZPB6OTeEBER9Q8MNS5oQkwAQpVy1DYa8NPxSmd3h4iIqF9gqHFBErEIt4w1j9ZwCoqIiKhrGGpclGUKauvhMtQ3G5zcGyIiItfHUOOiEgapEBngiYYWI7YfLXd2d4iIiFweQ42LEolEuGl0GADgl5Nc2k1ERHQlDDUubEiwNwCgVNvg5J4QERG5PoYaFxam8gQAlNY0OrknREREro+hxoWF+ykAcKSGiIioKxhqXJi6daRG12iAvokroIiIiDrDUOPCfORS+CqkADhaQ0REdCUMNS4uTGWZgmJdDRERUWcYalwci4WJiIi6hqHGxV0sFmaoISIi6gxDjYtTK1tHalhTQ0RE1CmGGhcX1jpSU8KRGiIiok4x1Li48NaaGg1HaoiIiDrFUOPi1JbVTywUJiIi6hRDjYuzLOmubTKgtrHFyb0hIiJyXQw1Ls5bLoWydQM+DetqiIiIOsRQ0w+E+5nralgsTERE1DGGmn7AMgXFYmEiIqKOMdT0A5aDLUtYLExERNShboWa1atXIyYmBgqFAsnJycjNze20/YYNGxAfHw+FQoExY8Zgy5YtNq9/8cUXuOGGGxAYGAiRSIS9e/e2eY/GxkbMnz8fgYGB8PHxwV133YWysrLudL/fCbee/8SRGiIioo7YHWrWr1+PRYsWYcWKFcjPz0dCQgLS0tJQXl7ebvudO3di1qxZmDdvHgoKCpCeno709HQcPHjQ2kav12Pq1Kl46aWXOvy5TzzxBL7++mts2LABP/74I0pKSnDnnXfa2/1+Sc1DLYmIiK5IJAiCYM8FycnJmDBhAt566y0AgMlkQmRkJB5//HEsXry4TfuZM2dCr9dj8+bN1ucmTZqExMRErFmzxqbtmTNnEBsbi4KCAiQmJlqf12q1CA4Oxtq1a/Gb3/wGAHD06FGMGDEC2dnZmDRp0hX7rdPpoFKpoNVqoVQq7fnITvfLyUrc+68cDA3xwbZF05zdHSIioj5jz/e3XSM1zc3NyMvLQ2pq6sU3EIuRmpqK7Ozsdq/Jzs62aQ8AaWlpHbZvT15eHlpaWmzeJz4+HlFRUR2+T1NTE3Q6nc2jvwqzbsDXADszKBER0YBhV6iprKyE0WhEaGiozfOhoaHQaDTtXqPRaOxq39F7yGQy+Pn5dfl9MjIyoFKprI/IyMgu/zxXE9ZaKKxvNqK2yeDk3hAREbkmt139tGTJEmi1WuujuLjY2V3qNk+ZBH5eHgB4XAIREVFH7Ao1QUFBkEgkbVYdlZWVQa1Wt3uNWq22q31H79Hc3Iyampouv49cLodSqbR59GdqJVdAERERdcauUCOTyZCUlISsrCzrcyaTCVlZWUhJSWn3mpSUFJv2ALB169YO27cnKSkJHh4eNu9z7NgxFBUV2fU+/ZllV2GugCIiImqf1N4LFi1ahDlz5mD8+PGYOHEiVq1aBb1ej7lz5wIAZs+ejYiICGRkZAAAFixYgGnTpuHVV1/F9OnTsW7dOuzZswfvvPOO9T2rq6tRVFSEkpISAObAAphHaNRqNVQqFebNm4dFixYhICAASqUSjz/+OFJSUrq08skdXFosTERERG3ZHWpmzpyJiooKLF++HBqNBomJicjMzLQWAxcVFUEsvjgANHnyZKxduxbLli3D0qVLERcXh40bN2L06NHWNps2bbKGIgC4++67AQArVqzAypUrAQCvv/46xGIx7rrrLjQ1NSEtLQ3/+Mc/uvWh+6Mw7lVDRETUKbv3qemv+vM+NQDwed45/GnDPkwdGoRPHkx2dneIiIj6RK/tU0POYxmpKWGhMBERUbsYavqJsNZCYY22kRvwERERtYOhpp+wjNTUNxuha+AGfERERJdjqOknFB4S+Fs24NNxCoqIiOhyDDX9iOW4BO4qTERE1BZDTT8S7sdiYSIioo4w1PQj6ta6Gg33qiEiImqDoaYfsUw/lXD6iYiIqA2Gmn7k4q7CnH4iIiK6HENNP2IZqeH0ExERUVsMNf3IpYXC3ICPiIjIFkNNPxKqNIeaxhYTaupbnNwbIiIi18JQ048oPCQIVcoBAKcr9U7uDRERkWthqOln4tXmE0qPlOqc3BMiIiLXwlDTz4wMN4eawww1RERENhhq+pkRYRypISIiag9DTT8zMswXAHBMUwujiSugiIiILBhq+pmYQG/IpWLUNxtxtorFwkRERBYMNf2MVCJGvNo8WnOktNbJvSEiInIdDDX9EOtqiIiI2mKo6YcYaoiIiNpiqOmHLKGGy7qJiIguYqjph+JbV0CVahtRU9/s5N4QERG5Boaafkip8EBkgPnEbo7WEBERmTHU9FMjWo9LOFzCUENERAQw1PRbluMSuKybiIjIjKGmn+IKKCIiIlsMNf3UyNZQc7K8Ds0Gk5N7Q0RE5HwMNf3UIH9P+MqlaDaacKqiztndISIicjqGmn5KJBJxCoqIiOgSDDX92IgwyxlQDDVEREQMNf0YdxYmIiK6iKGmH7t0WbcgCE7uDRERkXMx1PRjw0J9IRYB1fpmlNc2Obs7RERETsVQ048pPCQYHOwDgFNQREREDDX9nKWuZl9xDaegiIhoQJM6uwPUMyPDlPh6XwlWbTuBT3OKkDBIhTERfpgaF4ik6ABnd4+IiKjPcKSmn7s1IQwJg1QQi4CK2iZsO1KO17cdx13/zMYxDc+FIiKigYMjNf3cIH8vfPXYVDQ0G3G4VIv957T4945CnLvQgEMlWgxX+zq7i0RERH2CIzVuwlMmQVJ0AOZOicXUoUEAgLNV9U7uFRERUd9hqHFDkQFeAIDiaoYaIiIaOBhq3FB0oDnUnGWoISKiAYShxg1FB3gD4PQTERENLAw1biiqdaSmsq4J9c0GJ/eGiIiobzDUuCGVpwdUnh4AgCJOQRER0QDBUOOmrHU1nIIiIqIBgqHGTUW1roAqYqghIqIBgqHGTVlGajj9REREAwVDjZuyjNRwWTcREQ0UDDVuKqp1WXdRld7JPSEiIuobDDVuyjL9dO5CA4wmwcm9ISIi6n0MNW4qVKmATCKGwSSgpKbB2d0hIiLqdd0KNatXr0ZMTAwUCgWSk5ORm5vbafsNGzYgPj4eCoUCY8aMwZYtW2xeFwQBy5cvR1hYGDw9PZGamooTJ07YtDl+/Dhuv/12BAUFQalUYurUqfj++++70/0BQSIWYVCAJwAWCxMR0cBgd6hZv349Fi1ahBUrViA/Px8JCQlIS0tDeXl5u+137tyJWbNmYd68eSgoKEB6ejrS09Nx8OBBa5uXX34Zb775JtasWYOcnBx4e3sjLS0NjY2N1ja33HILDAYDtm/fjry8PCQkJOCWW26BRqPpxsceGKIDuFcNERENIIKdJk6cKMyfP9/6e6PRKISHhwsZGRnttv/tb38rTJ8+3ea55ORk4fe//70gCIJgMpkEtVotvPLKK9bXa2pqBLlcLnz22WeCIAhCRUWFAED46aefrG10Op0AQNi6dWuX+q3VagUAglar7doHdQMrvjooRP95s5Cx5Yizu0JERNQt9nx/2zVS09zcjLy8PKSmplqfE4vFSE1NRXZ2drvXZGdn27QHgLS0NGv7wsJCaDQamzYqlQrJycnWNoGBgRg+fDg++ugj6PV6GAwGvP322wgJCUFSUlK7P7epqQk6nc7mMdBEWjbgq+YKKCIicn92hZrKykoYjUaEhobaPB8aGtrhNJBGo+m0veXXztqIRCJs27YNBQUF8PX1hUKhwGuvvYbMzEz4+/u3+3MzMjKgUqmsj8jISHs+qlvg9BMREQ0k/WL1kyAImD9/PkJCQvDzzz8jNzcX6enpuPXWW1FaWtruNUuWLIFWq7U+iouL+7jXzmfdVbiqHoLAZd1EROTe7Ao1QUFBkEgkKCsrs3m+rKwMarW63WvUanWn7S2/dtZm+/bt2Lx5M9atW4cpU6bgqquuwj/+8Q94enriww8/bPfnyuVyKJVKm8dAY5l+qm0yoKa+xcm9ISIi6l12hRqZTIakpCRkZWVZnzOZTMjKykJKSkq716SkpNi0B4CtW7da28fGxkKtVtu00el0yMnJsbaprzdPn4jFtt0Vi8UwmUz2fIQBReEhQahSDoDHJRARkfuze/pp0aJFePfdd/Hhhx/iyJEjePTRR6HX6zF37lwAwOzZs7FkyRJr+wULFiAzMxOvvvoqjh49ipUrV2LPnj147LHHAJjrZRYuXIjnn38emzZtwoEDBzB79myEh4cjPT0dgDkY+fv7Y86cOdi3bx+OHz+Op556CoWFhZg+fboDboP7irYcl8BQQ0REbk5q7wUzZ85ERUUFli9fDo1Gg8TERGRmZloLfYuKimxGVCZPnoy1a9di2bJlWLp0KeLi4rBx40aMHj3a2ubpp5+GXq/Hww8/jJqaGkydOhWZmZlQKBQAzNNemZmZeOaZZ3DttdeipaUFo0aNwldffYWEhISe3gO3FhXohdwz1TwDioiI3J5IGCAVpDqdDiqVClqtdkDV17yZdQKvbT2OGUmD8MoMBkAiIupf7Pn+7hern6j7LCugWFNDRETujqHGzUW1roAqZqghIiI3x1Dj5qIDzYXCGl0jGluMTu4NERFR72GocXP+Xh7wkUshCMC5CxytISIi98VQ4+ZEIpF1CorLuomIyJ0x1AwA1mJhngFFRERujKFmAIhiqCEiogGAoWYA4PQTERENBAw1A0BskHkF1PGyWif3hIiIqPcw1AwAYyJUEImAcxcaUFHb5OzuEBER9QqGmgHAV+GBuBAfAMDe4hrndoaIiKiXMNQMEOMi/QEABUUXnNwTIiKi3sFQM0CMi/IDABQU1bT7uskkIGPLEXyWW9R3nSIiInIgqbM7QH1jXJR5pGb/uRoYTQIkYpHN67+cqsTbP52GSASMDldhzCCVM7pJRETUbRypGSCGhvjARy6FvtmIE+VtV0F9f7QCACAIwPJNB2EyCX3dRSIioh5hqBkgJGIREiLNoy/tTUH9cLzc+s8FRTX4b/65vuoaERGRQzDUDCCJkX4A2hYLF1XV43SFHlKxCI9fOxQA8NK3R6FtaOnrLhIREXUbQ80AcnEFVI3N85ZRmqRofzx+bRyGBHujSt+M17ce7+suEhERdRtDzQCS2LoC6kR5nc0ozPdHzaHm1/EhkEnFWHnbKADAR9lncKRU1+f9JCIi6g6GmgEkyEduPQdq/7kaAEBjixHZp6sAANcMDwYAXB0XjJtGq2ESgBWbDkEQWDRMRESuj6FmgLl8v5pdp6vQ2GJCmEqB4aG+1nbPTB8BhYcYuYXV+O6Qxgk9JSIisg9DzQAz7rJi4R+OmZdyXzM8GCLRxb1rBvl7YXZKDADg24MMNURE5PoYagaYxNZN+PYW10AQBPxwzFxPc83wkDZtf9363C8nK7lvDRERuTyGmgFmZJgSMqkYF+pb8MPxCpypqoeHRIQpQ4PatL0q2g+eHhJU1jXjqKbthn1ERESuhKFmgJFJxRgdrgQArGpdsj0hJgA+8rYnZsilEiQPDgAA7DhZ0XedJCIi6gaGmgHIcg7UvnNaABdXPbVnausIzs8nKnu/Y0RERD3AUDMAWVZAWfy6nXoai6vjzIEnt7AajS3G3uwWERFRjzDUDECWkRoAiPDzxNAQnw7bDgv1QYivHE0GE/LOXuiwHRERkbMx1AxA4SoFgn3lANou5b6cSCTC1DhOQRERketjqBmARCIRbhylhlgE3DEu4ortr24NNSwWJiIiV9Z2yQsNCM/eMhJ/vC7OOmLTGcty70MlOlTVNSHQ58rXEBER9TWO1AxQMqm4S4EGAEJ8FYhX+0IQgF9OVfVyz4iIiLqHoYa6xLK0e8cJTkEREZFrYqihLrEUC+84UclTu4mIyCUx1FCXJMcGQiYRo0TbiNOVemd3h4iIqA2GGuoST5kE42PM+9vs4NJuIiJyQQw11GXcr4aIiFwZQw112dVDzUcm7DpdBZOJdTVERORaGGqoy+LDfAEAdU0GaBtanNwbIiIiWww11GUeEjGUCvN+jVX6Jif3hoiIyBZDDdklqHU34aq6Zif3hIiIyBZDDdklwFsGAKjWM9QQEZFrYaghu1hCTSVDDRERuRiGGrKL5TDLak4/ERGRi2GoIbsEWqefWChMRESuhaGG7MLpJyIiclUMNWSXQJ/WkRpOPxERkYthqCG7BHq31tRwpIaIiFwMQw3ZxTL9xM33iIjI1TDUkF2CWqefLtS38PwnIiJyKQw1ZBf/1pEao0ng+U9ERORSuhVqVq9ejZiYGCgUCiQnJyM3N7fT9hs2bEB8fDwUCgXGjBmDLVu22LwuCAKWL1+OsLAweHp6IjU1FSdOnGjzPt988w2Sk5Ph6ekJf39/pKend6f71APdOf9JEAQcKtGiscXYm10jIqIBzu5Qs379eixatAgrVqxAfn4+EhISkJaWhvLy8nbb79y5E7NmzcK8efNQUFCA9PR0pKen4+DBg9Y2L7/8Mt58802sWbMGOTk58Pb2RlpaGhobG61tPv/8c9x///2YO3cu9u3bh19++QX33HNPNz4y9ZS95z+9+r/jmP7mDmRsOdKb3SIiogFOJAiCXYURycnJmDBhAt566y0AgMlkQmRkJB5//HEsXry4TfuZM2dCr9dj8+bN1ucmTZqExMRErFmzBoIgIDw8HH/605/w5JNPAgC0Wi1CQ0PxwQcf4O6774bBYEBMTAz+7//+D/PmzevWB9XpdFCpVNBqtVAqld16DzL7zT93Ys/ZC/jnvVfhpjFhnbb9Iv8cFv1nHwBgYkwA/vNISl90kYiI3IQ93992jdQ0NzcjLy8PqampF99ALEZqaiqys7PbvSY7O9umPQCkpaVZ2xcWFkKj0di0UalUSE5OtrbJz8/H+fPnIRaLMW7cOISFheGmm26yGe25XFNTE3Q6nc2DHKOrG/DtPlONxZ8fsP6+oo4rpoiIqPfYFWoqKythNBoRGhpq83xoaCg0Gk2712g0mk7bW37trM3p06cBACtXrsSyZcuwefNm+Pv745prrkF1dXW7PzcjIwMqlcr6iIyMtOejUie6cv5TUVU9fv9xHpqNJiRE+gEAKmvtCzXF1fX4suAcV1kREVGX9IvVTyaTCQDwzDPP4K677kJSUhLef/99iEQibNiwod1rlixZAq1Wa30UFxf3ZZfd2pXOf9I1tmDeh7tRrW/G6Agl3r0/CQBQ22RAQ3PXi4VXbDqEJ9bvw4fZZ3rcZyIicn92hZqgoCBIJBKUlZXZPF9WVga1Wt3uNWq1utP2ll87axMWZq7bGDlypPV1uVyOwYMHo6ioqN2fK5fLoVQqbR7kGFeafnp6w36cKK9DqFKOf82egGBfOeRS8x+1SjumoI6WmqcM3/3pNFqMph72moiI3J1doUYmkyEpKQlZWVnW50wmE7KyspCS0n4BaEpKik17ANi6dau1fWxsLNRqtU0bnU6HnJwca5ukpCTI5XIcO3bM2qalpQVnzpxBdHS0PR+BHKCz85+aDSb877B52nDNfUlQqxQQiUQI9jVPWZV3cQqqscWIEq159VuJthGb9pY4outEROTGpPZesGjRIsyZMwfjx4/HxIkTsWrVKuj1esydOxcAMHv2bERERCAjIwMAsGDBAkybNg2vvvoqpk+fjnXr1mHPnj145513AAAikQgLFy7E888/j7i4OMTGxuLZZ59FeHi4dR8apVKJRx55BCtWrEBkZCSio6PxyiuvAABmzJjhiPtAdujs/KfzNQ0wCYCnhwSJrbU0ABDsK8e5Cw1dHqkpqq63+f3bP53CHeMiIBaLut9xIiJya3aHmpkzZ6KiogLLly+HRqNBYmIiMjMzrYW+RUVFEIsvDgBNnjwZa9euxbJly7B06VLExcVh48aNGD16tLXN008/Db1ej4cffhg1NTWYOnUqMjMzoVAorG1eeeUVSKVS3H///WhoaEBycjK2b98Of3//nnx+6obOzn+yhJGoAC+IRBcDiGVvm4oujtScqdQDAAYHeaOitgnHy+qw/Wg5UkeGXuFKIiIaqOzep6a/4j41jlOua8TEv2ZBIhbhxPM32YyefLzrLJ7deBCpI0Lxrznjrc8v/fIA1uYUYcF1cXji+mFX/Bnv/nQaL2w5glvGhmGQvxfW/HgKV0X54fNHJ9uEJSIicm+9tk8NEdD5+U/Fl4zUXCq4daSmq9NPhVXmkZqYQG/8bkoMZFIx8otqsPvMhR71nYiI3BdDDdmts/OfLoYaT5vnLYXCXZ1+OtsaaqIDvRCiVOA3SYMAAGt+PNX9jhMRkVtjqKFu6ej8J2tNTaBXu+27uqvwmUrz+8QGeQMAHr56MMQiYPvRchwp5e7QRETUFkMNdUuAdQO+i6FGEAQUVXUw/WTHSE2TwYgSbQMAIDrQHGpigryt50xxtIaIiNrDUEPd0t4GfNqGFtQ2GQAAg/xtQ02I78WamivVphdX10MQAG+ZBEGte+IAwKPThgAANu0rwf5zNT3+DERE5F4Yaqhb2tuAzzL1FOIrh8JDYtPeMv3U2GJCXWvw6Yhl6ikmyNtmpdPoCBXSE8MhCOYjFHgmFBERXYqhhrrl4gZ8F6eTijpY+QQAnjIJfOTm4uIrTUGduWTl0+WW3DwC3jIJCopq8EXB+e51noiI3BJDDXVLe9NPnYUaoOt1NWdb63KiA9u+T6hSgceviwMAvPjtUdQ2trRpQ0REAxNDDXVLe9NPluXckR2FGuteNe0fhGlhHakJajtSAwBzp8QgNsgblXVNeDPrRJvXT5bX4XxNwxU+ARERuRuGGuqW9s5/utJITZCvOQhV1DZ2+t6dTT8BgFwqwfJbzSe2v//LGZwsrwUAHDinxe8+2I3U137Ejat+QgmDDRHRgGL32U9EQPvnP3W0R41FcBf2qmk2mHD+gjmMxHTwPgDw6+EhSB0Rgm1HyrHkiwNQecqw7UiZ9fXaRgOWf3UI785O4rEKREQDBEdqqFss008X6ltgMgkwGE0oqTGPwPSkpqb4Qj1MAuAlk1jbd2TZ9JGQScTYfeYCth0pg1gE3DkuAu/OHg8PiQjbjpThu0Oa7nw8IiLqhxhqqFv8vWzPfyrVNsJoEiCXiq0jMpcL9r1yTc3F4xG8rzjCEhPkjSfThkEqFuH2xHBsXTQNr81MxPUjQ/FI6542KzYdgo7FxEREAwJDDXWLTGp7/lPRJUXCl57afSnrUQmdjNRY96jpZOrpUg//agiOP38T3rh7HIYE+1ifn//roYgN8kaZrgmvZB7r0nsREVH/xlBD3RZ4yflP1lDj79lh+65MP106UtNV7YUohYcEL9wxGgDwSc5Z5J21Pd1bEIQr7mxMRET9CwuFqdsCvWUorNSjWt98xZVPwKXTT00wmYR2w0hhleUgy66N1HRm8pAgzEgahA1557D0iwNYmBqH/ee1OHBOi/3naiAIwKQhgZgyJBBT44IwJNiHRcVERP0YQw1126Ub8BVdYY8a4OIycENrHY6/t6xNm+6M1HRm6c0jkHW0HMfKavHop/ltXt96uAxbD5tXTYUq5Xjo6sH43ZTYDqfQiIjIdTHUULddugFfcRdGamRSMfy8PFBT34KKuqY2oabFaMI563Jux4Qaf28ZXrxzDP78+X5E+HtiTIQfxg5SYUyECiZBwC8nq/DLyUrsPlONMl0Tnv/mCL4/Vo6/zUhAmKrjqTQiInI9DDXUbZee/3SlPWosgn3k5lBT24Rhob42r52/0ACjSYDCQ2w91dsRbhilxg2j1O2+NnaQHx69ZggaW4z4b945vPDNEfxysgo3rvoZf71jDKaPDXNYP4iIqHexUJi6zTL9VFhVj5p687LpSP8rhJpOioULL9lJuK+nfxQeEtw3KRrf/HEqxg5SQdvQgvlr8/Hkhn0wGE192hciIuoehhrqNsv0077iGgBAkI8M3vLOB/8uLRa+3NlKSz1Nz4uEu2twsA8+f3QyHvv1UIhFwH/zzmFtbpHT+kNERF3HUEPdZpl+0ja0jtJ0Uk9j0dleNWeqLHvUOKaeprs8JGI8mTYcK28bBQBYte0EN/AjIuoHGGqo2wIuK/TtrEjYorPpp7NXOJ27r90zMQpDgr1RrW/G6u9POrs7RER0BQw11G2W6SeLLoWaTg61tIzUOHP66VJSiRhLbx4BAHh/xxnrCi8iInJNDDXUbZbznyyuVCQMAEEdjNQYjCZraHD29NOlro0PweQhgWg2mvDydzxugYjIlTHUULddev4T0LWaGstIzeWFwiU1jTC0HoipVioc29EeEIlEeGb6CIhEwNf7SlBQdPG4hcJKPeZ/mo9pr3yPXaernNhLIiICGGqohwIvOZH7SnvUABdraqr0zTZLpY+V1QIwTz252m6+o8JVuOuqQQCAF745gqq6JqzcdAjXv/YjvjlQirNV9Xjg/Vz8fKLCyT0lIhrYGGqoRwJbi4U9JKIujbAEeMsgFgGCAFTXN1uf//ZAKQAgZXBg73S0h568YTgUHmLsOXsBU17ajg92noHBJOCa4cH41bBgNLaYMO/DPcg6UubsrhIRDVgMNdQjlhVQg/y9IOnCCItELEKAt21dTWOLEf9rPX/ptsTwXuppz6hVCjx89WAAQGOLCSPDlPj0wWR8MHci3p2dhBtGhqLZYMIjn+Qh82Bpn/TJZBLwcfYZPLf5MDcIJCICj0mgHrKsgOpKPY1FsK8clXVN1lDz/dFy1DUZEOHniXGR/r3ST0f4w6+HQiQSITbIG7clhFunyeRSCVbfexWeWL8Xm/eXYv7aAtyeWIbGFiO0DS3QNrSgxSAgIVKFlCGBSBkcBLWqZ3VDpdoG/Ok/+7DzlLmWZ8rQQFwbH9rjz0hE1J8x1FCPWA59HGzH3jLBvnIcKb04UvP1/hIAwC0JYS5XT3MphYcET1w/rN3XPCRivHH3OMikYnyRfx5f5J9v0+ZYWS3+s+ccAPP9uic5Cg+2jv7YY8uBUiz54oB100MA2HmyiqGGiAY8hhrqkXuToyAWAb9JiuzyNRdXQDWjtrEFWUfKAQC3jnXNqaeukohF+NtvEjB5SBDOX2iAylMKPy8ZVJ4eMJoE7D5TjezTVTh4XovTlXo8/80RhCoVuDWha5+7yWDEsi8PYkOeORiNHaTC9SNC8erW4/jlFFdfEREx1FCPBPrI8di1cXZdE+RrnrKqqG3CtiNlaDKYMDjYG6PClb3RxT4lFovwm6RB7b6WOtI8kqJtaMGbWSfw7x2FeObLAxgf428d8erMv34uxIa8cxCJgD9cMwQLU4ehpr4Fr249jiOlOlTrm9vs8kxENJCwUJj63KW7Cm/aa556ui0hHCKR6049OZLK0wOLb4pHwiAVdI0GPLlhH0wmodNrmg0mfLjzDAAg444xeCotHh4SMYJ95Rge6gsA3CuHiAY8hhrqc5a9ak6U1eLnE5UA0OUpGHfhIRHjtZmJUHiI8cvJKnzQGlg68u3BUpTXNiHEV447r7IdCZo81LwMfuepyt7qLhFRv8BQQ33OEmqOamphMAkYFa7EkGAfJ/eq7w0J9sEzrWdLvZh5FMdbNyC8nCAI+PeOQgDA/ZOiIZPa/mc7eUgQAHOxMBHRQMZQQ30u+JJdiIGBN0pzqfsmReOa4cFoNpiwcN1eNBva7jeTX3QB+89pIZOKcU9yVJvXJ8YGQCwCTlfqUapt6ItuExG5JIYa6nOWkRqLgRxqRCIRXr5rLPy9PHC4VIe/bD4EQbCtr3nvlzMAgPTEcJtjKSxUnh4YE6ECAGS3swqqXNeIzIOaNu9LRORuGGqoz6k8PeAhMRcFj4/2R4TflVf+uLMQpQKv/CYBIhHwya4irPnxtPW1kpoGZB7UAADmTont8D1SLFNQl4Uag9GE+/6dg0c+ycO21qXzRETuiqGG+pxIJLJOQQ3kUZpLpY4MxbLpIwEAL2UexcYC8+Z9H2WfhdEkIGVwIEaEdbzkfUprsXD2qSqbEZn/5p3D8bI6AMAOHrhJRG6OoYac4ndTY/GrYcG446oIZ3fFZcybGosHp5pHY5767z5sO1yGz3KLAJjvV2fGRwfAQyLC+ZoGnK2qBwDUNxvw+rbj1ja7z1zopZ4TEbkGhhpyigevHoyPfjcRSoWHs7viUpbePALTx4ahxSjgwY/2QNvQgqgAL1wbH9LpdZ4yCcZFmc/NskxBvbejEGU68zJwADii0UHX2NLhexAR9XcMNUQuRCwW4dUZCZgYG2B97oHJMV06AX3ykIv71VTWNVlrc56ZPgLRgV4QBCD/LEdriMh9MdQQuRiFhwTv3j8eYyJUiA70wozx7R+7cLkpQ83FwtmnqvBm1gnUNRkwJkKFW8eGY3y0OSTtPlPda/0mInI2nv1E5IJUXh74av4UiETo8vERCYP84OkhQZW+GR9lnwUALLkpHmKxCBNj/fF5/jnsLuRIDRG5L47UELkosVhk13lYMqkYEy6ZtrpmeDAmt47eTIgxP7/3XA2aDEbHdpSIyEUw1BC5EUtdjUgELL4p3vp8bJA3gnxkaDaYcOCctkvvVddkQH2zoVf6SUTUGxhqiNzIbQnhiA70wmO/Hop49cV9bUQi0SV1NZ1PQRVX12PJFwcw7i//w21v/YIWY9ujG4iIXBFraojcSLifJ3586tftvjYhNgCZhzTYfaYaj2JIm9cLK/VY/f1JfFlwHkaTeQO/k+V12HGyEr8e3vmSciIiV8BQQzRATIgx72Oz50w1TCYB4kuWiX+acxbPbjyI1iyDq+OCIJOIkXW0HJv2ljDUEFG/wFBDNECMDFPCWyaBrtGA4+W11umpUm0Dnt98BCbBXFy84Lo4jIvyR37RBWQdLcd3hzSobzbAS8a/LojItbGmhmiAkErEuCraPFqzu/DifjUZW46iocWIpGh/vP/ABOvOxOMi/RAV4IX6ZiO2Hi5zSp/dwXeHNO2enk5EjtetULN69WrExMRAoVAgOTkZubm5nbbfsGED4uPjoVAoMGbMGGzZssXmdUEQsHz5coSFhcHT0xOpqak4ceJEu+/V1NSExMREiEQi7N27tzvdJxqwLi8WzjldhU37SiASAf932yibJeQikQi3J5oPHN20t6TvO+sGNNpGPPJJHh76aI+1TomIeo/doWb9+vVYtGgRVqxYgfz8fCQkJCAtLQ3l5eXttt+5cydmzZqFefPmoaCgAOnp6UhPT8fBgwetbV5++WW8+eabWLNmDXJycuDt7Y20tDQ0Nja2eb+nn34a4eE82ZmoOybEto7UnKmGwWjCik2HAACzJkZhdISqTfvbE80Hjv54vALV+ua+66ibOFKqgyCYl8efu1Dv7O4QuT27Q81rr72Ghx56CHPnzsXIkSOxZs0aeHl54b333mu3/RtvvIEbb7wRTz31FEaMGIHnnnsOV111Fd566y0A5lGaVatWYdmyZbj99tsxduxYfPTRRygpKcHGjRtt3uvbb7/F//73P/ztb3+z/5MSEcZF+kMqFqFU24hX/ncMRzW1UHl64MkbhrfbfmiID0ZHKGEwCfjmQGmb17/ZX4r/7Cnu7W73W0c1tdZ/Pl2hd2JPiAYGu0JNc3Mz8vLykJqaevENxGKkpqYiOzu73Wuys7Nt2gNAWlqatX1hYSE0Go1NG5VKheTkZJv3LCsrw0MPPYSPP/4YXl5eV+xrU1MTdDqdzYNooPOUSawjMm+3Hnj5pxuGIcBb1uE16a2jNV8VnLd5/vO8c5i/Nh9P/3c/Civ5hd2e42UXQ82pijon9oRoYLAr1FRWVsJoNCI0NNTm+dDQUGg0mnav0Wg0nba3/NpZG0EQ8MADD+CRRx7B+PHju9TXjIwMqFQq6yMyMrJL1xG5u0tPAI9X++KeiVGdtr9lbDhEImDP2QsorjZPoew8VYnFX+y3ttl1uu8LYQVBwJofT2FdblGf/+yuOqa5NNQw+BH1tn6x+unvf/87amtrsWTJki5fs2TJEmi1WuujuJhD5ETAxXOgAGDlbaMglXT+14BapUDKYPPxC5v2leBEWS1+/3EeWowClArzMm9nhJq9xTV48dujWPLlAdTUu169j8FowslLRmdOc6SGqNfZFWqCgoIgkUhQVma7vLOsrAxqtbrda9RqdaftLb921mb79u3Izs6GXC6HVCrF0KFDAQDjx4/HnDlz2v25crkcSqXS5kFE5o31UkeE4o/XxWFSa1i5EssU1H/zzmHuB7tR22hAUrQ/3rh7HAAg53Q1BKFvV/ds2mdekSUIwK7T1Vdo3ffOVNWj2XDxiInTnKIj6nV2hRqZTIakpCRkZWVZnzOZTMjKykJKSkq716SkpNi0B4CtW7da28fGxkKtVtu00el0yMnJsbZ58803sW/fPuzduxd79+61Lglfv349XnjhBXs+AtGAp/CQ4F9zxmPR9cO6fM2NY9SQScUorNTj3IUGxAR64d3Z4zFpcCBkEjE0ukacreq71T1Gk4Bv9l8sXM4+VdlnP7urLPU0Q4K9AQAVtU3QNbY4s0tEbs/uLUIXLVqEOXPmYPz48Zg4cSJWrVoFvV6PuXPnAgBmz56NiIgIZGRkAAAWLFiAadOm4dVXX8X06dOxbt067NmzB++88w4A814YCxcuxPPPP4+4uDjExsbi2WefRXh4ONLT0wEAUVG2c/4+Pj4AgCFDhmDQoEHd/vBE1DVKhQeuHR6CzEMa+Ht54P25E63FxQmRKuw+cwE5hVWICfLuk/7kFFahvLbJ+vudLri5naWeJinaH7WNBpTXNuF0hR6JkX7O7ZibMpkE3PfvHDQZTFj38CR4XGFaldyT3aFm5syZqKiowPLly6HRaJCYmIjMzExroW9RURHE4ot/mCZPnoy1a9di2bJlWLp0KeLi4rBx40aMHj3a2ubpp5+GXq/Hww8/jJqaGkydOhWZmZlQKBQO+IhE5AiLbhgGsRj4/a+GIPaS8JIcG4jdZy5g1+lqzJzQedGxRW1jC7xlUpvzp+zx9T7zKE3aqFD873AZTpTXoby2ESG+rvN3hmWkZlioL4qq61tDTR1DTS/JPVNtDbcnyuowMpwlBwNRtw5zeeyxx/DYY4+1+9oPP/zQ5rkZM2ZgxowZHb6fSCTCX/7yF/zlL3/p0s+PiYnp8/l7ooFuWKgv/nFvUpvnJw0OxFvfn0TO6SoIgmCzK/HlWowmrNp2HP/84RRuHhOGt+65yu5+NBtM+PagOdTMTolBcXUDDpfqkH2qyrpZoCuwjNQMV/vidKUeu05Xc6+aXmSpsQKAw6U6hpoBiuNzRNQjV0X7QSoWoUTbiOLqhg7bFVXVY8aabKz+/hRMArB5fym2H7X/TKlfTlaipr4FQT5yTBociMlDzMXOzliB1ZHGFiPOVJkDzPBQXwwJNk+Zc6+a3tFiNOHbSzaHPFSidWJvyJkYaoioR7xkUiS0TqnsKmw/WGwsOI+b3/wZe4troFRIcc3wYADAc5uP2KwQ6grL/5HfMjYMErEIk4eaQ40r1dWcLK+DSQD8vTwQ7CvH4NZiYY7U9I4dJypxof5iEfbhEm62OlAx1BBRjyW3bujX3mjJc5sPY+H6vahrMmBCjD++Xfgr/H3WOAT5yFFYqcf7vxR2+ec0thjxv0PmTTlvTTCfATchJgASsQhnq+pd5nwly9TTsFBfiEQiDAkyj9QUVul5sGUvsARdy8aSh0t1LFEYoBhqiKjHLPvd5Fy2X8yu01X4945CiETAE6nD8NlDkxDh5wlfhQcW3xQPAHgz6wTKdW0Pr23P9qPl0DcbEeHniaui/AAAvgoPjB1kPvoh+wqjNabWpeC//3gPcgt7b28bS5HwcLUvACDC3xMyqRjNBhNKajqeoiP7NTRfDLp/un4YPCQi1DYacO4C7/NAxFBDRD2WFO0PiViE8zUN1qMUDEYTVnxlPgX8nolRWJAaZ7N78Z3jIpAQ6Qd9sxEvZR7r0s/52jL1lBBmU5BsqavpKNQIgoAfjpXjttU7MH9tPr47VIbFn++HqZdGTY5dsvIJACRiEWIDzVNQJ1lX41CWoDvI3xMTYwMQF2K+54c4BTUgMdQQUY95y6XW0ZKc1hGQj7LP4lhZLfy82j8FXCwWYeWtIwEAn+efQ0HRhU5/Rm1jC7KOlgMAbmuderKYPCQIgLmu5vJph33FNZj5zi488P5uHDyvg7dMAi+ZBKcr9db3c7TjrdNP8a0jNQBYV9NLNu0zH7R6a0I4RCIRRrWuejpc6vxQk1tYjTv/8QsOnGPhcl9hqCEih0iOvbgKqaK2Ca9vPQ4AeDotHv4dnAI+Lsofd11l3kBz5deHOx052Xq4DM0GEwYHe2NkmO1y3aRof+vOxpeeGF5QdAG/fTsbuYXVkEnFeHBqLH7+87WYnRIDAHj359Pd/rwd0Ta0oERrnk6LC20v1HCkxlF0jS34/lgFgItB17KU+7ALrIBate048otq8FLmUWd3ZcBgqCEih5g02FykmVNYhZcyj6K2yYAxESrMnBDZ6XV/vnE4vGUS7CuuwacdnLjdZDBizY+nAJi/vC7fC0fhIcFV0X4ALq6COnehHg99lIcmgwlXxwXhhyevwbJbRiLAW4YHJsdAKhYht7Aa+8/V9OBTt3WideopTKWAytPD+vzgIC7rdrTvDmrQbDAhLsTHOipmCbzOXgFVVddkHbXccbKS/977CEMNETnE+NZVSMXVDfhv3jkAwF9uHwXJFXYNDlEq8GSaeXoqY8sRFLVzhtRb20/ieFkdgnxk1lGWy1mmoLJPVaGuyYAHP9yDyromxKt98c/7khDu52ltq1YprKun/vVz11dfdcXl9TQWQ0LMoYbTT45jWfV0adAd0TpSU6JtxAW9805v33q4zGal2ye7zjqtL1fSYrRvWwVXxlBDRA7hI5didITK+vvfjh+EcVH+Xbp2TkoMkmMDUN9sxJP/3WczDXXwvBb/+ME8SvOX20dbz5y6nLVY+HQV/vhZAY5qahHsK8d7D0yAj7zt5ukPXh0LAPjmQCnOO3BFUnv1NMDF6afy2ibU8mDLHqusa7KOyt16SY2VUuGBqAAvAM6tq/n2oHlFlmUE879551DfbHBafzryac5ZDFv2rc0Bsf0ZQw0ROcyk1n1ClAop/nxjfJevE4tF+NuMBHjJJMgtrMb7O88AMB+J8NR/98NoEnDzGDVuHhPW4XuMHeQHL5kE1fpmbD9aDrlUjHdnj7cZobnUqHAVJg8JhNEk4AM79sq5kqOa9kdqlAoPBPnIAcCm7qevldQ04LPcIru+YE0mAf/6+TRWbTvuMl/M3+wvhdEkIGGQqs1BqtZiYSdNQWnrW/DLSfPJ8c+nj0F0oBdqGw34am/JFa7sWyaTgH/+cAqCAPztf8fcYg8lhhoicph7k6MxMSYAr8xIQGDrF3hXRQZ44ZnpIwAAL2cexamKOvzzh1M4UqqDv5cH/nL76E6vl0nFGB8TYP39a79NvOLhkQ9dPRgAsC63uM3oSUOzEflFF/DxrrNY8sV+3PbWDtzw+o84eL7jAlRBENrsUXOpIa2jNc6qr7igb8Zv387Gki8O4LG1BV36EmsyGLFg/V48/80RrNp2Ajeu+vmK+wH1NqNJwIetwTd9XNvzvix1Nc46LmHbkTIYTAKGh/piaIgP7kuOBgB8nH3WpTYFzD5dZd3Pp7BSj62H7T+2xNUw1BCRw0QFeuE/j6QgbZS6W9ffMzEKV8cFoclgwqOf5OGt708AAFbeNso6ytGZu66KgIdEhCU3xWP62I5HdSymDQvG0BAf1DYZsH53Mcp0jfhk11nMfi8XY//vO9z5j514duNBfJZbjP3ntDheVod7/5XTYbCpqGvChfoWiEXA0NYamksNDnZeXY3BaMLjnxVYv8S2Hy3Hi98e6fQabX0L7v93Lr7eVwKpWIRQpRxF1fWY9e4uLNt4AHVNzhm12Xq4DKcr9VAqpJgxvm0h+kgnL+u2HLh642jzfwczxg+CXCrG4VId8q+wdUFfWr+7GACs07Pv/HTKmd1xiG6d0k1E1BtEIhFe/s1Y3PD6TzheZh7NuH5kaJt9aTpye2IEbh4TBg9J1/5/TSwW4cGpsVj8xQG8/N0xPP+N7Zd8kI8co8KVGBWuxIgwJd77pRAFRTW49185+PTBZJsaIgA4rjH3OSbQGwoPSZufN8SJe9W88t0x7DhZCU8PCR69Zghe23oc7/5ciKEhPpg5IapN+3MX6vHA+7txsrwOPnIp1tyXhIRIFTK+PYq1OUX4ZFcRvj9agetHhkKtUiBUKUeoUgFfuQfqmw2obzZC32xAs8GEKUODEKpUOORzCIJgXQk3OyWm3XqpUeHmfy+nKvRobDG2+++iM8XV9ThcqsMNI0M7PXW+PbWNLfjphHnqyTJd6uclw20J4diQdw4fZ59FUnRAZ2/RJ7T1Lchs3Yn5jbsT8egn+cgvqsGeM9U2I579DUMNEbmUMJUnVt46Cn/asA9KhRQvpI+264ulq4HGIn1cBF7dehwVtU0QiYBxkX64fqQa148MbTPacs3wYMx5Lxf5RTW4591d+PTBSRgz6GKwOaoxjwxcXk9jMbgH008Hz2txqESLeLUSw9W+7X5RG4wmtBgFeMpsX/t6Xwne/sm8J88rM8bilrHhMAkCVm07gWUbDyI60Nt61IWusQXfHdTgle+Ooby2CWqlAu/PnYARrVM6f71jDKaPCcOfP9+Pcxca8EHrNFBnfOVS/N/to3DHuAi7Q8Llcgqrsbe4BjKpGHMmx7TbJlQpR4C3DNX6ZhzT1FoPXO2Kcl0j7vrnTpTXNmHlrSPxwJRYu/q3/Wi5eT+lIG8MC7345+f+lGhsyDuHLQc0WHZLE4J85BAEAXlnL+CXk1UIUykwZpAKcSE+Njtv95av9p1Hs8GEeLUvro0PwR3jIrB+TzHe/un0FUON0STgle+Ooahaj+duH233VHNvYqghIpdz51UR8FVIERXohRAH/R9+RxQeEqx9MBmHSnSYPDQQIb4d/zxfhQc+/N1EPPD+buSdvYB7/7UL9yRH41RFHY6X1aKo9YiIYe3U0wDAkNbpp8JKPUwmAeIrLHcHzMXSr287jjU/mgs6AUAqFmG42hejwpVoNphwvqYBJTWN0OgaIQgCEiL9MG1YMH41LBgyiRhP/3c/AOD30wbjlrHmUa8F18XhZHkdNu8vxSOf5GHxjfHYfrQcPxyrQHPrEt/hob744HcTEKayLbaeMjQI3y38Fb7aW4Ki6nqU68w/u0zXiPpmI7xkEnjJpNbC7RPldVj0n33IOlKO59NHd7gZY1dYRmlmJA1CsG/7X6YikQgjw5TYcbISh0t1NqGmscWIxhYj/Lza9qHZYMIfPs1HeW0TAOClzGO4Nj4UUYFeXe5fZuuqp5vGqG0C3NhBfkiI9MO+4hq8tf0kfORSfLXvPIqrbVfeKTzEGBGmxMSYAMyaGNWmCNpR/rPHPPX02/GREIlEeOhXsVi/pxjbjpThVEWd9c/q5UwmAX/+fL9124Zjmlp88mBymz8jziISXKlqqRfpdDqoVCpotVoolcorX0BE1IG6JgPmvJeLvLNt6yMi/Dzx7wfGI17d9u8Zo0nAiGcz0Ww04eenf43IgM6/LE+W12Hh+gIcPG8eAUqI9ENRlR4X6u1fEn51XBA+mDvRZt+gxhYjZr6djX2XbeM/NMQHtyeE44EpMfBVeFz+VnYxGE1Y8+MprNp2AgaTgBBfOZ69ZSQCvWVoNBjR2GJCY4sRYpEIUokIHhIxZBIxArxlGDtIZRMMjpTqcNMbP0MsAr5/8hpEB3b8hZ+x5Qje/uk07p8UjefSzUXmVXVNmPF2Noqr67H8lpG4b1K0zfuv3HQIH+w8A1+5FIODvbHvnBaTBgdg7YOTuhRA65sNuOq5rWhsMWHz41PbTE/+N+8cntywz+Y5b5kE1wwPQbW+GQfPa1F7SZ2SSARcFx+CuVNiMXlIYI9HuSwOlWgx/c0dkEnEyFl6nTVkPvjhbmw7Uo5ZEyORcefYNteZTAKe2XgAn+UWQyIWwd9Lhsq6Jgzy98SnDyZ3+u+jJ+z5/uZIDRGRnXzkUnz4u4nI2HIEBqOA4WpfxKt9MUzt22lBs0QsQnSgF06U1+F0pR6RAV4wGE2obTRA32xAk8GEphYTmo0m5J+9gJe/O4rGFhP8vDzw4p1jcOPoMAiCgPM1DThwTosjpTp4yaUI9/NEhJ8nBvl7wmASsONEBX48XoGfT1SittGAyABPvHn3uDYbISo8JHh39njc+68cNBlMmD42DLclhCNe7euwL1CpRIzHro3Dr4YFY+H6vThdocfjnxV06dpr40Pw4l1jrKNn77ROod00JuyKX6CWYmHLCqjGFiMe+miPtZ7p2a8OIb+oBn+9Yww8ZRJ8kX/OOpX22sxEDA/1Rdqqn7DrdDU+zS3C/ZOir9jfH49VoLHFhMgAT+uy8kvdMjYMf99+AucvNGDasGDcPi4C148ItU4XmkwCzlTpsf+cFhv3nscPxyqw7Ug5th0px7BQH4yL9IevQgpfhQd8FVIM8vfEtfEhdk9XbdhjHmW5fmSozajZw78agm1HyvF5/nksun64zUiYIAhYvslcNC8WAa/PTERStD/ufXcXzlTVY8aabHzyYHKHU699hSM1RER96Pcf78F3h8qgVEhhEnDFFURXxwXhbzMSulVoazCacKS0FpEBnu1Ot/S1hmYjXv3fMWQdLYeHRASFhwQKqQRyD/OXcrPBBINJQIvRhKOaWjQbTPD38kDGnWMwOkKFaa/8AKNJwNePTbWpZWrPibJaXP/6T/CSSbB/xQ3447oCbDmggVIhxX2TovH2T6dhNAmIV/tiwXVxWLh+L5oMJvzx2qFY1HoA6we/FGLl14fhJZPgu4W/shlZO1yiQ97ZagT5yBHhbw6VK78+jK/3leDhXw3G0ptHdHgPDCZTl0bATlXU4cOdZ1o37jO222ZoiA+eThuO67tY1NzYYkTyX7OgbWjBh7+biGnDgq2vCYKAO/6xE3uLazBvaizuSY6CySTAYBKwLrcIH2afhUgEvPbbBNwxznxmW3ltI2b/OxdHNbXw9/LAR79LvuK/G3vZ8/3NUENE1If+9fPpNqusAPM+OwqpGHIPCWQSMXzkUtw9MRJzUmK6NPXhbo5parFw/V4caV2WHRngieLqBkwZGohPH5x0xeuNJgGjVmSiscWEm8eoseWABh4SET6el4xJgwORc7oKj31WgIrW+hnAXAj+7zkTrCNaJpOAu9/Zhdwz1Zg8JBDvPTABmQc1+HjX2XanHi2+/MPkLu+m3RXahhZ8d0iDitom6BpboGswQNdo3uCvpnUqMinaH3++MR4TYzsv8v16Xwke/6wA4SoFfv7ztW1G7749UIpHP83v8PqXfzMWv71sGX1NfTPmvL8b+4prEOHnie+fvAYyqeOKnRlq2sFQQ0SuwGgScOC8FmKReZdhpad5KsHeVVsDQXtF0h/Pm4ir44I7v7DV7at/wb7iGuvvV81MtNmsr1zXiPlr87H7zAVEBXhh02NT2oxonanU48Y3fkJjiwneMgn0rSMmUrEIkwYHoq7JgJKaBmtx8fBQX3y74Oo+CaK6xha8/eMp/HtHIRpbzMXdV0X5IXVkKFJHhCIuxMdm9EZb34JHPskzHyVyyYjUpYwmAXM/2I09Z6ohFYsglYghFongI5fg8WvjcFfSoHb7UtdkwILPCvCHXw9FUrTjAh3AUNMuhhoiov5p95lq/OXrw4gJ8sabdyd2ud5n6ZcHsDbHfPL7ouuH4Y/XxbVp02I0IetIOZKi/TtcTfXvHYV4bvNhAIBaqcA9yVG4e0Kkzcq8JoMRZdomhCjldu+L01Nluka8kXUC63cX2+wSHRngiaQof5RoG3G6og6VdRcP+PzpqV/btarLmRhq2sFQQ0Q0sGQdKcO8D/dg1sQo/PUO+/Y7upTJJODz/HNQenrgum4U5vYVjbYR246UYduRMuw8VYVmQ9vTt9VKBe5KisBTaV0/m83ZGGrawVBDRDTw6BpboOzhsvT+qL7ZgJ9PVOJEWS0G+XthSLAPYoO9292B2dVxSTcREREwIAMNAHjJpEgbpe72OWz9lWuOoRERERHZiaGGiIiI3AJDDREREbkFhhoiIiJyCww1RERE5BYYaoiIiMgtMNQQERGRW2CoISIiIrfAUENERERugaGGiIiI3AJDDREREbkFhhoiIiJyCww1RERE5BYGzCndgiAAMB9hTkRERP2D5Xvb8j3emQETamprawEAkZGRTu4JERER2au2thYqlarTNiKhK9HHDZhMJpSUlMDX1xcikcih763T6RAZGYni4mIolUqHvjfZ4r3uO7zXfYf3uu/wXvcdR91rQRBQW1uL8PBwiMWdV80MmJEasViMQYMG9erPUCqV/I+kj/Be9x3e677De913eK/7jiPu9ZVGaCxYKExERERugaGGiIiI3AJDjQPI5XKsWLECcrnc2V1xe7zXfYf3uu/wXvcd3uu+44x7PWAKhYmIiMi9caSGiIiI3AJDDREREbkFhhoiIiJyCww1RERE5BYYanpo9erViImJgUKhQHJyMnJzc53dpX4vIyMDEyZMgK+vL0JCQpCeno5jx47ZtGlsbMT8+fMRGBgIHx8f3HXXXSgrK3NSj93Hiy++CJFIhIULF1qf4712nPPnz+O+++5DYGAgPD09MWbMGOzZs8f6uiAIWL58OcLCwuDp6YnU1FScOHHCiT3un4xGI5599lnExsbC09MTQ4YMwXPPPWdzdhDvdff99NNPuPXWWxEeHg6RSISNGzfavN6Ve1tdXY17770XSqUSfn5+mDdvHurq6nreOYG6bd26dYJMJhPee+894dChQ8JDDz0k+Pn5CWVlZc7uWr+WlpYmvP/++8LBgweFvXv3CjfffLMQFRUl1NXVWds88sgjQmRkpJCVlSXs2bNHmDRpkjB58mQn9rr/y83NFWJiYoSxY8cKCxYssD7Pe+0Y1dXVQnR0tPDAAw8IOTk5wunTp4XvvvtOOHnypLXNiy++KKhUKmHjxo3Cvn37hNtuu02IjY0VGhoanNjz/ueFF14QAgMDhc2bNwuFhYXChg0bBB8fH+GNN96wtuG97r4tW7YIzzzzjPDFF18IAIQvv/zS5vWu3Nsbb7xRSEhIEHbt2iX8/PPPwtChQ4VZs2b1uG8MNT0wceJEYf78+dbfG41GITw8XMjIyHBir9xPeXm5AED48ccfBUEQhJqaGsHDw0PYsGGDtc2RI0cEAEJ2drazutmv1dbWCnFxccLWrVuFadOmWUMN77Xj/PnPfxamTp3a4esmk0lQq9XCK6+8Yn2upqZGkMvlwmeffdYXXXQb06dPF373u9/ZPHfnnXcK9957ryAIvNeOdHmo6cq9PXz4sABA2L17t7XNt99+K4hEIuH8+fM96g+nn7qpubkZeXl5SE1NtT4nFouRmpqK7OxsJ/bM/Wi1WgBAQEAAACAvLw8tLS029z4+Ph5RUVG89900f/58TJ8+3eaeArzXjrRp0yaMHz8eM2bMQEhICMaNG4d3333X+nphYSE0Go3NvVapVEhOTua9ttPkyZORlZWF48ePAwD27duHHTt24KabbgLAe92bunJvs7Oz4efnh/Hjx1vbpKamQiwWIycnp0c/f8AcaOlolZWVMBqNCA0NtXk+NDQUR48edVKv3I/JZMLChQsxZcoUjB49GgCg0Wggk8ng5+dn0zY0NBQajcYJvezf1q1bh/z8fOzevbvNa7zXjnP69Gn885//xKJFi7B06VLs3r0bf/zjHyGTyTBnzhzr/Wzv7xTea/ssXrwYOp0O8fHxkEgkMBqNeOGFF3DvvfcCAO91L+rKvdVoNAgJCbF5XSqVIiAgoMf3n6GGXNr8+fNx8OBB7Nixw9ldcUvFxcVYsGABtm7dCoVC4ezuuDWTyYTx48fjr3/9KwBg3LhxOHjwINasWYM5c+Y4uXfu5T//+Q8+/fRTrF27FqNGjcLevXuxcOFChIeH8167OU4/dVNQUBAkEkmbVSBlZWVQq9VO6pV7eeyxx7B582Z8//33GDRokPV5tVqN5uZm1NTU2LTnvbdfXl4eysvLcdVVV0EqlUIqleLHH3/Em2++CalUitDQUN5rBwkLC8PIkSNtnhsxYgSKiooAwHo/+XdKzz311FNYvHgx7r77bowZMwb3338/nnjiCWRkZADgve5NXbm3arUa5eXlNq8bDAZUV1f3+P4z1HSTTCZDUlISsrKyrM+ZTCZkZWUhJSXFiT3r/wRBwGOPPYYvv/wS27dvR2xsrM3rSUlJ8PDwsLn3x44dQ1FREe+9na677jocOHAAe/futT7Gjx+Pe++91/rPvNeOMWXKlDZbExw/fhzR0dEAgNjYWKjVapt7rdPpkJOTw3ttp/r6eojFtl9vEokEJpMJAO91b+rKvU1JSUFNTQ3y8vKsbbZv3w6TyYTk5OSedaBHZcYD3Lp16wS5XC588MEHwuHDh4WHH35Y8PPzEzQajbO71q89+uijgkqlEn744QehtLTU+qivr7e2eeSRR4SoqChh+/btwp49e4SUlBQhJSXFib12H5eufhIE3mtHyc3NFaRSqfDCCy8IJ06cED799FPBy8tL+OSTT6xtXnzxRcHPz0/46quvhP379wu33347lxl3w5w5c4SIiAjrku4vvvhCCAoKEp5++mlrG97r7qutrRUKCgqEgoICAYDw2muvCQUFBcLZs2cFQejavb3xxhuFcePGCTk5OcKOHTuEuLg4Lul2BX//+9+FqKgoQSaTCRMnThR27drl7C71ewDafbz//vvWNg0NDcIf/vAHwd/fX/Dy8hLuuOMOobS01HmddiOXhxrea8f5+uuvhdGjRwtyuVyIj48X3nnnHZvXTSaT8OyzzwqhoaGCXC4XrrvuOuHYsWNO6m3/pdPphAULFghRUVGCQqEQBg8eLDzzzDNCU1OTtQ3vdfd9//337f4dPWfOHEEQunZvq6qqhFmzZgk+Pj6CUqkU5s6dK9TW1va4byJBuGSLRSIiIqJ+ijU1RERE5BYYaoiIiMgtMNQQERGRW2CoISIiIrfAUENERERugaGGiIiI3AJDDREREbkFhhoiIiJyCww1RERE5BYYaoiIiMgtMNQQERGRW2CoISIiIrfw/6cZJ/dqChcuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757241.302 -363563.136      -2.436       8.533 7757267.039 -363540.223\n",
      "      -2.394       8.685      -0.003] -> [ 8.691282    0.00094773  0.0322624   8.622851    0.00197271  0.0316968\n",
      "  8.645795   -0.00421031  0.03993797  8.635903    0.00203282  0.01158202\n",
      "  8.6324835   0.00746205  0.00780278  8.636266   -0.01028911  0.0069222\n",
      "  8.624413    0.00577027  0.00597888  8.636649    0.00470718  0.02835889\n",
      "  8.631962   -0.01124253  0.02227421  8.6231985   0.00166798  0.01686366\n",
      "  8.63375     0.01534212  0.02597287  8.634499    0.00817214  0.01892758\n",
      "  8.625862   -0.00579662  0.02778574  8.626856    0.01145294  0.0216725\n",
      "  8.649312    0.01223331  0.00658671  8.633038   -0.00508229  0.01571035\n",
      "  8.633189   -0.00432694  0.00975724  8.637997   -0.00015145  0.01661479\n",
      "  8.638698    0.01047744  0.03009073  8.634072    0.01637786  0.02571611\n",
      "  8.649082    0.00432654  0.01179413  8.640776    0.000671    0.01372196\n",
      "  8.647301   -0.01277976  0.01291653  8.63982     0.00303249  0.03349569\n",
      "  8.638771    0.01536232  0.03208824  8.635587    0.01274179  0.02866582\n",
      "  8.655595    0.01528044  0.01361074  8.640607    0.01331898  0.00469624\n",
      "  8.652552    0.00169075  0.03873429  8.642606    0.0162598   0.02301447\n",
      "  8.659688    0.02406836  0.02241444  8.642205    0.01639539  0.02190789\n",
      "  8.643198    0.00792658  0.02377949  8.6430855   0.02005824  0.02128511\n",
      "  8.649064   -0.00608053  0.01445897  8.652979    0.00563405  0.02235843\n",
      "  8.645159    0.00158359  0.02696148  8.661086    0.0099616   0.02360788\n",
      "  8.641507    0.02161683  0.01663567  8.649721    0.01299195  0.01227644\n",
      "  8.645328    0.02042973  0.00354428  8.641736    0.02832557  0.01131307\n",
      "  8.650827    0.02165801  0.01734944  8.640131    0.00182006  0.01848064\n",
      "  8.638061    0.00870947  0.0207203   8.650236    0.01829491  0.01598773\n",
      "  8.643723    0.0354243   0.01998422  8.65576     0.01843997  0.00973593\n",
      "  8.6553955   0.00380115  0.01169546  8.644266    0.00454167  0.03654381] (expected [ 8.685 -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55\n",
      " -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003\n",
      "  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02\n",
      "  8.55  -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55\n",
      " -0.003  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02\n",
      "  8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55\n",
      " -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02\n",
      "  8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55\n",
      " -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02\n",
      "  8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55\n",
      " -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02 ])\n",
      "[7756535.365 -363776.659      -2.004       8.55  7756557.314 -363750.158\n",
      "      -2.45        8.693       0.016] -> [ 8.66072     0.02108897  0.03374822  8.564833    0.01964995  0.032125\n",
      "  8.587124    0.01268701  0.04308098  8.576812    0.02106571  0.01014245\n",
      "  8.572063    0.02516358  0.00594869  8.576709    0.00563344  0.00615163\n",
      "  8.563222    0.02406895  0.00804794  8.575751    0.02296425  0.02925921\n",
      "  8.569751    0.00451711  0.02357157  8.558437    0.01688069  0.01723384\n",
      "  8.571008    0.03231991  0.02485982  8.5703      0.02549432  0.01745606\n",
      "  8.561825    0.00740807  0.02845951  8.561422    0.02891257  0.02281643\n",
      "  8.584801    0.02878528  0.00614671  8.565558    0.01147802  0.01393377\n",
      "  8.565901    0.01233459  0.01031168  8.568856    0.01545555  0.01557147\n",
      "  8.570623    0.0273576   0.03077896  8.563766    0.03596145  0.02467244\n",
      "  8.580229    0.01969358  0.01414726  8.569083    0.01718438  0.01258989\n",
      "  8.576696   -0.00745236  0.01415952  8.569       0.01637249  0.0322949\n",
      "  8.5668335   0.03009027  0.03107854  8.562229    0.02841901  0.02827982\n",
      "  8.584103    0.0326887   0.01322998  8.566923    0.02896985  0.00712167\n",
      "  8.578381    0.01812971  0.03972722  8.566996    0.03165115  0.02153139\n",
      "  8.583461    0.04014982  0.02184391  8.566347    0.0359692   0.02092179\n",
      "  8.567728    0.02090335  0.02456889  8.563993    0.03703341  0.01881825\n",
      "  8.571128    0.01055918  0.01488229  8.574274    0.02038155  0.02467264\n",
      "  8.563605    0.0203004   0.02720455  8.581472    0.02616643  0.02428094\n",
      "  8.5606575   0.03959359  0.01857592  8.568799    0.02872656  0.00934711\n",
      "  8.562377    0.04033029  0.0038305   8.55762     0.04844869  0.00924044\n",
      "  8.567625    0.03971172  0.01552268  8.557608    0.01830456  0.01890288\n",
      "  8.552646    0.02522076  0.02184814  8.56648     0.03783337  0.01339922\n",
      "  8.557642    0.05559094  0.02056453  8.570158    0.03617289  0.00887023\n",
      "  8.5686865   0.01648347  0.01225669  8.555571    0.01941809  0.03642138] (expected [8.693 0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02\n",
      " 8.55  0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02\n",
      " 8.55  0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02\n",
      " 8.55  0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02  8.55  0.016 0.02\n",
      " 8.55  0.016 0.02  8.55  0.017 0.02  8.55  0.017 0.02  8.55  0.017 0.02\n",
      " 8.55  0.017 0.02  8.55  0.017 0.02  8.55  0.017 0.02  8.55  0.017 0.02\n",
      " 8.55  0.017 0.02  8.55  0.017 0.02  8.55  0.017 0.02  8.55  0.017 0.02\n",
      " 8.55  0.018 0.02  8.55  0.018 0.02  8.55  0.018 0.02  8.55  0.018 0.02\n",
      " 8.55  0.018 0.02  8.55  0.018 0.02  8.55  0.018 0.02  8.55  0.018 0.02\n",
      " 8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02  8.55  0.019 0.02\n",
      " 8.55  0.019 0.02  8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.02  0.02\n",
      " 8.55  0.02  0.02  8.55  0.02  0.02  8.55  0.021 0.02  8.55  0.021 0.02\n",
      " 8.55  0.021 0.02  8.55  0.021 0.02 ])\n",
      "[7756814.348 -364036.21       -0.194       2.781 7756804.296 -364033.696\n",
      "      -0.206       0.047      -0.471] -> [ 0.10707805 -0.4698971  -0.00022807  0.12791519 -0.45615473  0.01222053\n",
      "  0.11377852 -0.45723736 -0.00931581  0.11295175 -0.46934575  0.03642919\n",
      "  0.11944154 -0.45638704  0.05592749  0.1319224  -0.4493895   0.03879196\n",
      "  0.14796434 -0.4728004   0.01711414  0.13693246 -0.47553414  0.00458798\n",
      "  0.13806798 -0.45032495  0.01143957  0.15164438 -0.44903496  0.01202105\n",
      "  0.15138432 -0.46221283  0.03070386  0.16670018 -0.46105868  0.02564104\n",
      "  0.16423206 -0.43072742  0.01270947  0.1632725  -0.46301967  0.01097716\n",
      "  0.14982322 -0.46210417  0.03744685  0.1661886  -0.43592107  0.03171613\n",
      "  0.16169478 -0.45369425  0.0262124   0.17818707 -0.45263672  0.01938479\n",
      "  0.17972542 -0.45563236  0.01176662  0.18821138 -0.48661682  0.01570102\n",
      "  0.1734028  -0.4483235   0.02217795  0.18419631 -0.46554402  0.03855267\n",
      "  0.19490738 -0.41058388  0.02925227  0.20251876 -0.44923484 -0.00000599\n",
      "  0.20058642 -0.45679525 -0.00195086  0.2155984  -0.44961578  0.01163694\n",
      "  0.20297056 -0.45857212  0.04058947  0.20856147 -0.45819956  0.01832355\n",
      "  0.2087284  -0.44566107 -0.00877192  0.22673182 -0.45488596  0.03541183\n",
      "  0.2149128  -0.45614773  0.01403669  0.24936906 -0.4694118   0.02655179\n",
      "  0.24417979 -0.4320429   0.00014387  0.23795153 -0.46398762  0.03273791\n",
      "  0.24970835 -0.4491272   0.03041249  0.2559151  -0.44970208 -0.00279954\n",
      "  0.27215952 -0.45641577  0.00625223  0.27492303 -0.4518419   0.01668506\n",
      "  0.2804548  -0.44999814  0.01988719  0.28494096 -0.45589742  0.03782222\n",
      "  0.29936373 -0.4624139   0.04328753  0.30141708 -0.4775726   0.03134979\n",
      "  0.30246943 -0.46201414  0.03674966  0.31054473 -0.4454681   0.0176226\n",
      "  0.33400607 -0.43901893  0.03254087  0.3033008  -0.46073544  0.02955663\n",
      "  0.331262   -0.46625113  0.01460284  0.32684222 -0.44729772  0.02996085\n",
      "  0.32786196 -0.4265213   0.03777208  0.34808344 -0.4345924   0.00395307] (expected [ 0.047 -0.471  0.02   0.055 -0.47   0.02   0.062 -0.469  0.02   0.069\n",
      " -0.468  0.02   0.077 -0.467  0.02   0.084 -0.466  0.02   0.092 -0.465\n",
      "  0.02   0.099 -0.464  0.02   0.107 -0.463  0.02   0.114 -0.462  0.02\n",
      "  0.122 -0.461  0.02   0.129 -0.46   0.02   0.137 -0.458  0.02   0.144\n",
      " -0.457  0.02   0.152 -0.456  0.02   0.159 -0.455  0.02   0.166 -0.454\n",
      "  0.02   0.174 -0.453  0.02   0.181 -0.452  0.02   0.189 -0.451  0.02\n",
      "  0.196 -0.45   0.02   0.204 -0.448  0.02   0.211 -0.447  0.02   0.219\n",
      " -0.446  0.02   0.226 -0.445  0.02   0.234 -0.444  0.02   0.241 -0.442\n",
      "  0.02   0.248 -0.441  0.02   0.256 -0.44   0.02   0.263 -0.439  0.02\n",
      "  0.271 -0.437  0.02   0.278 -0.436  0.02   0.286 -0.435  0.02   0.293\n",
      " -0.433  0.02   0.301 -0.432  0.02   0.308 -0.431  0.02   0.316 -0.429\n",
      "  0.02   0.323 -0.428  0.02   0.331 -0.426  0.02   0.338 -0.425  0.02\n",
      "  0.345 -0.423  0.02   0.353 -0.422  0.02   0.36  -0.42   0.02   0.368\n",
      " -0.419  0.02   0.375 -0.417  0.02   0.383 -0.415  0.02   0.39  -0.414\n",
      "  0.02   0.398 -0.412  0.02   0.405 -0.41   0.02   0.413 -0.408  0.02 ])\n",
      "[7756550.568 -363759.163       0.743       8.55  7756533.864 -363787.817\n",
      "       1.285       8.534      -0.027] -> [ 8.509222   -0.02454542  0.03220172  8.450754   -0.0245761   0.03159637\n",
      "  8.47119    -0.03012522  0.03977751  8.460137   -0.02399981  0.01258803\n",
      "  8.457109   -0.01876179  0.00872734  8.460828   -0.03542153  0.00774319\n",
      "  8.448053   -0.02148998  0.00866729  8.458665   -0.02081162  0.02741332\n",
      "  8.453067   -0.03648832  0.02154298  8.442628   -0.02503425  0.01725124\n",
      "  8.454      -0.01173817  0.02430716  8.452611   -0.01776017  0.0193581\n",
      "  8.443875   -0.03357316  0.02785655  8.443575   -0.0145695   0.02196146\n",
      "  8.464181   -0.01395888  0.0081853   8.447717   -0.03072505  0.01507115\n",
      "  8.44703    -0.02945638  0.01070257  8.449573   -0.02656405  0.01572072\n",
      "  8.450353   -0.01558564  0.02921833  8.445669   -0.00902069  0.02410387\n",
      "  8.459494   -0.0222098   0.01330487  8.447754   -0.02363926  0.01308121\n",
      "  8.454963   -0.0443645   0.01499399  8.446407   -0.02423449  0.03163579\n",
      "  8.445617   -0.01210958  0.03092434  8.4420395  -0.01403941  0.02723674\n",
      "  8.459377   -0.00994734  0.01334776  8.444201   -0.01257041  0.00525736\n",
      "  8.453541   -0.02334022  0.03632275  8.444642   -0.01036011  0.0230314\n",
      "  8.458761   -0.00318592  0.02179169  8.443127   -0.00798905  0.0205911\n",
      "  8.443623   -0.0189532   0.02406672  8.439526   -0.00551036  0.02037643\n",
      "  8.446522   -0.02872255  0.01490875  8.4485445  -0.01981594  0.02276482\n",
      "  8.438481   -0.02109145  0.02727506  8.455607   -0.0140282   0.02396766\n",
      "  8.435915   -0.00361966  0.01846601  8.442818   -0.01058801  0.01281527\n",
      "  8.436406   -0.00308025  0.00469024  8.43262     0.00571502  0.01241057\n",
      "  8.440903   -0.00102549  0.01657551  8.431828   -0.01899865  0.01911507\n",
      "  8.427189   -0.01497411  0.02031976  8.438727   -0.00308224  0.0165672\n",
      "  8.430103    0.01259632  0.02014623  8.441408   -0.00327865  0.01144801\n",
      "  8.440364   -0.02187247  0.0115077   8.4283085  -0.01817027  0.03566679] (expected [ 8.534 -0.027  0.02   8.534 -0.027  0.02   8.534 -0.027  0.02   8.534\n",
      " -0.027  0.02   8.534 -0.027  0.02   8.534 -0.027  0.02   8.535 -0.027\n",
      "  0.02   8.535 -0.027  0.02   8.535 -0.027  0.02   8.535 -0.027  0.02\n",
      "  8.535 -0.027  0.02   8.535 -0.027  0.02   8.535 -0.027  0.02   8.535\n",
      " -0.028  0.02   8.535 -0.028  0.02   8.535 -0.028  0.02   8.535 -0.028\n",
      "  0.02   8.535 -0.028  0.02   8.536 -0.028  0.02   8.536 -0.028  0.02\n",
      "  8.536 -0.028  0.02   8.536 -0.028  0.02   8.536 -0.028  0.02   8.536\n",
      " -0.028  0.02   8.536 -0.028  0.02   8.536 -0.028  0.02   8.536 -0.029\n",
      "  0.02   8.536 -0.029  0.02   8.536 -0.029  0.02   8.536 -0.029  0.02\n",
      "  8.536 -0.029  0.02   8.537 -0.029  0.02   8.537 -0.029  0.02   8.537\n",
      " -0.029  0.02   8.537 -0.03   0.02   8.537 -0.03   0.02   8.537 -0.03\n",
      "  0.02   8.537 -0.03   0.02   8.537 -0.03   0.02   8.537 -0.03   0.02\n",
      "  8.537 -0.031  0.02   8.537 -0.031  0.02   8.537 -0.031  0.02   8.538\n",
      " -0.031  0.02   8.538 -0.031  0.02   8.538 -0.032  0.02   8.538 -0.032\n",
      "  0.02   8.538 -0.032  0.02   8.538 -0.032  0.02   8.538 -0.033  0.02 ])\n",
      "[7757192.786 -364079.85        2.94        8.55  7757225.311 -364087.175\n",
      "       2.932       8.537      -0.005] -> [ 8.514309   -0.00338422  0.03331347  8.469393   -0.00556728  0.03111345\n",
      "  8.490196   -0.00850208  0.04252212  8.480233   -0.00759286  0.01124096\n",
      "  8.476723   -0.00072838  0.00912654  8.483953   -0.01492409  0.00837023\n",
      "  8.473013   -0.00627482  0.01192579  8.484978    0.00072585  0.02835293\n",
      "  8.478214   -0.0143772   0.020166    8.470803   -0.00376606  0.02105101\n",
      "  8.483647    0.00708736  0.02221456  8.484855   -0.00279225  0.0191406\n",
      "  8.475045   -0.01512117  0.02814385  8.47291     0.00440934  0.02049328\n",
      "  8.490247    0.00924712  0.00990073  8.480173   -0.01283364  0.01349365\n",
      "  8.477441   -0.00935066  0.0119917   8.483711   -0.00714343  0.01720321\n",
      "  8.481087   -0.00076542  0.02545558  8.483137    0.01211542  0.0235685\n",
      "  8.492201   -0.00103406  0.01238707  8.481799   -0.00512206  0.0134181\n",
      "  8.489528   -0.04122638  0.01608601  8.484875   -0.01022299  0.0307298\n",
      "  8.483511    0.00389022  0.02877562  8.482604    0.00442063  0.02465299\n",
      "  8.495138    0.00448086  0.01072492  8.484506    0.003095    0.00578247\n",
      "  8.493626   -0.00198245  0.03651101  8.488407    0.00914754  0.02140956\n",
      "  8.500938    0.01255567  0.02260542  8.490927    0.00749547  0.02118143\n",
      "  8.489983   -0.00236356  0.02167682  8.482414    0.01359925  0.0215721\n",
      "  8.492926   -0.00476804  0.01709541  8.495775   -0.00515838  0.02455045\n",
      "  8.489913    0.00123502  0.02694295  8.506365    0.00820266  0.02202621\n",
      "  8.487786    0.01154305  0.0180806   8.49664     0.0076165   0.01390401\n",
      "  8.491007    0.01598537  0.00003714  8.487344    0.02607442  0.01297759\n",
      "  8.499062    0.01859797  0.01284741  8.491507    0.0013983   0.01947055\n",
      "  8.489024    0.00155602  0.01940566  8.496549    0.01917655  0.01447413\n",
      "  8.493574    0.03219492  0.01936958  8.501711    0.02169671  0.01344024\n",
      "  8.501894   -0.00719566  0.00990398  8.493609   -0.00295892  0.03338077] (expected [ 8.537 -0.005  0.02   8.537 -0.005  0.02   8.537 -0.005  0.02   8.537\n",
      " -0.005  0.02   8.537 -0.005  0.02   8.537 -0.005  0.02   8.537 -0.005\n",
      "  0.02   8.537 -0.005  0.02   8.537 -0.005  0.02   8.537 -0.005  0.02\n",
      "  8.538 -0.005  0.02   8.538 -0.005  0.02   8.538 -0.005  0.02   8.538\n",
      " -0.005  0.02   8.538 -0.005  0.02   8.538 -0.005  0.02   8.538 -0.005\n",
      "  0.02   8.538 -0.005  0.02   8.538 -0.005  0.02   8.538 -0.005  0.02\n",
      "  8.538 -0.005  0.02   8.538 -0.005  0.02   8.538 -0.005  0.02   8.538\n",
      " -0.005  0.02   8.538 -0.005  0.02   8.539 -0.005  0.02   8.539 -0.005\n",
      "  0.02   8.539 -0.005  0.02   8.539 -0.005  0.02   8.539 -0.005  0.02\n",
      "  8.539 -0.005  0.02   8.539 -0.005  0.02   8.539 -0.005  0.02   8.539\n",
      " -0.005  0.02   8.539 -0.005  0.02   8.539 -0.005  0.02   8.539 -0.005\n",
      "  0.02   8.539 -0.005  0.02   8.539 -0.005  0.02   8.539 -0.005  0.02\n",
      "  8.54  -0.005  0.02   8.54  -0.005  0.02   8.54  -0.005  0.02   8.54\n",
      " -0.005  0.02   8.54  -0.005  0.02   8.54  -0.005  0.02   8.54  -0.005\n",
      "  0.02   8.54  -0.004  0.02   8.54  -0.004  0.02   8.54  -0.004  0.02 ])\n"
     ]
    }
   ],
   "source": [
    "#CONFIGURAR PARA VARIAS SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,150))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 150)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 150)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 2400),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2400, 1200),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1200, 600),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(600, 150)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end]  # Modify this line\n",
    "            y_batch = y_train[start:end]  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 1)\n"
     ]
    }
   ],
   "source": [
    "print(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757819.5   -363524.875       2.687       7.901 7757828.5   -363530.219\n",
      "        2.569       7.668       0.03 ]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[7757819.5   -363524.875       2.687       7.901 7757828.5   -363530.219\n",
      "        2.569       7.668       0.03 ]]\n",
      "[[1.42005795 1.29789503 1.32252006 0.15014253 1.43366659 1.26184555\n",
      "  1.25993265 0.09551552 0.64087875]]\n",
      "[7757241.302 -363563.136      -2.436       8.533 7757267.039 -363540.223\n",
      "      -2.394       8.685      -0.003] -> [7.676292   0.02891351 0.03239961 7.658706   0.02880111 0.03012395\n",
      " 7.681146   0.02622609 0.03947585 7.6723475  0.02737701 0.01246453\n",
      " 7.6718597  0.03261744 0.0069226  7.6762547  0.019178   0.0082192\n",
      " 7.6675158  0.02923611 0.01016352 7.6792912  0.03572161 0.02920748\n",
      " 7.675805   0.02078435 0.02023919 7.6698055  0.029998   0.02000459\n",
      " 7.679816   0.03918327 0.0236651  7.6819134  0.03006206 0.0212285\n",
      " 7.674125   0.02070468 0.0281758  7.6740913  0.03689172 0.02140976\n",
      " 7.6901717  0.04090744 0.01016334 7.683492   0.01968582 0.01626622\n",
      " 7.682811   0.02409196 0.01076992 7.6898856  0.02604372 0.01816857\n",
      " 7.687876   0.03255238 0.02518837 7.690033   0.04360717 0.02532758\n",
      " 7.6985908  0.03091129 0.01065991 7.691146   0.02855897 0.01368298\n",
      " 7.697899   0.00203741 0.01421311 7.694497   0.02567725 0.03243914\n",
      " 7.6940207  0.03687829 0.03044127 7.693629   0.03614234 0.024995\n",
      " 7.706344   0.03626784 0.01159407 7.6987967  0.03487703 0.00607561\n",
      " 7.707383   0.02987779 0.03737573 7.7030244  0.04157795 0.02144985\n",
      " 7.717112   0.04400463 0.02235174 7.7065334  0.03815037 0.02147397\n",
      " 7.705231   0.03146672 0.02226863 7.704144   0.04505643 0.02329623\n",
      " 7.711662   0.02771375 0.01654716 7.7150292  0.031031   0.02260651\n",
      " 7.7108655  0.03201748 0.02728633 7.7259827  0.03928923 0.02209994\n",
      " 7.710045   0.0410632  0.01507176 7.7179203  0.04008625 0.01577154\n",
      " 7.7133856  0.04387724 0.00117666 7.711954   0.05382205 0.01454841\n",
      " 7.7233343  0.04880263 0.01428994 7.715123   0.03322444 0.01930032\n",
      " 7.714275   0.03499727 0.01682788 7.724447   0.04973585 0.01652441\n",
      " 7.7217016  0.06054432 0.01899073 7.7299204  0.04951443 0.01324783\n",
      " 7.7314844  0.02748065 0.00905306 7.724333   0.02930334 0.03403201] (expected [ 8.685 -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55\n",
      " -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003\n",
      "  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02\n",
      "  8.55  -0.003  0.02   8.55  -0.003  0.02   8.55  -0.003  0.02   8.55\n",
      " -0.003  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02\n",
      "  8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55\n",
      " -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02\n",
      "  8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55\n",
      " -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02\n",
      "  8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55\n",
      " -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002\n",
      "  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02   8.55  -0.002  0.02 ])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "values = [[7757819.500, -363524.875, 2.687, 7.901, 7757828.500, -363530.219, 2.569, 7.668, 0.030]]\n",
    "arr = np.array(values)\n",
    "\n",
    "print(arr)\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(1):\n",
    "        X_sample = arr[i:i+1]\n",
    "        print(type(X_sample))\n",
    "        print(X_sample)\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        print(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[7757781.538 -363521.914      -2.797       7.479 7757813.153 -363521.892\n",
      "        2.827       8.2         0.051]]\n",
      "[[ 1.33226234  1.31622879 -1.39685001 -0.06478618  1.39973425  1.3065505\n",
      "   1.37944972  0.38450701  1.04319887]]\n",
      "[7757781.538 -363521.914      -2.797       7.479 7757813.153 -363521.892\n",
      "       2.827       8.2         0.051] -> [8.181326   0.05272616 0.02641746 8.140773   0.06074997 0.01603541\n",
      " 8.129248   0.05398777 0.01440225 8.135523   0.049911   0.01537436\n",
      " 8.1323805  0.05261231 0.02257932 8.1269865  0.04800221 0.01963068\n",
      " 8.124198   0.0509049  0.02371841 8.11923    0.05256447 0.01630135\n",
      " 8.114489   0.04791815 0.01409454 8.113762   0.05891797 0.02015051\n",
      " 8.111128   0.05003864 0.02361509 8.112732   0.05322156 0.01978908\n",
      " 8.113821   0.05088584 0.01970432 8.107655   0.05278888 0.02204894\n",
      " 8.105561   0.05155259 0.01740434 8.103662   0.04708258 0.01973448\n",
      " 8.100708   0.05222019 0.02272007 8.100998   0.05017047 0.01678706\n",
      " 8.091274   0.05167418 0.01685839 8.090018   0.04690822 0.0247036\n",
      " 8.096461   0.05405676 0.01682393 8.094748   0.050661   0.02127638\n",
      " 8.086491   0.05312075 0.01212277 8.089228   0.04447697 0.02096066\n",
      " 8.081609   0.0547631  0.01939246 8.077865   0.05345492 0.0201423\n",
      " 8.0810375  0.05437741 0.02708411 8.076733   0.05754933 0.02357301\n",
      " 8.076645   0.05426828 0.02095463 8.072516   0.05298759 0.02287421\n",
      " 8.0699415  0.05447268 0.0192939  8.064233   0.05423389 0.0195383\n",
      " 8.062398   0.05034141 0.01974893 8.059404   0.05339309 0.02247215\n",
      " 8.063102   0.05869516 0.02332221 8.054881   0.04618666 0.02758465\n",
      " 8.054841   0.05024753 0.02181757 8.058218   0.05386145 0.02372503\n",
      " 8.050544   0.05557213 0.02327129 8.046917   0.05065179 0.0218269\n",
      " 8.045702   0.05441321 0.01731804 8.042693   0.05150549 0.02021753\n",
      " 8.039089   0.05001142 0.02420444 8.040739   0.03592366 0.01753216\n",
      " 8.04229    0.04844355 0.02261725 8.036257   0.05217041 0.01469718\n",
      " 8.032951   0.05186881 0.02124875 8.023761   0.0499049  0.02194553\n",
      " 8.028658   0.04910132 0.02256993 8.017795   0.05136245 0.02107617] (expected [8.2   0.051 0.02  8.196 0.051 0.02  8.193 0.052 0.02  8.189 0.052 0.02\n",
      " 8.186 0.052 0.02  8.182 0.052 0.02  8.178 0.052 0.02  8.175 0.052 0.02\n",
      " 8.171 0.052 0.02  8.168 0.052 0.02  8.164 0.052 0.02  8.161 0.052 0.02\n",
      " 8.157 0.052 0.02  8.154 0.052 0.02  8.15  0.052 0.02  8.147 0.052 0.02\n",
      " 8.143 0.052 0.02  8.14  0.052 0.02  8.136 0.052 0.02  8.133 0.052 0.02\n",
      " 8.129 0.052 0.02  8.126 0.052 0.02  8.122 0.052 0.02  8.119 0.052 0.02\n",
      " 8.115 0.052 0.02  8.112 0.052 0.02  8.108 0.052 0.02  8.105 0.052 0.02\n",
      " 8.101 0.052 0.02  8.098 0.052 0.02  8.094 0.052 0.02  8.09  0.052 0.02\n",
      " 8.087 0.052 0.02  8.083 0.052 0.02  8.08  0.052 0.02  8.076 0.052 0.02\n",
      " 8.073 0.052 0.02  8.069 0.052 0.02  8.066 0.052 0.02  8.062 0.052 0.02\n",
      " 8.059 0.052 0.02  8.055 0.052 0.02  8.052 0.052 0.02  8.048 0.052 0.02\n",
      " 8.045 0.052 0.02  8.041 0.052 0.02  8.038 0.052 0.02  8.034 0.052 0.02\n",
      " 8.031 0.052 0.02  8.027 0.052 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(1):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        print(type(X_sample))\n",
    "        print(X_sample)\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        print(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757241.302 -363563.136      -2.436       8.533 7757267.039 -363540.223\n",
      "       -2.394       8.685      -0.003]]\n",
      "[[ 0.03881761  1.10981298 -1.22407144  0.47235186  0.09350635  1.21278579\n",
      "  -1.20176972  0.64514142 -0.00334679]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    dummy_input = X_test_raw[i: i+1]\n",
    "    print(dummy_input)\n",
    "    dummy_input = scaler.transform(dummy_input)\n",
    "    print(dummy_input)\n",
    "    dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "    traced_script_module = torch.jit.trace(model, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"model_clean_maior1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757219.02030919 -363790.45257479       0.02507255       7.59847813\n",
      " 7757221.91891166 -363789.01252881       0.02444362       7.47429562\n",
      "      -0.00269055]\n",
      "[419.98896269 203.30314877   2.00996865   1.96946407 420.14477201\n",
      " 203.81701318   2.01436103   1.86837855   0.05217095]\n"
     ]
    }
   ],
   "source": [
    "mean = scaler.mean_\n",
    "std_dev = scaler.scale_\n",
    "print(mean)\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757225.05264482 -363788.90212366       0.02647504       7.60650176\n",
      " 7757227.86445566 -363787.52767805       0.02886931       7.49126291\n",
      "      -0.00282856]\n",
      "[418.6078148  203.42717893   2.01170859   1.96145779 418.95064762\n",
      " 203.91455788   2.0160845    1.85034947   0.0512243 ]\n"
     ]
    }
   ],
   "source": [
    "#maior1\n",
    "mean = scaler.mean_\n",
    "std_dev = scaler.scale_\n",
    "print(mean)\n",
    "print(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_test_cpp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m7757481.724\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m363634.012\u001b[39m, \u001b[39m2.313\u001b[39m, \u001b[39m8.372\u001b[39m, \u001b[39m7757506.813\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m363650.764\u001b[39m, \u001b[39m2.799\u001b[39m, \u001b[39m7.703\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.037\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_test_cpp \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(X_test_cpp)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann_clean.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(X_test_cpp)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:1003\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    989\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \n\u001b[1;32m    991\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39m        Transformed array.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1003\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1005\u001b[0m     copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m   1006\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1007\u001b[0m         X,\n\u001b[1;32m   1008\u001b[0m         reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1013\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[1;32m   1460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1461\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_test_cpp = np.array([7757481.724, -363634.012, 2.313, 8.372, 7757506.813, -363650.764, 2.799, 7.703, -0.037])\n",
    "X_test_cpp = scaler.transform(X_test_cpp)\n",
    "print(X_test_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0573,  1.5971, -0.0614, -0.1519,  2.0956,  0.6641,  0.5896, -0.4267,\n",
      "          1.4114]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=24, bias=True)\n",
       "  (1): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (2): Linear(in_features=12, out_features=6, bias=True)\n",
       "  (3): Linear(in_features=6, out_features=150, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n",
      "          1.2702]])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have a trained model 'model'\n",
    "#dummy_input = torch.randn(1, 9)  # Adjust as necessary\n",
    "dummy_input = X_test_raw[i: i+1]\n",
    "dummy_input = scaler.transform(dummy_input)\n",
    "dummy_input = torch.tensor(dummy_input, dtype=torch.float32)\n",
    "print(dummy_input)\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/Dados/caiopinho/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.ones(1, 9, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Convert the model to Torch Script\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, dummy_input)\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Save the Torch Script module\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Dados/caiopinho/carmen_lcad/pytorch_treino_validacao_teste_ann.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m script_module\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/jit/_trace.py:778\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    773\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrace doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support compiling individual module\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms functions.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    774\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use trace_module\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m     )\n\u001b[1;32m    777\u001b[0m name \u001b[39m=\u001b[39m _qualified_name(func)\n\u001b[0;32m--> 778\u001b[0m traced \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_function_from_trace(\n\u001b[1;32m    779\u001b[0m     name, func, example_inputs, var_lookup_fn, strict, _force_outplace\n\u001b[1;32m    780\u001b[0m )\n\u001b[1;32m    782\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m check_trace:\n",
      "\u001b[0;31mTypeError\u001b[0m: _create_function_from_trace(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: str, arg1: function, arg2: tuple, arg3: function, arg4: bool, arg5: bool) -> torch._C.ScriptFunction\n\nInvoked with: '__torch__.onnx.onnx_ml_pb2.ModelProto', ir_version: 6\nopset_import {\n  version: 9\n}\nproducer_name: \"pytorch\"\nproducer_version: \"1.7\"\ngraph {\n  node {\n    input: \"input.1\"\n    input: \"0.weight\"\n    input: \"0.bias\"\n    output: \"9\"\n    name: \"Gemm_0\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"9\"\n    input: \"1.weight\"\n    input: \"1.bias\"\n    output: \"10\"\n    name: \"Gemm_1\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"10\"\n    input: \"2.weight\"\n    input: \"2.bias\"\n    output: \"11\"\n    name: \"Gemm_2\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  node {\n    input: \"11\"\n    input: \"3.weight\"\n    input: \"3.bias\"\n    output: \"12\"\n    name: \"Gemm_3\"\n    op_type: \"Gemm\"\n    attribute {\n      name: \"alpha\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"beta\"\n      type: FLOAT\n      f: 1\n    }\n    attribute {\n      name: \"transB\"\n      type: INT\n      i: 1\n    }\n  }\n  name: \"torch-jit-export\"\n  initializer {\n    dims: 24\n    data_type: 1\n    name: \"0.bias\"\n    raw_data: \"\\\"\\037\\361>3t\\362>\\203u\\311>,\\371\\342>[\\365}\\276\\323\\310\\227>\\344i\\350\\276\\243\\331\\272\\276F\\032x\\276\\236V\\373>\\306P\\362\\276&\\363 >[\\373\\267>\\216\\213\\324\\276\\204\\010\\222\\276\\024w\\353>y\\026\\223\\276y\\322\\n\\277*+\\t\\277Fnh>\\267\\250\\330\\276\\272\\361\\034?G\\002\\217>0w\\275\\276\"\n  }\n  initializer {\n    dims: 24\n    dims: 9\n    data_type: 1\n    name: \"0.weight\"\n    raw_data: \"\\356R\\027\\276\\213c1\\276\\017dU\\276\\3406U\\276\\366\\347\\307=X\\267C<\\370P\\013\\276$\\0138\\276\\351\\265\\\"\\276\\217\\236\\030>\\0361\\213=\\317\\3456\\276\\034\\022\\331=vM5\\275\\010\\346\\353=\\252\\237\\311<\\310\\0048\\273i1\\203>S>`\\276\\374`\\226\\276\\202\\261\\245=\\005\\027\\214\\276\\327\\300\\253\\275\\203~\\313\\275\\'0Q=\\337\\323w>\\232\\275@>/\\023\\202>\\357\\311u\\274M>]>$*C\\275\\2450\\223\\276z\\344J\\275+\\351\\205=\\204\\313\\004\\276\\366\\223\\371\\274\\322\\215h\\276\\212|\\223>\\365G\\301=\\271\\014g=\\205P\\036>t\\356\\272=\\221\\032\\344\\275\\205\\274\\210\\276V`\\353=\\312Z\\267\\275Y\\005\\217>4U\\360=\\236\\037\\321\\275[\\337\\231<\\307J\\245\\276\\375\\271\\232\\274o\\204$=\\323\\245\\204>\\\\\\305r\\276K\\213\\367=\\013\\247\\202\\276-\\377\\255\\276\\262\\366\\211=(^i>Eu]\\276@\\347O>\\036%\\260\\275\\033\\356Q>\\217\\201\\334\\275\\214\\237\\035>x\\030?>c\\025\\230>\\252]\\265;\\330,\\345\\275\\202\\263G\\276\\024\\202\\206><\\315Y\\2760\\372\\212>^\\264\\230\\276\\336\\343\\345:\\356\\214X\\276\\372\\230}>w\\006J\\276O\\035\\013>\\341\\220\\274;\\2622r\\276\\375M\\232>\\203S\\341=\\244\\260\\037\\276B\\360d>?N\\361=\\000FO>\\014)\\324>i!\\275\\275XM\\'>\\301\\374\\277\\274\\216\\022i>\\0241\\336\\274\\000\\353\\020>\\022%\\025>\\301\\352\\217\\274\\253\\200\\205\\276\\242\\243\\266><.\\274=\\310\\365<=Y\\2443\\276\\310\\017\\360=\\312\\357\\204\\276\\036S\\211>\\237;\\207=\\363Z\\313=\\303\\217\\355=\\371v\\220=e\\332\\203>\\321\\002l>Q]\\332\\273\\325\\227\\002\\276\\300\\3725=|R\\'>x\\277\\326\\275m\\036\\272\\275\\225\\325\\232\\275\\024\\234\\212\\276\\254\\t\\367;\\302\\351\\214\\276\\367\\200E\\276\\002t\\332=\\207\\363z\\276C7\\321\\276Ht\\000;b\\rg>\\225Q$=\\261\\315\\n\\276>\\004J\\276\\241\\315K>\\356F \\276\\207\\n\\323>\\005k\\023\\275\\356\\024t\\276RB\\277=\\037pp<\\004\\210A\\275\\300m\\200\\275\\021\\2229>>[d=\\374z\\323=\\021\\232\\226\\275\\023\\263\\220\\2759\\371\\221\\276\\353m\\202\\276HL?\\276F\\230s>~1\\035\\2769+\\000>\\336\\022\\223>\\010\\017\\330\\276\\004s-\\276\\235\\2522>.\\222\\355=\\220[\\257=\\362e\\313\\276\\274\\366\\314<)\\345\\354=\\255\\000\\231>]\\322(\\276\\205K\\233\\276\\205\\027\\253=\\224\\351\\312\\275:\\321D>\\254~Q\\275+\\321u\\276\\016\\377\\021\\276@\\352o\\275\\275\\330?>7)c>7H\\230\\275\\353\\346M\\276\\025\\222)=\\371\\315w\\276p\\327V\\276V \\r=j\\030B\\275g\\216\\232>:Z\\307=y\\314\\200\\275\\025\\274\\360\\275\\362-;\\275s\\303\\221\\276\\261\\224\\344\\275\\321Uu\\275\\274\\\"\\376<;\\021\\204\\276\\346i\\253\\273\\r\\275[=[\\026\\314\\275gm\\237\\273\\257\\317X>\\263\\374\\203>s\\005+>?\\240\\225\\276\\013\\312\\215>\\025-\\275=!\\331w\\275\\031C\\014=\\r\\372\\344\\275}\\374?\\276\\346\\240\\216\\276\\226\\361\\000=I\\310\\316\\276\\271-\\020>I\\251\\366\\275\\005\\361\\203\\276.\\243\\251>\\375\\027\\003\\274\\273\\237\\001>&\\246\\001\\274\\331\\327|\\274\\334\\362\\033\\276\\360\\234\\323\\276\\034\\317\\305\\275\"\n  }\n  initializer {\n    dims: 12\n    data_type: 1\n    name: \"1.bias\"\n    raw_data: \"\\t\\021\\325\\2765\\343 \\276\\201=\\323\\276E\\266\\237\\276\\230\\317\\263\\276\\002\\t\\322\\276\\245\\372$\\276pd\\230\\276\\307\\267\\257= \\342\\241\\276\\227\\363\\302\\276\\n\\321\\303\\276\"\n  }\n  initializer {\n    dims: 12\n    dims: 24\n    data_type: 1\n    name: \"1.weight\"\n    raw_data: \"\\250?\\037\\276\\020S\\225\\276!>?\\276\\313\\320\\016\\276\\345\\315\\234>\\331l\\013\\276\\277L&>tb\\201>2[\\031>RT\\312\\276\\323\\r\\034>\\220\\035\\002\\276\\315=\\217\\276\\254\\232\\227>\\241\\363$>%\\203\\265\\276\\262\\014\\221>\\214\\272\\367<\\3677\\366=KC\\020\\276t\\365\\235\\275\\246\\326+\\276\\022\\341\\251\\276\\037\\031\\323>\\373\\020\\177\\276\\312\\227Q\\276Ku\\363\\275\\371l\\255\\275\\r\\364y>R\\256>\\2766\\373\\317>\\014\\033\\311>\\203\\311\\241<\\027q\\031\\276z2\\247>\\367\\312\\346\\275\\377\\262\\324\\276\\334\\037\\302=\\035\\345\\025>\\322r|\\276\\353\\003\\220\\275\\243\\273\\264>\\254\\347\\002>\\335\\254\\214=|\\356\\253>mm\\265\\276\\245\\252j\\276#M_>yU\\252\\275\\334\\205d\\276\\036s\\225\\276\\255\\212\\314\\275\\254\\222\\014>\\256\\363\\323\\275\\346\\302$> \\372@>\\222BP>\\267\\205\\243\\276\\024\\002\\217=V F\\275\\230\\016\\031<.+\\370=^\\310\\276;\\034I\\320\\274\\201\\340\\250>\\222\\024\\254<\\\\\\t6>m\\250\\203\\276\\340B_>/\\277\\215\\276\\325\\311\\210\\276m\\226s=77\\031\\275\\023\\3351\\275\\026ia\\276\\304\\247\\221\\276\\222=\\353=\\241h\\216=9aB=\\335<;<{w\\321;\\032NQ\\276\\202\\352\\006=bU\\215\\2751\\211\\247\\276:* >n\\023 =\\233qt\\276\\211;\\231\\274\\212\\024\\220>\\343\\247R>_A|\\276\\t\\315\\024>D\\207\\253\\274\\321b\\224\\276\\022t\\266>\\372\\2539\\276\\263\\260{\\276\\315\\242\\207\\275f\\324\\034\\276A\\252\\225=12\\023\\275g\\351\\310>\\341(\\334=\\242tg\\275{\\016K\\276O^B>\\010H\\260\\275mc\\234\\276y\\373O>\\214\\3437>c\\374q\\276\\254\\370h>h\\352\\212=^\\310\\036=\\214\\315\\276\\275\\020R\\264>D\\236\\303\\275\\351\\304\\332\\275\\025\\277\\254>D\\241\\236\\276^r\\251\\276\\375o\\231<|j\\352\\275y\\271\\257\\275\\222\\031\\024\\276$\\t\\016=v\\271\\246>\\030\\205J\\273N\\017\\\\\\276:\\217\\217>#v\\032\\276\\257dB\\2765{\\206<T\\337\\364\\275\\022R=\\275\\275M*=\\263\\025\\214>!&\\207>\\317\\211\\200\\276\\304\\314\\236:\\206<\\\"\\276f\\362\\227\\276\\210cQ>B\\372\\'\\276L\\013d\\276(K\\364\\275\\361C\\372\\275\\234\\364\\367=\\273w\\243\\275\\303\\350S>\\207\\226\\234>\\276Z\\314=\\356l\\261\\275\\226%\\325>~\\020.>\\373\\260\\303\\276\\257\\273\\206>\\344\\223\\r=M\\247[\\276\\032\\237\\233>\\276@\\217<P\\212\\216>\\026\\267t\\275\\200:\\261>\\367\\311}\\276\\243\\322/\\275\\377 ?>\\274\\377+\\276|\\'\\205\\276\\372\\337c\\2756\\202\\370\\276\\302\\377~\\275;\\261]\\276\\024\\302\\326=!\\001\\036>\\274\\221S>*\\346\\256\\274\\\\=\\203>\\227\\021\\014=>\\217\\027\\275\\227\\361\\307>#\\305\\032>\\340v\\230\\276\\360\\250\\232\\275\\303b\\313>nv\\251>\\010tZ\\274\\223\\\\\\246=\\276\\314\\301\\2762\\247\\204=*\\376];\\343\\364m>\\327Bj>\\256Sn>\\370\\346\\256>\\3337\\340\\2753M\\364\\272\\232\\022\\346\\275J\\276\\276\\275\\252\\237\\006\\276\\255\\220\\353=\\013\\270\\017\\276\\035\\022S>\\274\\210Q>\\342>)\\276\\345OS\\276\\376\\007M=\\240\\212e<O\\323)\\276\\202(\\277\\276\\371\\261v>\\374!\\244\\276\\355}\\263>\\\\\\365\\022>\\240\\330D\\276\\216\\177+\\275\\257=\\005\\276\\260\\222\\333\\275\\353\\356\\232\\276I\\212L>\\271c\\255=&19><\\240;=\\330oh>\\3216_\\276A\\202\\262>\\037\\351s\\274\\2624\\231=X\\241\\367=\\367\\232\\233\\272\\256\\357\\004\\276\\037n/>\\020\\375\\252> \\273\\355=\\233\\275\\000\\275Q\\360m>o\\030/\\274K\\200\\271<\\376lp>\\2528\\325<:\\273\\271\\274k\\346|\\275\\231A\\261\\275\\324\\'6\\275\\014\\330?\\2743\\235\\250<\\246\\213\\265>\\035-Q>?\\364\\252\\276-\\257\\215>]CI\\275\\220\\005\\t\\276qv\\356<\\\\\\337d>\\262\\316D\\276\\177\\277\\205>\\035o\\203>\\342<\\271>{\\303\\212=!t;>\\300\\313E\\2766bH\\276\\035\\360\\017>\\346}*\\276\\361o\\246\\276l\\355k\\276v\\323\\252\\276\\024\\230\\304=\\263\\\"P\\276\\004\\370]>v\\357\\263<\\253v\\\"\\276\\315N\\332\\275\\372\\037\\211>\\017\\222\\340;A\\031>\\275\\265tt\\275\\237uI=\\355\\203,\\276\\261\\321\\232=\\202h\\237>\\266\\232\\322=\\261\\325u\\276\\332Wa>;\\003]\\276\\004\\216M=\\014\\253\\243>\"\n  }\n  initializer {\n    dims: 6\n    data_type: 1\n    name: \"2.bias\"\n    raw_data: \"\\240\\240\\353>\\251\\303\\313\\276N\\\"\\304>\\361\\216\\306\\2764\\331\\237>\\271\\331X\\276\"\n  }\n  initializer {\n    dims: 6\n    dims: 12\n    data_type: 1\n    name: \"2.weight\"\n    raw_data: \"+\\254\\230\\2763\\342\\245\\273n\\245\\345\\275E\\230Q\\276\\257\\262\\274\\276\\243\\000\\243\\276\\330qG\\276\\274%v=Cm\\267>\\004\\177\\213\\276!\\236\\277\\276k3\\267\\276L\\364\\341\\273\\216L\\226>\\224<w<0\\034=>\\356?\\332>o\\332\\376=`]\\227;k\\333\\327>@\\337\\237\\276}\\035\\226>\\265\\357\\313>\\250%\\264<$tJ\\274`\\235\\001\\277\\241b\\024\\275C\\320\\215\\275\\242\\001`\\276O\\324p<\\037\\034\\343\\276\\003\\017k\\276N4\\211>a\\250\\316\\274g0\\266\\276\\033\\206\\224\\276\\313y\\247>E\\352\\351<\\243#\\343<2\\024\\265>\\210(\\210>\\245\\367c>\\201}\\224\\275\\343\\316\\346>(\\032\\023\\276Ys\\205>T\\037\\367>\\261\\2531>6\\347\\002\\277\\021\\217\\274\\276h\\320\\000\\277\\222N\\257\\275\\022\\306\\326<\\226\\255Q\\276\\220\\266\\036\\276\\000k\\275\\275\\n2\\312>\\371a\\006\\276\\322Y \\276QN\\206=\\037\\351\\277>\\234!Y>\\322\\373\\356>\\257L\\245>\\275G\\270>\\266\\\\\\315>\\316Bm>\\375b\\220>\\252\\215\\212\\275\\036i\\213=\\376\\026\\177>o\\234\\265>\"\n  }\n  initializer {\n    dims: 150\n    data_type: 1\n    name: \"3.bias\"\n    raw_data: \"\\355\\013]=\\277\\330\\005\\276+\\264\\375<\\177]&>\\010s+\\276j]\\263=\\265eD>\\263J\\261\\275N\\022L=\\337\\263\\352=6\\374\\364\\275\\342\\300\\247\\274.\\303\\231=`\\233\\242\\275U\\266\\256<\\231\\177\\241=\\203\\205\\227\\275sb\\315=\\331\\3402>\\213#\\027\\276\\303Q\\312=t\\214\\021=\\007]\\247\\275\\325\\224\\r<t^\\246=\\024j\\010\\2760\\342\\360\\274\\017M*>|\\333j\\275\\205X\\252=\\374\\271F=\\225\\025\\202\\275\\370\\022\\275=:\\260A>\\2477]\\276\\240Y\\255\\273\\344^&>\\262a\\315\\275H^O=\\032\\255g=\\360G\\007\\276\\222}6\\275m\\366\\352=\\023\\001\\213\\275y\\t\\203=\\321o\\332=\\016\\020/\\276\\031(\\027=?(X>\\320\\254\\r\\276a\\372p=E\\020 >H\\303)\\275Y\\257\\310=\\264\\023{>B\\362<\\276\\234\\234\\255=\\257Y\\032>\\ng<\\2762\\nt\\275V79>\\361\\211\\013\\276gA\\271;\\'ut>KZ\\306\\275e\\2017<I\\237\\203>J\\350\\366\\275\\337{\\203=\\3609\\017>\\235e+\\276cQf\\275%ol>\\341\\330-\\276\\266\\236T\\274\\322\\032\\037>O\\030\\304\\275}\\266\\007=\\035gy>\\377\\023\\265\\275FM\\235=\\332lz>\\315Y\\236\\275\\2630\\245=\\000\\\"U>\\014\\312\\321\\275&\\2543\\274z\\261c>\\024\\305\\t\\276b\\377\\261<\\266)%>\\274w\\337\\274/\\341P<\\324\\262\\225>\\021-p\\275\\372\\223/<\\305\\227\\221>\\215\\3316\\276\\340\\013==b\\263y>\\\\~C\\276\\\\\\225\\356<\\010t\\213>\\253!=\\276\\212m\\230\\275F$\\232>j1\\002\\276r\\214\\021=(8:>\\013\\363\\346\\275\\235\\373\\031\\272\\000\\236\\225>\\0072=\\276\\014\\323\\361=}\\207\\225>\\270\\250\\016\\276\\262\\371\\031=IJ\\231>\\205\\366L\\276\\211\\271\\342\\274\\303\\300\\262>\\371\\006\\010\\276\\373!\\322=VH\\234>*}\\311\\27509G=\\247\\216o>\\345\\352[\\275\\321\\267\\256\\274T)\\251>F\\340\\350\\275q\\003M\\274\\210\\365g>$\\334\\236\\275\\371\\306\\005\\275T\\177r>\\016D\\345\\275\\345\\207)=|^\\253>f3\\324\\275\\272\\311\\024=\\321wK>\\227d\\250\\275\\321\\333B<48\\220>\\026\\204\\267\\275\\371\\224\\243=\\270\\217\\263>=\\210\\376\\275\\326/\\244\\274\"\n  }\n  initializer {\n    dims: 150\n    dims: 6\n    data_type: 1\n    name: \"3.weight\"\n    raw_data: \".\\334\\216>\\320K\\004>R\\234\\327\\275\\n\\366E\\276\\264t\\023?\\352\\201\\334\\276\\3134\\354<\\016\\315=\\276q8\\304\\276\\216xu\\276\\212\\263\\326\\276\\276\\213\\221\\276nao>7\\216\\224=\\023-\\325=\\226V\\250=B\\206\\030\\276:\\225)=S\\231\\314>\\241\\273.>\\334\\3376=lv\\016=\\246{\\323>\\311\\274\\010\\277\\331\\267o<\\306\\272\\205\\276bq\\001\\277\\311\\236\\267\\276\\254\\333\\236\\276\\214\\302 \\276!\\2219\\276\\0247D\\276i\\347\\306\\275\\255\\303\\203>\\t\\261\\213=\\215\\327g\\276\\314\\204\\265=%Ug=j\\371\\010\\275\\372\\273\\233=\\312\\007\\005? X7\\277\\251\\261\\216>T\\013\\344\\276:\\335\\010\\277s\\246\\200=\\202\\035\\337\\276q\\252w\\276\\350\\031\\307>\\266\\371\\215=\\224\\315\\021>(EF>\\\"\\346r\\276\\006JF=\\rmE?aN\\371=\\376\\371\\016\\274\\221\\003\\235\\275\\010S\\233>^\\223h\\276\\3454;\\274\\314@\\\\>\\3528\\216\\273c\\372\\243\\276\\310l$\\277\\240\\325\\340\\276\\223D\\254\\276=d\\201>S\\252\\021>\\341l\\236\\276\\\\\\021Z=\\2472\\250\\275N\\316\\007?5\\304\\267>\\334 8>E\\334\\262\\276\\375^\\373>~\\021\\327\\275\\230[\\226>\\216\\203F\\276\\260\\345\\225\\276y\\351\\277<\\302\\301\\027\\277\\'\\034\\246\\276\\001c\\354=\\322\\334\\\\\\276\\003\\024=\\276\\273Z\\303=\\2127\\230=\\264\\303\\316=\\305\\305\\315>\\332\\335\\204>e5\\201=\\225W\\303\\276\\335\\336\\304>\\255!\\222\\276M\\314?>\\312\\350U\\2768)\\236\\276\\232\\337\\244<\\3576\\r\\277Ti\\302\\276\\222/\\\"\\276\\307\\271N\\276\\334\\323\\260\\275f\\232\\240>\\376H6=\\200\\220\\201\\276\\2325g>D\\177\\320\\275A\\211\\353\\275\\272\\275\\302<\\240\\177\\023?\\310\\035\\353\\276\\235|\\303>\\000\\372!\\276\\2751\\262\\276\\001n^\\276D\\303\\010\\277\\266\\336\\267\\275\\225}\\252\\276]\\261\\006\\276\\270\\320%\\275\\334\\267x>\\314g\\231=s1\\255\\276\\214\\010\\n?\\276\\350Y>\\322\\356\\204<\\2659\\006\\277^\\314\\354>\\3702|\\271)\\317\\341=\\031\\320\\t\\276n\\221\\204\\276\\017\\240I\\275\\353\\245\\014\\277\\233\\027\\320\\276W)\\226\\274)\\202Y\\275\\2260\\210\\275\\305\\200\\005\\275\\266\\001c=o\\225*=\\267\\275\\346>D/\\310>p\\212~>\\'\\000\\345\\276\\236\\222\\223> /e\\276\\034-\\242\\276\\264\\241\\341=\\244V\\027\\276D$\\327\\276\\035\\265\\340\\276\\207\\n\\373\\276\\034\\336\\237\\275\\200\\001\\277\\273\\003\\035\\251\\275\\242\\330O\\276\\277\\177\\350=\\351\\334\\365=0\\207\\237>\\034>\\242=\\304\\332\\365=\\376\\242\\234\\275\\314\\257\\n?\\343\\372\\224\\276\\335\\345\\204\\274\\2178\\027\\276\\317\\351}\\276\\016\\315Q<A\\273\\007\\277v\\304\\006\\277\\377ws<_}\\031\\275\\'\\032g=\\t\\266\\177>\\207K\\262\\275\\247\\3343\\276#\\341\\342>\\035*\\361=\\244i3\\275O\\257\\014\\277\\013\\351\\242>\\265\\201\\026\\276\\373\\325\\034\\276\\\"\\001\\300\\276\\303x\\364\\2762\\266\\224<>\\324\\255\\276k\\202\\000\\277-\\366B\\276\\362!\\241\\276\\262\\363P\\276)\\033\\235>A[\\010>\\236AX\\276\\346\\226\\250>@8\\335\\275\\305w\\303;\\014\\205\\270<\\362\\004\\006?\\\"\\007\\240\\276\\2114\\372>\\232\\245d>\\032W\\256\\275y\\314\\014\\277\\330v,\\277\\357M}=m\\304\\255\\275\\3204\\241>YQz>T)Q\\276\\036\\366\\322\\275\\034\\344.\\2751\\360\\241>\\360\\370F\\2768S\\013\\276\\201P\\315\\275\\001\\307\\306>O\\344\\301\\276\\000yb=\\274qe\\275<\\340^\\276\\230\\010\\035\\276\\256^\\t\\277\\213\\210\\307\\276\\021\\t{=\\361\\212\\034\\276\\336\\000\\272\\275\\360%1>\\260JI<$\\274\\336\\274\\353<\\r>\\221-\\216\\276Gl\\255\\276\\314X\\005\\277\\017\\276I?Q\\231k<\\376\\361f\\275\\206\\310\\356\\275\\r$\\250\\276\\376\\037\\221\\276\\330\\303\\320\\276\\203\\007\\245\\276=aL\\276\\n\\t\\007\\276\\021kl\\276C\\020\\203\\276@\\325\\202>}5\\032>\\317,r>\\256g\\255>e\\237\\236>:\\020\\370\\276\\231-,>\\213\\262\\301\\276h\\212\\333=\\272\\0258\\276P\\\"\\217\\276\\021\\263\\205<\\215/\\t\\277\\376\\213\\334\\276\\307t\\242=A\\222\\223\\276\\327\\322F\\276\\325\\271\\207>t\\346t=\\326\\212\\301\\274.\\306\\002?\\3471\\314\\274\\013\\323(\\274G\\221\\276\\276c\\260.>\\226\\'S\\276Y2:>]\\000\\020\\276U\\322\\303\\276\\004\\304\\267\\276F\\261\\326\\276Z\\334\\310\\275\\325x\\234=\\310\\016\\306=\\370(\\365=\\265Sf=\\262\\352\\343\\275\\022\\226?\\275\\253\\310\\246>\\305|\\214>nF\\354> v\\316\\275\\253*\\'>\\177A\\337\\276\\275,B=_\\030\\014\\276\\231\\317\\260\\276\\224\\330\\213\\276\\202\\310\\327\\276G\\024\\201\\276\\372fF\\275w!\\220=l\\376\\352=\\356\\017\\346=ik\\253\\275{? \\276\\362\\014X>\\333n@>\\316C\\236>\\273\\310\\250\\276\\376\\002\\245>\\371_\\221\\276\\025\\230\\210=\\332\\232\\016\\276\\277NU\\276\\364\\263\\277=0\\260\\024\\277\\216\\330\\010\\277n~[\\275C\\273@\\276:\\222\\211\\275{X\\250>Nh\\3127\\032wT\\276FT\\353>\\177{\\224\\276\\230%\\243:@\\256!>\\363\\304\\024>\\373\\240\\356\\276\\323\\361z>\\341\\231^\\274_\\324\\216\\276\\341\\020\\333\\276$*\\372\\276]\\260~\\275(L\\224\\275\\014\\377\\256\\275\\363\\004\\324;\\023\\370{>Im\\355\\274\\016\\236O\\276J\\361\\246>\\300\\255\\203\\276\\233\\326\\233\\275t\\351w\\276\\350\\267\\337>f\\263\\001\\276\\024\\341_>\\232\\025\\314\\275\\033\\351\\267\\276+\\030\\321\\276\\243\\236\\333\\276R\\300K\\275\\316\\220\\232\\276+\\203\\252=\\233\\344\\204\\275\\274(\\314\\276\\013&K>\\212`\\305=(\\362\\223=\\226\\373\\254\\275\\021\\236\\014>\\272;\\177\\276\\343\\342\\365>\\235Y\\207\\276&,\\350\\274\\271\\262\\233\\274\\326\\341v\\276Gb\\242\\2760\\201\\351\\276~3\\242\\2763%\\010\\275(\\272\\375;\\326\\220\\206\\274 R\\204\\275)\\314\\002=\\2255\\350<\\344i\\215<vE\\000\\276S\\351-> V\\216\\275Wp\\224>\\221d\\n\\277\\203\\244\\321\\274\\346\\240\\026\\276@\\244\\232\\276\\376\\353\\010\\276\\213v\\344\\276\\342\\357\\313\\276Q5~>\\007\\326\\374\\275\\022\\331\\320\\275\\022\\305\\210=\\022\\261I\\274\\214m$>\\312\\242(\\276\\327f\\231\\275\\344\\322\\203>\\365.\\220\\275\\316G\\277>\\272\\257\\030\\277\\222-/>\\375l\\034=C#\\027\\276\\204rd\\276\\306\\366\\025\\277\\023\\350\\226\\276\\036#4=d.\\321\\275c\\260\\333\\274\\317\\314Q>d\\373\\000\\275\\301v\\266\\275\\241\\t\\010?-\\374\\201\\276\\330\\361\\037\\275J\\216\\247\\276\\025\\342\\000>\\017\\001\\326\\2751\\356\\276>\\324\\262!>\\212\\233\\256\\275B\\350\\301\\276\\333\\035\\'\\277\\377\\337\\316\\275D\\263\\240=L\\216\\226=\\246a\\007\\275\\240U\\221\\276\\311XT=Q\\007y>\\346\\325\\231>\\261[i\\276\\013\\314\\036>F84\\275\\006\\350\\223>\\223\\254\\203\\276\\024Q\\002\\276\\025tc\\274v\\327\\225\\276\\320\\376\\357\\276E_\\270\\276\\327\\327\\200\\276\\007~\\205=hr\\301\\274\\272\\027~\\275u\\324\\312\\275\\007\\274)=&\\366\\007>o0\\204>\\255\\354s\\276Q\\264\\004<9\\376\\301\\276E\\373=>\\203;b\\276F\\r\\303<\\312\\\":=\\241\\364\\363\\275L\\317.\\276\\272\\013\\021\\277\\036Q\\332\\276\\275\\271\\256=z\\222=>\\330\\327H>\\2779\\242<\\377\\003\\\"\\276\\263\\\\c\\275\\010N\\235<\\275\\007X\\276\\2667\\\">\\016\\r\\t\\276\\214\\032\\016>\\352\\242\\014\\277[ \\205\\276\\035\\331\\263\\275{\\306\\203\\276|\\3337\\276?\\350\\311\\276\\257I\\007\\277\\357\\337\\024\\276\\316Tt\\275\\213qC<f\\230B>\\357\\253\\030\\273\\320/\\\\\\276S\\303\\257>y\\352\\347\\276ia\\025<\\330\\356\\214<\\375i\\210>\\014\\023i\\276\\375\\252\\245\\275\\343\\333\\272\\2758ii\\276\\315\\353\\272\\275~\\325\\363\\276\\261\\205\\370\\276\\232.\\002>\\343;\\373;\\302\\255\\326=\\333\\263\\203>\\216K\\033\\2764\\004\\n\\276\\355\\'\\254\\275\\222\\025\\274\\274r\\363\\244>\\275\\247\\275\\276\\366\\035N>\\357\\267\\326\\276\\355\\302\\240>B9Y\\276\\277u\\254\\276t}I\\275\\227\\307\\003\\277\\005,X\\276\\307\\304\\214>\\222\\263\\324=:r\\236=\\363d\\223\\275\\330t\\352\\275\\n%5>l\\315\\\\\\276\\275\\252\\252\\275A\\253\\243>{\\243\\253\\276\\323\\355\\315>\\031\\007\\266\\276f4\\201>\\242\\312\\036>\\363\\277V\\275\\016z\\223\\276\\024F%\\277\\303\\347s\\276\\236+N=\\257l\\333<\\361a\\002=\\211=L<\\261a\\031\\275\\270\\265\\370;\\373\\365\\021>,P\\226\\275\\2357\\214>2\\361\\000\\277@U|>B\\n\\272\\275\\301\\274;>J\\251\\223\\276\\311\\343\\237\\276\\320\\337^>c\\223\\t\\277}\\327\\356\\276B(\\233<\\236y\\201\\274\\247\\245\\273\\274\\r-\\220\\274l\\211Y<v\\315\\n=\\245\\027\\253>\\217\\356\\313\\276\\234\\221E>bY\\325=#\\254\\343=\\334)\\244\\276\\213\\365~>\\214\\320\\334\\276\\001M\\366\\276[M!>\\362@\\333\\276\\264\\025\\233\\276\\376\\220j\\273\\033\\325\\317>\\336\\\\\\267>\\254B\\030\\276\\344\\257X\\276\\331k\\252\\275\\026\\226\\030\\275\\036\\263\\000\\276\\347\\214\\312>\\357\\237\\001\\276\\002\\326q;\\326\\373\\025\\277:\\373\\353;\\323?A\\276*\\201\\347\\276\\334(\\327\\276\\022x\\217\\276\\317z\\330\\275\\350\\336\\036\\276,%\\003\\275<\\275\\350\\273\\305\\355\\205=\\2621\\022=\\342r\\010\\276\\207^\\360>\\335}^\\275\\350 \\000?\\223n)\\276\\354\\322/;\\035\\354\\330\\275\\261m\\302\\275\\374P\\277\\274\\243\\343\\247\\276.\\027\\n\\2775\\210\\237\\276~2\\034\\276f\\276\\273\\275\\226\\312.\\276\\321\\335\\033\\276\\023Jj=z\\275\\356=\\207I\\226\\274n\\030\\271=H\\002\\216\\276\\213*\\234>KE\\367\\275p+\\022>\\022\\364\\250\\276\\336F\\016>\\021\\374\\035\\275US\\237\\276d\\225\\347\\276\\361z\\314\\276^\\373\\213\\275\\n\\356f>\\231\\204a=\\255:}\\275\\350\\264\\235\\276<\\261\\016=6\\314\\271>\\357\\370\\231=hH\\024\\277\\227;\\306=]\\332c=(\\324\\246>\\353K\\211\\276\\267\\254\\005>\\240\\003r\\276\\257\\311\\321\\276%\\331<\\276\\263\\367\\272\\276E\\3669\\276mK6=\\324\\342j\\27659<\\2768\\301\\010>\\207\\311\\260=\\034H\\006=IM\\205\\274g.\\031\\276o\\001\\260>v\\246\\n\\277\\031Z\\300>\\006c\\251<$d\\032>\\335!m\\275\\267\\023g\\276\\303p5\\276\\3426\\000\\2771q\\211\\276\\233Y\\037>\\265\\227i\\275\\316Q\\210\\275y\\277\\242\\274\\033\\244\\251;\\255\\033\\020>Q\\233\\203>\\225\\335\\222\\276\\201h\\307>\\307#j\\275\\340w9<3q\\211\\276\\020_\\013>\\330\\010\\226\\275\\230\\351\\257\\276\\177Q\\344\\276[\\240\\275\\276^1T\\275\\221#N\\276\\307}%\\275\\317[\\251=\\260\\322\\245>\\276\\314n\\275\\367w\\274\\276Q\\252A=\\223\\005\\350\\276\\001|p>\\337c\\252\\275\\224T4>\\030\\306\\223\\276\\212\\277\\356>\\370\\311\\246\\276\\256\\353\\364\\276M\\347\\367\\275\\0212\\326\\2763|\\274<\\352m!\\276\\312Y2\\275\\000\\370\\365\\274\\200q\\023=\\013\\251i=5-\\327\\275f\\314\\236>m\\t\\353\\276,(\\234>e\\230\\033<\\017\\367=>\\'b\\227\\275\\351\\210\\007>\\363QZ\\275\\024\\016\\262\\276Y\\374\\002\\277\\016\\n\\263\\276qX\\325\\273\\364\\324\\002>\\304\\364{>\\2679.>\\243pY\\276\\r\\337\\341\\275\\322\\311\\004>\\272t\\035\\276\\0201\\231\\276\\375Z\\361>pk\\371\\272\\332\\004G=\\026\\016\\r\\277Y\\243Q\\275\\201\\2701=\\245\\2579\\276\\351*\\254\\276x\\032\\341\\276e=\\236\\276\\020\\2715\\275\\235\\267\\240\\274\\013\\331\\301=1d\\232>\\300/\\330\\275\\027\\316\\206\\276l\\344\\027\\276\\366\\033\\256\\276\\367\\370\\274>%\\307;\\276E\\306\\231<\\313\\271\\364\\276Vb\\304\\276C\\002\\213<z~@\\276)\\031\\223\\276\\210h\\263\\276f.\\n\\277\\014\\342\\034>\\222L\\371\\2751\\376f\\275Q^9>\\372L\\031\\275\\245\\317\\373;X\\034M>\\303\\233\\370\\276\\250\\3373>~\\202\\257\\276/\\374\\316<\\267\\212\\311\\275\\260\\217/\\276\\252g\\330\\276\\233\\242\\001\\277\\035\\233f=\\243\\250}\\276\\263\\027\\354\\276^\\026\\327\\273\\014\\266\\306\\275dn\\027\\2763\\276\\003\\276c\\335\\375=w\\242\\030>\\365\\263\\325>\\263\\244\\035\\276\\367D0?f\\030\\211\\274>\\265^\\276`\\251W\\276\\375\\210\\312>\\242\\233\\324\\275\\025\\274|\\276<e\\344\\275\\356\\035\\013\\2779\\\\\\004\\276L\\351&\\276\\204\\254Z\\274I\\326\\226\\275\\247*$\\276\\311q\\374=\\366\\327\\025=\\247\\321\\261>\\363\\266\\347\\276\\014\\332\\231>2\\270\\257\\276\\207\\262\\201>j\\316\\214>X\\347\\260>\\001Ug=\\340\\t]\\275a\\034\\023\\275\\357v+\\277\\252d\\231\\276\\350,\\023\\274\\240\\002\\362=\\345\\266\\006=\\227#m\\276\\371?\\271<\\035\\363\\376=\\352\\316J>\\265\\320\\301\\276\\002\\313\\251>\\307\\300\\324\\276h8`\\275\\323x\\206\\275\\342\\225\\264>oX\\215\\276\\301\\274\\317\\276\\213)\\217\\275L\\234\\330\\276;\\201\\304\\275\\033\\000\\003\\275\\027!t<\\211`\\'=\\270\\202\\211=\\3335\\373\\274y\\277\\247\\275Y\\311^\\276\\222\\211\\017\\277\\'j\\232>\\020\\204\\346\\275\\322\\200\\023>\\362\\202\\300\\276,Ey\\275kZ5\\276\\316\\265\\257\\276\\331\\'3\\276\\202&\\254\\2763W\\243\\276\\352\\221\\326=\\277W\\336\\275`\\337\\207\\275rV\\363=\\205`\\313\\273\\312\\021\\263<i\\372A\\274c)\\321\\276\\371\\023\\217>\\204m!\\277`\\237%>t\\211\\234=\\226}v>\\275Q\\227\\276\\247\\206\\310\\276fcy<X\\023\\320\\276\\226k]\\276Q\\332\\201\\276<da\\275\\261\\343\\257\\275;#\\247\\275\\245\\214\\021>\\202\\304\\200\\275\\023Y\\202\\273m_\\274\\276\\261\\250\\363>\\226\\034\\253\\276P\\242\\371=\\256\\251^\\275\\311 4\\276MU\\227\\276]]\\342\\276\\314\\307\\370\\275\\333:r\\276\\373\\035\\273\\276\\346\\246i\\274T\\236\\014=n\\373\\352=\\267\\304V>o\\301\\342\\2755\\201I\\276\\356\\274l>Z\\312/\\277\\250v\\214>\\\\\\277\\320<)\\362&\\276\\266\\n\\213\\276I\\177\\272>\\347\\254\\207\\276 &\\322\\276\\302\\256\\365\\275\\251\\303\\305\\276\\243k\\375\\274xO\\026\\274J\\354\\237=\\330\\022e<W\\2451\\276i\\256\\312<\\320\\227\\306=\"\n  }\n  input {\n    name: \"input.1\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 9\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: \"12\"\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 150\n          }\n        }\n      }\n    }\n  }\n}\n, (tensor([[ 0.2144,  1.4291, -1.2174, -0.6024,  0.2654,  1.4626,  1.5191, -0.3682,\n          1.2702]]),), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x7f17e83d9af0>, True, False"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"model.onnx\")\n",
    "\n",
    "# Convert the model to Torch Script\n",
    "script_module = torch.jit.trace(model, dummy_input)\n",
    "\n",
    "# Save the Torch Script module\n",
    "script_module.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "       -2.487       4.803       0.001]]\n",
      "[[ 1.16240348 -0.45512402 -1.25481378  0.4579256   1.19118628 -0.4031037\n",
      "  -1.25742504 -1.43256721  0.07519625]]\n",
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001]\n"
     ]
    }
   ],
   "source": [
    "X_sample2 = X_test_raw[0: 1]\n",
    "print(X_sample2)\n",
    "\n",
    "X_sample2 = scaler.transform(X_sample2)\n",
    "print(X_sample2)\n",
    "X_sample2 = X_test_raw[0]\n",
    "print(X_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7757706.153 -363881.716      -2.482       8.499 7757721.272 -363870.038\n",
      "      -2.487       4.803       0.001] -> [ 4.8010063  -0.00074159  0.01997822  4.8005514  -0.00091523  0.02000268\n",
      "  4.814805   -0.00176182  0.01970529  4.8287263  -0.000778    0.02051836\n",
      "  4.8326116  -0.00174367  0.01992373  4.856453   -0.00167146  0.01983681\n",
      "  4.864167   -0.00193731  0.01993301  4.879089   -0.00164818  0.02014743\n",
      "  4.8937235  -0.00073487  0.02012613  4.8967085  -0.00159477  0.01993886\n",
      "  4.9280586  -0.00181691  0.01975316  4.925619   -0.00195716  0.02010386\n",
      "  4.950785   -0.00190242  0.02001777  4.957052   -0.00186971  0.0202428\n",
      "  4.97818    -0.00249793  0.01988537  4.995721   -0.00255796  0.02014657\n",
      "  4.994455   -0.0025937   0.01995826  5.008133   -0.00280979  0.02011759\n",
      "  5.0308924  -0.00291541  0.01984772  5.0377316  -0.00323275  0.02050596\n",
      "  5.0456805  -0.00307235  0.0199565   5.065904   -0.00340613  0.01975301\n",
      "  5.074639   -0.00332363  0.01996499  5.1010294  -0.00328155  0.01999776\n",
      "  5.1006637  -0.00362112  0.01982425  5.1268015  -0.00374103  0.01991623\n",
      "  5.138431   -0.00395512  0.01991449  5.14359    -0.00391159  0.01998987\n",
      "  5.1597624  -0.00423715  0.0200338   5.164531   -0.00380588  0.01998207\n",
      "  5.1826973  -0.00437438  0.02011609  5.1961102  -0.00469906  0.02033865\n",
      "  5.2155013  -0.00415806  0.02007735  5.2181277  -0.00392795  0.01971572\n",
      "  5.235365   -0.0039203   0.02010624  5.2443867  -0.00465819  0.01985199\n",
      "  5.254088   -0.00413277  0.02006014  5.2746816  -0.0038663   0.0199084\n",
      "  5.2876625  -0.00470388  0.0199628   5.2932086  -0.00375362  0.02029131\n",
      "  5.3144155  -0.0036635   0.02001484  5.3334975  -0.00344844  0.01998478\n",
      "  5.3484445  -0.00428118  0.01996177  5.3510637  -0.00424473  0.0199277\n",
      "  5.3572283  -0.00406776  0.02008447  5.3868194  -0.00447915  0.02004181\n",
      "  5.3942337  -0.00368278  0.01986287  5.4088097  -0.00456195  0.02005492\n",
      "  5.414704   -0.00376444  0.02006499  5.440771   -0.0048934   0.01993128] (expected [4.803 0.001 0.02  4.819 0.001 0.02  4.835 0.001 0.02  4.851 0.001 0.02\n",
      " 4.867 0.001 0.02  4.883 0.001 0.02  4.899 0.001 0.02  4.915 0.001 0.02\n",
      " 4.931 0.001 0.02  4.947 0.001 0.02  4.963 0.001 0.02  4.979 0.001 0.02\n",
      " 4.995 0.001 0.02  5.011 0.001 0.02  5.027 0.001 0.02  5.043 0.001 0.02\n",
      " 5.059 0.001 0.02  5.075 0.001 0.02  5.091 0.001 0.02  5.107 0.001 0.02\n",
      " 5.123 0.001 0.02  5.139 0.001 0.02  5.155 0.001 0.02  5.171 0.    0.02\n",
      " 5.187 0.    0.02  5.203 0.    0.02  5.219 0.    0.02  5.235 0.    0.02\n",
      " 5.251 0.    0.02  5.267 0.    0.02  5.283 0.    0.02  5.299 0.    0.02\n",
      " 5.315 0.    0.02  5.331 0.    0.02  5.347 0.    0.02  5.363 0.    0.02\n",
      " 5.379 0.    0.02  5.395 0.    0.02  5.411 0.    0.02  5.427 0.    0.02\n",
      " 5.443 0.    0.02  5.459 0.    0.02  5.475 0.    0.02  5.491 0.    0.02\n",
      " 5.507 0.    0.02  5.523 0.    0.02  5.539 0.    0.02  5.555 0.    0.02\n",
      " 5.571 0.    0.02  5.587 0.001 0.02 ])\n",
      "[7757801.761 -363519.424       3.074       8.016 7757831.521 -363531.805\n",
      "       2.493       8.334       0.025] -> [8.332953   0.02570583 0.02057826 8.279287   0.0260936  0.01937635\n",
      " 8.279661   0.02568588 0.02047574 8.281424   0.02454777 0.01915007\n",
      " 8.274772   0.02515006 0.02098195 8.281982   0.02503929 0.01914372\n",
      " 8.278026   0.02583499 0.0184833  8.280119   0.02489562 0.02037758\n",
      " 8.2803     0.02479535 0.02028337 8.273154   0.02475645 0.01960913\n",
      " 8.286489   0.02491888 0.01928371 8.275139   0.02615823 0.01904969\n",
      " 8.283588   0.0249912  0.020569   8.279796   0.02533591 0.02059739\n",
      " 8.283659   0.02476165 0.02070565 8.287676   0.02572682 0.02014912\n",
      " 8.276308   0.02517223 0.01923848 8.27715    0.02432403 0.01998729\n",
      " 8.284091   0.0255501  0.01925227 8.280431   0.02544269 0.02009993\n",
      " 8.276081   0.0244431  0.01982384 8.280431   0.02421162 0.0209767\n",
      " 8.276962   0.02461271 0.02015173 8.288047   0.02541332 0.02063011\n",
      " 8.277835   0.02415167 0.02029199 8.287139   0.0238065  0.01952587\n",
      " 8.285027   0.02313591 0.01905958 8.280449   0.02377018 0.01999696\n",
      " 8.28143    0.02516142 0.02103802 8.275567   0.02468783 0.02011264\n",
      " 8.279786   0.02446736 0.0203737  8.279707   0.02499932 0.01933622\n",
      " 8.283042   0.02523439 0.01940995 8.276601   0.02493435 0.01961403\n",
      " 8.27914    0.02568574 0.02154677 8.276657   0.02521071 0.02053792\n",
      " 8.274283   0.02505938 0.02104003 8.278971   0.02595724 0.01849017\n",
      " 8.2789345  0.02633464 0.01930214 8.273977   0.02619009 0.02057384\n",
      " 8.278184   0.02495228 0.0193009  8.282623   0.02417462 0.0207606\n",
      " 8.285052   0.02478037 0.02051708 8.276708   0.02573486 0.01951893\n",
      " 8.273311   0.02499515 0.0200881  8.283986   0.02586628 0.01974319\n",
      " 8.279172   0.02529712 0.02044044 8.281159   0.02531607 0.01932614\n",
      " 8.275503   0.02524789 0.01950336 8.284525   0.02565493 0.01986678] (expected [8.334 0.025 0.02  8.332 0.025 0.02  8.331 0.025 0.02  8.329 0.025 0.02\n",
      " 8.327 0.025 0.02  8.326 0.025 0.02  8.324 0.025 0.02  8.323 0.025 0.02\n",
      " 8.321 0.025 0.02  8.319 0.025 0.02  8.318 0.025 0.02  8.316 0.025 0.02\n",
      " 8.315 0.025 0.02  8.313 0.025 0.02  8.312 0.025 0.02  8.31  0.025 0.02\n",
      " 8.308 0.026 0.02  8.307 0.026 0.02  8.305 0.026 0.02  8.304 0.026 0.02\n",
      " 8.302 0.026 0.02  8.3   0.026 0.02  8.299 0.026 0.02  8.297 0.026 0.02\n",
      " 8.296 0.026 0.02  8.294 0.026 0.02  8.292 0.026 0.02  8.291 0.026 0.02\n",
      " 8.289 0.027 0.02  8.288 0.027 0.02  8.286 0.027 0.02  8.285 0.027 0.02\n",
      " 8.283 0.027 0.02  8.281 0.027 0.02  8.28  0.027 0.02  8.278 0.028 0.02\n",
      " 8.277 0.028 0.02  8.275 0.028 0.02  8.273 0.028 0.02  8.272 0.029 0.02\n",
      " 8.27  0.029 0.02  8.269 0.029 0.02  8.267 0.029 0.02  8.265 0.03  0.02\n",
      " 8.264 0.03  0.02  8.262 0.03  0.02  8.261 0.031 0.02  8.259 0.031 0.02\n",
      " 8.257 0.031 0.02  8.256 0.032 0.02 ])\n",
      "[7757398.832 -363523.465       2.313       8.55  7757418.023 -363547.615\n",
      "       2.224       7.703       0.001] -> [7.68352    0.00130333 0.02032702 7.641883   0.00083899 0.02039786\n",
      " 7.6465163  0.00056658 0.02013385 7.6483893  0.00194509 0.02029281\n",
      " 7.6505     0.00100994 0.01988105 7.6568565  0.00122235 0.02029719\n",
      " 7.6596446  0.00039227 0.02037289 7.662617   0.00142402 0.02003271\n",
      " 7.667677   0.00241441 0.01962855 7.669256   0.00201954 0.02052943\n",
      " 7.6761103  0.00163754 0.01999038 7.6771     0.00058164 0.02000098\n",
      " 7.683269   0.00165032 0.02034155 7.684547   0.00150722 0.01954996\n",
      " 7.6919785  0.00146589 0.02018756 7.695269   0.0005441  0.0205392\n",
      " 7.6975493  0.00094914 0.02031845 7.700929   0.00180373 0.02080054\n",
      " 7.7061877  0.00045523 0.02029929 7.7079177  0.00016031 0.01984137\n",
      " 7.711619   0.00095294 0.01972057 7.7176385  0.00099961 0.01966164\n",
      " 7.720926   0.00110845 0.02040421 7.725027   0.00096409 0.01933991\n",
      " 7.726849   0.00044702 0.01945675 7.7329917  0.00127519 0.02017855\n",
      " 7.737667   0.00104059 0.02027552 7.738297   0.00138625 0.02069708\n",
      " 7.7441926  0.00089028 0.02004447 7.7461205  0.00130421 0.02008313\n",
      " 7.749738   0.00169409 0.02011915 7.7536077  0.00105089 0.02062368\n",
      " 7.760129   0.00061737 0.02020869 7.760017   0.0009951  0.01945942\n",
      " 7.7652626  0.00119765 0.01941936 7.7676105  0.00134489 0.01985163\n",
      " 7.770476   0.00189952 0.01999766 7.776159   0.00147761 0.02066216\n",
      " 7.7798986  0.00109136 0.01993258 7.7812815  0.0016046  0.02023147\n",
      " 7.788701   0.00245623 0.02079733 7.793334   0.00313549 0.02034777\n",
      " 7.795774   0.00259195 0.01947185 7.7981896  0.00216164 0.01940961\n",
      " 7.7987413  0.0028218  0.01963487 7.8069115  0.00203289 0.02025949\n",
      " 7.810602   0.00299086 0.02001701 7.8133383  0.00247199 0.01974632\n",
      " 7.816203   0.00330944 0.02070255 7.8224535  0.00220504 0.01950284] (expected [7.703 0.001 0.02  7.707 0.001 0.02  7.712 0.001 0.02  7.716 0.001 0.02\n",
      " 7.72  0.001 0.02  7.725 0.001 0.02  7.729 0.001 0.02  7.734 0.001 0.02\n",
      " 7.738 0.001 0.02  7.742 0.001 0.02  7.747 0.001 0.02  7.751 0.001 0.02\n",
      " 7.755 0.001 0.02  7.76  0.001 0.02  7.764 0.001 0.02  7.769 0.001 0.02\n",
      " 7.773 0.001 0.02  7.777 0.001 0.02  7.782 0.001 0.02  7.786 0.001 0.02\n",
      " 7.791 0.001 0.02  7.795 0.001 0.02  7.799 0.001 0.02  7.804 0.001 0.02\n",
      " 7.808 0.001 0.02  7.813 0.001 0.02  7.817 0.001 0.02  7.821 0.001 0.02\n",
      " 7.826 0.001 0.02  7.83  0.001 0.02  7.835 0.001 0.02  7.839 0.001 0.02\n",
      " 7.843 0.001 0.02  7.848 0.001 0.02  7.852 0.001 0.02  7.857 0.001 0.02\n",
      " 7.861 0.001 0.02  7.865 0.001 0.02  7.87  0.001 0.02  7.874 0.001 0.02\n",
      " 7.878 0.001 0.02  7.883 0.001 0.02  7.887 0.001 0.02  7.892 0.001 0.02\n",
      " 7.896 0.001 0.02  7.9   0.001 0.02  7.905 0.001 0.02  7.909 0.001 0.02\n",
      " 7.914 0.001 0.02  7.918 0.001 0.02 ])\n",
      "[7756536.421 -363779.861       1.18        8.55  7756528.942 -363813.723\n",
      "       1.441       8.68       -0.007] -> [ 8.648965   -0.00748847  0.02032312  8.593876   -0.00899696  0.02150925\n",
      "  8.5948105  -0.00896706  0.02008479  8.58801    -0.00458245  0.02139455\n",
      "  8.591499   -0.00721812  0.01868896  8.588325   -0.00662043  0.02156892\n",
      "  8.590234   -0.00932901  0.02237298  8.5854225  -0.00596195  0.0196064\n",
      "  8.587645   -0.00375348  0.01870826  8.590537   -0.00439189  0.02173356\n",
      "  8.581299   -0.00550023  0.02065581  8.587846   -0.00899826  0.02101593\n",
      "  8.5828     -0.00535823  0.02023461  8.580964   -0.0060997   0.01808261\n",
      "  8.584315   -0.00537994  0.01971883  8.577991   -0.00857803  0.02118644\n",
      "  8.587483   -0.00700641  0.021599    8.58501    -0.00396815  0.02187604\n",
      "  8.579759   -0.00841048  0.02152368  8.5788145  -0.00893942  0.01926094\n",
      "  8.583215   -0.00601663  0.01948993  8.582711   -0.00559088  0.01828561\n",
      "  8.585115   -0.00567044  0.02085053  8.572363   -0.00679334  0.01776277\n",
      "  8.579396   -0.00675549  0.0184348   8.573252   -0.00431146  0.02105259\n",
      "  8.577254   -0.00418436  0.02162115  8.574989   -0.00399152  0.0217767\n",
      "  8.57805    -0.00653502  0.01914867  8.58017    -0.00506145  0.02012574\n",
      "  8.574344   -0.00387561  0.01986536  8.574201   -0.00594503  0.02222824\n",
      "  8.575941   -0.00736262  0.02103469  8.574182   -0.00618547  0.0190888\n",
      "  8.573944   -0.00645809  0.01701276  8.573064   -0.00555292  0.0190782\n",
      "  8.573169   -0.00409814  0.01893005  8.571572   -0.00615226  0.0231559\n",
      "  8.570943   -0.00733435  0.02050165  8.570824   -0.00616522  0.01997779\n",
      "  8.573595   -0.00285508  0.02266856  8.569768   -0.0005482   0.0200972\n",
      "  8.563346   -0.00242199  0.01813856  8.569615   -0.00433783  0.01900239\n",
      "  8.565632   -0.00200707  0.01899615  8.562543   -0.00488578  0.02088645\n",
      "  8.567423   -0.00223367  0.01964829  8.562147   -0.00337069  0.01994379\n",
      "  8.566233   -0.00156729  0.02223463  8.560793   -0.00444076  0.01894637] (expected [ 8.68  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55\n",
      " -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007\n",
      "  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02   8.55  -0.007  0.02\n",
      "  8.55  -0.007  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02\n",
      "  8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55\n",
      " -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.008\n",
      "  0.02   8.55  -0.008  0.02   8.55  -0.008  0.02   8.55  -0.009  0.02\n",
      "  8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55\n",
      " -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009\n",
      "  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02   8.55  -0.009  0.02 ])\n",
      "[7757309.348 -363499.087      -2.407       6.407 7757333.518 -363490.282\n",
      "       3.096       6.789       0.063] -> [6.7516246  0.06393541 0.0203922  6.714112   0.06429583 0.01986296\n",
      " 6.7130346  0.06421862 0.02037632 6.714601   0.06174846 0.01862007\n",
      " 6.690399   0.06312048 0.02134422 6.7101917  0.06299231 0.01969864\n",
      " 6.697115   0.0635093  0.01890697 6.6980944  0.06255621 0.02043486\n",
      " 6.696756   0.06170458 0.02021852 6.673561   0.0622045  0.01976297\n",
      " 6.710045   0.06274613 0.02008623 6.674609   0.0626265  0.01846962\n",
      " 6.6977534  0.06200032 0.02084127 6.681123   0.06232089 0.02072971\n",
      " 6.691144   0.06180153 0.02126975 6.7009463  0.06254116 0.01991961\n",
      " 6.6646037  0.06192434 0.01919109 6.663426   0.06095931 0.02039833\n",
      " 6.6841207  0.06183478 0.01955387 6.6679854  0.06177959 0.01980429\n",
      " 6.652021   0.06063057 0.01983571 6.6637483  0.06052557 0.02118478\n",
      " 6.650559   0.06046109 0.02037393 6.679942   0.06084244 0.02039348\n",
      " 6.64709    0.05994342 0.02032236 6.6720653  0.05926207 0.01921879\n",
      " 6.664455   0.05888236 0.0193051  6.647466   0.0593219  0.0200149\n",
      " 6.6470604  0.06064299 0.02071782 6.626414   0.05951655 0.02003768\n",
      " 6.635787   0.05980266 0.02034537 6.635339   0.06039565 0.01852893\n",
      " 6.6426735  0.06026457 0.01953453 6.6192966  0.05949992 0.02007317\n",
      " 6.6249437  0.06008597 0.02125828 6.615039   0.05911204 0.02098817\n",
      " 6.6027455  0.05909542 0.02104271 6.616658   0.06002344 0.01874468\n",
      " 6.613754   0.06030071 0.01947895 6.5958104  0.05995737 0.01991723\n",
      " 6.606965   0.05849443 0.01943179 6.617211   0.05763273 0.02095491\n",
      " 6.620795   0.05855547 0.02065229 6.593711   0.05880125 0.01958214\n",
      " 6.578475   0.05770756 0.01979366 6.6092935  0.05872704 0.01973746\n",
      " 6.593334   0.05818869 0.02065203 6.594169   0.05764527 0.0194798\n",
      " 6.5751987  0.05768259 0.01949466 6.601967   0.05686679 0.01971253] (expected [6.789 0.063 0.02  6.787 0.063 0.02  6.785 0.063 0.02  6.783 0.063 0.02\n",
      " 6.781 0.063 0.02  6.779 0.063 0.02  6.777 0.063 0.02  6.775 0.063 0.02\n",
      " 6.773 0.063 0.02  6.771 0.063 0.02  6.769 0.063 0.02  6.767 0.063 0.02\n",
      " 6.765 0.063 0.02  6.763 0.063 0.02  6.761 0.063 0.02  6.759 0.063 0.02\n",
      " 6.757 0.064 0.02  6.755 0.064 0.02  6.753 0.064 0.02  6.751 0.064 0.02\n",
      " 6.75  0.064 0.02  6.748 0.064 0.02  6.746 0.064 0.02  6.744 0.064 0.02\n",
      " 6.742 0.064 0.02  6.74  0.064 0.02  6.738 0.064 0.02  6.736 0.065 0.02\n",
      " 6.734 0.065 0.02  6.732 0.065 0.02  6.73  0.065 0.02  6.728 0.065 0.02\n",
      " 6.726 0.066 0.02  6.724 0.066 0.02  6.722 0.066 0.02  6.72  0.066 0.02\n",
      " 6.718 0.067 0.02  6.716 0.067 0.02  6.714 0.067 0.02  6.712 0.067 0.02\n",
      " 6.71  0.068 0.02  6.708 0.068 0.02  6.706 0.068 0.02  6.705 0.069 0.02\n",
      " 6.703 0.069 0.02  6.701 0.07  0.02  6.699 0.07  0.02  6.697 0.071 0.02\n",
      " 6.695 0.071 0.02  6.693 0.072 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "np.set_printoptions(suppress=True)\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.02\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75696163e+06 -3.64057635e+05 -1.38000000e-01  8.54600000e+00\n",
      "  7.75692823e+06 -3.64053126e+05 -1.32000000e-01  8.49100000e+00\n",
      " -2.00000000e-03] -> [ 8.4910440e+00 -2.1275878e-03  2.0009704e-02] (expected [ 8.491e+00 -2.000e-03  2.000e-02])\n",
      "[ 7.75720516e+06 -3.63589039e+05 -2.53100000e+00  8.55000000e+00\n",
      "  7.75723371e+06 -3.63569516e+05 -2.49900000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609583e+00 -6.1482787e-03  2.0036645e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75717733e+06 -3.63615552e+05  1.04800000e+00  4.16700000e+00\n",
      "  7.75716855e+06 -3.63636256e+05  1.09200000e+00  5.54400000e+00\n",
      "  6.30000000e-02] -> [5.5442753  0.06288677 0.02018113] (expected [5.544 0.063 0.02 ])\n",
      "[ 7.75719467e+06 -3.63595825e+05 -2.57200000e+00  8.52500000e+00\n",
      "  7.75722353e+06 -3.63576869e+05 -2.54100000e+00  8.66100000e+00\n",
      " -6.00000000e-03] -> [ 8.6609735e+00 -6.1470866e-03  2.0041056e-02] (expected [ 8.661e+00 -6.000e-03  2.000e-02])\n",
      "[ 7.75663871e+06 -3.63686725e+05 -2.46600000e+00  8.55000000e+00\n",
      "  7.75666680e+06 -3.63666710e+05 -2.61800000e+00  8.69300000e+00\n",
      "  2.20000000e-02] -> [8.693061   0.02189618 0.01997633] (expected [8.693 0.022 0.02 ])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU COM 3 SAIDAS\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,3))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 3)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 3)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    #torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 3)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            end = min(start+batch_size, len(X_train))  # Add this line\n",
    "            X_batch = X_train[start:end]  # Modify this line\n",
    "            y_batch = y_train[start:end]  # Modify this line\n",
    "            #X_batch = X_train[start:start+batch_size]\n",
    "            #y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RMSE: 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAy80lEQVR4nO3dfXhU5YH//89kkpkkSCaEQB4kQBAEUZ4EifGh6s9oSPlS6e5a5EslpoqXlO6KqVrTKuhaG7UtRXdZWRUMblXQr4qtD6iNAksNIGC0toqgyGMmQDSZJEBCMuf3B2TiSCBzwsw5k/h+Xde5IOfc58w999WaD/fTcRiGYQgAACCKxdhdAQAAgM4QWAAAQNQjsAAAgKhHYAEAAFGPwAIAAKIegQUAAEQ9AgsAAIh6BBYAABD1Yu2uQDj4/X7t27dPvXv3lsPhsLs6AAAgBIZhqL6+XpmZmYqJOXUfSo8ILPv27VNWVpbd1QAAAF2we/duDRgw4JRlekRg6d27t6RjXzgpKcnm2gAAgFD4fD5lZWUFfo+fSo8ILG3DQElJSQQWAAC6mVCmczDpFgAARD0CCwAAiHoEFgAAEPUILAAAIOoRWAAAQNQjsAAAgKhHYAEAAFGPwAIAAKIegQUAAEQ9AgsAAIh6BBYAABD1CCwAACDq9YiXH0ZKc4tfD636VEdb/frV5HPkjnXaXSUAAL6T6GHpxJJ1O/R0xU41tfjtrgoAAN9ZBJZTiHO2v+76KIEFAADbEFhOweFwKDbmWGg52mrYXBsAAL67CCydiHMea6KjrfSwAABgFwJLJ9qGhQgsAADYh8DSCVdsWw8LQ0IAANiFwNIJhoQAALAfgaUTbYGlmcACAIBtCCydiG2bw8KyZgAAbENg6YTLyRwWAADsRmDpBHNYAACwH4GlE23LmpnDAgCAfUwHlrVr12rKlCnKzMyUw+HQypUrT1n+hhtukMPhOOE499xzA2XuvffeE66PGDHC9JeJhLYelhaGhAAAsI3pwNLY2KgxY8Zo0aJFIZV/5JFHVFVVFTh2796tlJQUXXvttUHlzj333KBy69atM1u1iGjfh4UeFgAA7BJr9oaCggIVFBSEXN7j8cjj8QR+Xrlypb7++msVFRUFVyQ2Vunp6WarE3EsawYAwH6Wz2FZsmSJ8vLyNGjQoKDz27ZtU2ZmpoYMGaIZM2Zo165dJ31GU1OTfD5f0BEpbM0PAID9LA0s+/bt0xtvvKGbbrop6HxOTo7Kysq0atUqPfbYY9qxY4cuvfRS1dfXd/ic0tLSQM+Nx+NRVlZWxOoc27ZKiH1YAACwjaWBZdmyZUpOTtbUqVODzhcUFOjaa6/V6NGjlZ+fr9dff121tbV6/vnnO3xOSUmJ6urqAsfu3bsjVmf2YQEAwH6m57B0lWEYWrp0qa6//nq5XK5Tlk1OTtbZZ5+t7du3d3jd7XbL7XZHoponYFkzAAD2s6yHZc2aNdq+fbtuvPHGTss2NDTo888/V0ZGhgU1OzU2jgMAwH6mA0tDQ4MqKytVWVkpSdqxY4cqKysDk2RLSko0c+bME+5bsmSJcnJydN55551w7fbbb9eaNWv05Zdf6r333tMPf/hDOZ1OTZ8+3Wz1wo59WAAAsJ/pIaFNmzbpiiuuCPxcXFwsSSosLFRZWZmqqqpOWOFTV1enF198UY888kiHz9yzZ4+mT5+umpoa9evXT5dcconWr1+vfv36ma1e2LEPCwAA9jMdWC6//HIZxsl7G8rKyk445/F4dOjQoZPes3z5crPVsAxzWAAAsB/vEuoEc1gAALAfgaUTgcDSwhwWAADsQmDpBDvdAgBgPwJLJ3iXEAAA9iOwdIJlzQAA2I/A0gkXk24BALAdgaUTcbEsawYAwG4Elk6wrBkAAPsRWDoRx9uaAQCwHYGlEyxrBgDAfgSWTgSWNbcQWAAAsAuBpRPMYQEAwH4Elk4E9mHxM4cFAAC7EFg6EdiHhSEhAABsQ2DpRPs+LPSwAABgFwJLJ5jDAgCA/QgsnYiLIbAAAGA3Aksn2oaECCwAANiHwNKJb+50axjMYwEAwA4Elk60BRaJ7fkBALALgaUTrm8ElhY/w0IAANiBwNKJtncJSdLRFnpYAACwA4GlE84YhxzHM0szE28BALAFgaUTDoeDvVgAALAZgSUEcTEsbQYAwE4ElhDExdLDAgCAnQgsIWgbEmpm0i0AALYgsITAxRwWAABsRWAJQdvSZvZhAQDAHgSWEDAkBACAvQgsIWBZMwAA9iKwhIBVQgAA2IvAEgL2YQEAwF4ElhAE5rDwtmYAAGxhOrCsXbtWU6ZMUWZmphwOh1auXHnK8qtXr5bD4Tjh8Hq9QeUWLVqkwYMHKz4+Xjk5Odq4caPZqkVMYEiohR4WAADsYDqwNDY2asyYMVq0aJGp+7Zu3aqqqqrA0b9//8C1FStWqLi4WPPnz9eWLVs0ZswY5efna//+/WarFxEuljUDAGCrWLM3FBQUqKCgwPQH9e/fX8nJyR1eW7BggWbNmqWioiJJ0uLFi/Xaa69p6dKluuuuu0x/VrgxJAQAgL0sm8MyduxYZWRk6KqrrtJf//rXwPnm5mZt3rxZeXl57ZWKiVFeXp4qKiqsqt4pBZY1MyQEAIAtIh5YMjIytHjxYr344ot68cUXlZWVpcsvv1xbtmyRJB08eFCtra1KS0sLui8tLe2EeS5tmpqa5PP5go5IYh8WAADsZXpIyKzhw4dr+PDhgZ8vuugiff755/rDH/6g//mf/+nSM0tLS3XfffeFq4qdatuan8ACAIA9bFnWPHHiRG3fvl2SlJqaKqfTqerq6qAy1dXVSk9P7/D+kpIS1dXVBY7du3dHtL7MYQEAwF62BJbKykplZGRIklwul8aPH6/y8vLAdb/fr/LycuXm5nZ4v9vtVlJSUtARSQwJAQBgL9NDQg0NDYHeEUnasWOHKisrlZKSooEDB6qkpER79+7V008/LUlauHChsrOzde655+rIkSN68skn9c477+itt94KPKO4uFiFhYWaMGGCJk6cqIULF6qxsTGwashucbHHh4SYdAsAgC1MB5ZNmzbpiiuuCPxcXFwsSSosLFRZWZmqqqq0a9euwPXm5mb9/Oc/1969e5WYmKjRo0frL3/5S9Azpk2bpgMHDmjevHnyer0aO3asVq1adcJEXLu4jvewtPgZEgIAwA4OwzC6/W9hn88nj8ejurq6iAwPPVq+TQve/kz/N2egfvPDUWF/PgAA30Vmfn/zLqEQsA8LAAD2IrCEgGXNAADYi8ASgvZVQt1+9AwAgG6JwBKC9n1Y6GEBAMAOBJYQMCQEAIC9CCwhcMWycRwAAHYisISAOSwAANiLwBICtuYHAMBeBJYQMIcFAAB7EVhC4ApsHMeQEAAAdiCwhCCWISEAAGxFYAlB25AQ+7AAAGAPAksImHQLAIC9CCwhaN+HhTksAADYgcASAnpYAACwF4ElBCxrBgDAXgSWELjY6RYAAFsRWELQtqy51W+o1U9oAQDAagSWELQNCUkMCwEAYAcCSwjaJt1KBBYAAOxAYAlBcGBhSAgAAKsRWELgjHHIGcNKIQAA7EJgCRFLmwEAsA+BJURxLG0GAMA2BJYQudjtFgAA2xBYQhTb9sbmFgILAABWI7CEiPcJAQBgHwJLiNieHwAA+xBYQkQPCwAA9iGwhCgulmXNAADYhcASIpY1AwBgHwJLiBgSAgDAPgSWELEPCwAA9iGwhIh9WAAAsA+BJUTMYQEAwD6mA8vatWs1ZcoUZWZmyuFwaOXKlacs/9JLL+mqq65Sv379lJSUpNzcXL355ptBZe699145HI6gY8SIEWarFlEMCQEAYB/TgaWxsVFjxozRokWLQiq/du1aXXXVVXr99de1efNmXXHFFZoyZYo++OCDoHLnnnuuqqqqAse6devMVi2ieFszAAD2iTV7Q0FBgQoKCkIuv3DhwqCff/Ob3+iVV17Rn//8Z40bN669IrGxSk9PN1sdyzAkBACAfSyfw+L3+1VfX6+UlJSg89u2bVNmZqaGDBmiGTNmaNeuXSd9RlNTk3w+X9ARaXGxDAkBAGAXywPL7373OzU0NOhHP/pR4FxOTo7Kysq0atUqPfbYY9qxY4cuvfRS1dfXd/iM0tJSeTyewJGVlRXxejOHBQAA+1gaWJ599lndd999ev7559W/f//A+YKCAl177bUaPXq08vPz9frrr6u2tlbPP/98h88pKSlRXV1d4Ni9e3fE6x4bc3xZM4EFAADLmZ7D0lXLly/XTTfdpBdeeEF5eXmnLJucnKyzzz5b27dv7/C62+2W2+2ORDVPKjAk1MIcFgAArGZJD8tzzz2noqIiPffcc5o8eXKn5RsaGvT5558rIyPDgtqFhq35AQCwj+keloaGhqCejx07dqiyslIpKSkaOHCgSkpKtHfvXj399NOSjg0DFRYW6pFHHlFOTo68Xq8kKSEhQR6PR5J0++23a8qUKRo0aJD27dun+fPny+l0avr06eH4jmHhYlkzAAC2Md3DsmnTJo0bNy6wJLm4uFjjxo3TvHnzJElVVVVBK3wef/xxtbS0aM6cOcrIyAgct956a6DMnj17NH36dA0fPlw/+tGP1LdvX61fv179+vU73e8XNm09LMxhAQDAeqZ7WC6//HIZxsnncZSVlQX9vHr16k6fuXz5crPVsFxbYGlhHxYAACzHu4RCxD4sAADYh8ASIuawAABgHwJLiGJj2uawMCQEAIDVCCwhat+HhR4WAACsRmAJEUNCAADYh8ASIjaOAwDAPgSWELXvw8IcFgAArEZgCVH7Piz0sAAAYDUCS4hcscxhAQDALgSWELXPYWFICAAAqxFYQtS+Dws9LAAAWI3AEiKGhAAAsA+BJUSBISE2jgMAwHIElhAxhwUAAPsQWELUvg+LX4ZBaAEAwEoElhC5nO1N1eonsAAAYCUCS4jijk+6lRgWAgDAagSWEMV9o4eFpc0AAFiLwBKi2Jhv9rAQWAAAsBKBJUQOh0NxTvZiAQDADgQWE9r3YmEOCwAAViKwmPDNpc0AAMA6BBYT2gJLi5/AAgCAlQgsJrja5rAwJAQAgKUILCbExTIkBACAHQgsJrQtbWaVEAAA1iKwmND+AkQCCwAAViKwmOCKJbAAAGAHAosJgWXNTLoFAMBSBBYT2OkWAAB7EFhMYB8WAADsQWAxwcXW/AAA2ILAYgJb8wMAYA8CiwmxzGEBAMAWBBYTXOzDAgCALUwHlrVr12rKlCnKzMyUw+HQypUrO71n9erVOv/88+V2uzV06FCVlZWdUGbRokUaPHiw4uPjlZOTo40bN5qtWsS1bxzHHBYAAKxkOrA0NjZqzJgxWrRoUUjld+zYocmTJ+uKK65QZWWl5s6dq5tuuklvvvlmoMyKFStUXFys+fPna8uWLRozZozy8/O1f/9+s9WLqLjYY0NCzS30sAAAYKVYszcUFBSooKAg5PKLFy9Wdna2fv/730uSzjnnHK1bt05/+MMflJ+fL0lasGCBZs2apaKiosA9r732mpYuXaq77rrLbBUjhq35AQCwR8TnsFRUVCgvLy/oXH5+vioqKiRJzc3N2rx5c1CZmJgY5eXlBcp8W1NTk3w+X9BhBVdgHxaGhAAAsFLEA4vX61VaWlrQubS0NPl8Ph0+fFgHDx5Ua2trh2W8Xm+HzywtLZXH4wkcWVlZEav/N7VvzU8PCwAAVuqWq4RKSkpUV1cXOHbv3m3J5zIkBACAPUzPYTErPT1d1dXVQeeqq6uVlJSkhIQEOZ1OOZ3ODsukp6d3+Ey32y232x2xOp8M+7AAAGCPiPew5Obmqry8POjc22+/rdzcXEmSy+XS+PHjg8r4/X6Vl5cHykQLF8uaAQCwhenA0tDQoMrKSlVWVko6tmy5srJSu3btknRsuGbmzJmB8rfccou++OIL3Xnnnfr000/1X//1X3r++ed12223BcoUFxfriSee0LJly/TJJ59o9uzZamxsDKwaihZtb2tma34AAKxlekho06ZNuuKKKwI/FxcXS5IKCwtVVlamqqqqQHiRpOzsbL322mu67bbb9Mgjj2jAgAF68sknA0uaJWnatGk6cOCA5s2bJ6/Xq7Fjx2rVqlUnTMS1W1xs28sPCSwAAFjJYRhGtx/f8Pl88ng8qqurU1JSUsQ+5/lNu3Xn//tIVwzvp6eKJkbscwAA+C4w8/u7W64Ssgv7sAAAYA8CiwnswwIAgD0ILCawrBkAAHsQWExgWTMAAPYgsJjATrcAANiDwGIC+7AAAGAPAosJgX1YCCwAAFiKwGJCYA5LC3NYAACwEoHFhLjAPiz0sAAAYCUCiwmBOSzswwIAgKUILCbEsawZAABbEFhMYFkzAAD2ILCY0DYk1OI35Od9QgAAWIbAYkLbsmZJOsrEWwAALENgMaFtWbPEPBYAAKxEYDEh7huBpYV5LAAAWIbAYoIzxqGYY9NY2J4fAAALEVhMYmkzAADWI7CYFAgsbB4HAIBlCCwmtS1tZi8WAACsQ2Axqa2HhTksAABYh8BiEnNYAACwHoHFJFcs2/MDAGA1AotJzGEBAMB6BBaTGBICAMB6BBaTYlnWDACA5QgsJrkYEgIAwHIEFpNY1gwAgPUILCYxhwUAAOsRWExqDyz0sAAAYBUCi0muWOawAABgNQKLSQwJAQBgPQKLSQwJAQBgPQKLSYGdbtmHBQAAyxBYTKKHBQAA63UpsCxatEiDBw9WfHy8cnJytHHjxpOWvfzyy+VwOE44Jk+eHChzww03nHB90qRJXalaxLXvw8IcFgAArBJr9oYVK1aouLhYixcvVk5OjhYuXKj8/Hxt3bpV/fv3P6H8Sy+9pObm5sDPNTU1GjNmjK699tqgcpMmTdJTTz0V+NntdputmiXoYQEAwHqme1gWLFigWbNmqaioSCNHjtTixYuVmJiopUuXdlg+JSVF6enpgePtt99WYmLiCYHF7XYHlevTp0/XvlGEsTU/AADWMxVYmpubtXnzZuXl5bU/ICZGeXl5qqioCOkZS5Ys0XXXXadevXoFnV+9erX69++v4cOHa/bs2aqpqTnpM5qamuTz+YIOq9DDAgCA9UwFloMHD6q1tVVpaWlB59PS0uT1eju9f+PGjfr444910003BZ2fNGmSnn76aZWXl+uhhx7SmjVrVFBQoNbW1g6fU1paKo/HEziysrLMfI3TkuBySpIamjquGwAACD/Tc1hOx5IlSzRq1ChNnDgx6Px1110X+PuoUaM0evRonXXWWVq9erWuvPLKE55TUlKi4uLiwM8+n8+y0JLSyyVJqj3U3ElJAAAQLqZ6WFJTU+V0OlVdXR10vrq6Wunp6ae8t7GxUcuXL9eNN97Y6ecMGTJEqamp2r59e4fX3W63kpKSgg6r9DkeWL5qJLAAAGAVU4HF5XJp/PjxKi8vD5zz+/0qLy9Xbm7uKe994YUX1NTUpB//+Medfs6ePXtUU1OjjIwMM9WzREriscDyNYEFAADLmF4lVFxcrCeeeELLli3TJ598otmzZ6uxsVFFRUWSpJkzZ6qkpOSE+5YsWaKpU6eqb9++QecbGhp0xx13aP369fryyy9VXl6ua665RkOHDlV+fn4Xv1bktA0JfcWQEAAAljE9h2XatGk6cOCA5s2bJ6/Xq7Fjx2rVqlWBibi7du1STExwDtq6davWrVunt95664TnOZ1OffTRR1q2bJlqa2uVmZmpq6++Wvfff39U7sWSnBgnSTpy1K/Dza2BSbgAACByHIZhdPstW30+nzwej+rq6iI+n8UwDJ199xs62mror3f9fzozOSGinwcAQE9l5vc37xIyyeFwqA/zWAAAsBSBpQva5rF8zTwWAAAsQWDpgrYeFpY2AwBgDQJLFwR6WAgsAABYgsDSBX16HVsp9NWhozbXBACA7wYCSxeweRwAANYisHRBHzaPAwDAUgSWLmBZMwAA1iKwdAEvQAQAwFoEli4IzGFhSAgAAEsQWLqgbZXQ141H1QPebAAAQNQjsHRB2z4sza1+HWputbk2AAD0fASWLkiIc8ode6zpmMcCAEDkEVi6wOFw8D4hAAAsRGDpIt4nBACAdQgsXUQPCwAA1iGwdFH7Xiy8TwgAgEgjsHRRn8S2pc30sAAAEGkEli4KzGFhSAgAgIgjsHRRYA4LPSwAAEQcgaWLeJ8QAADWIbB0Udv7hGoPMekWAIBII7B0Udv7hJjDAgBA5BFYuuibc1h4ASIAAJFFYOmitlVCLX5D9U0tNtcGAICejcDSRfFxTiW6nJJYKQQAQKQRWE4D7xMCAMAaBJbT0DbxlvcJAQAQWQSW09Dew8LSZgAAIonAchrY7RYAAGsQWE4D7xMCAMAaBJbTQA8LAADWILCchrb3CTHpFgCAyCKwnIa29wl9zaRbAAAiisByGnifEAAA1uhSYFm0aJEGDx6s+Ph45eTkaOPGjSctW1ZWJofDEXTEx8cHlTEMQ/PmzVNGRoYSEhKUl5enbdu2daVqluqTyBwWAACsYDqwrFixQsXFxZo/f762bNmiMWPGKD8/X/v37z/pPUlJSaqqqgocO3fuDLr+8MMP69FHH9XixYu1YcMG9erVS/n5+Tpy5Ij5b2ShlG/MYfH7eQEiAACRYjqwLFiwQLNmzVJRUZFGjhypxYsXKzExUUuXLj3pPQ6HQ+np6YEjLS0tcM0wDC1cuFB33323rrnmGo0ePVpPP/209u3bp5UrV3bpS1klOfHYkJDfkHxHmMcCAECkmAoszc3N2rx5s/Ly8tofEBOjvLw8VVRUnPS+hoYGDRo0SFlZWbrmmmv097//PXBtx44d8nq9Qc/0eDzKyck56TObmprk8/mCDju4Y506wx0rifcJAQAQSaYCy8GDB9Xa2hrUQyJJaWlp8nq9Hd4zfPhwLV26VK+88or++Mc/yu/366KLLtKePXskKXCfmWeWlpbK4/EEjqysLDNfI6x4nxAAAJEX8VVCubm5mjlzpsaOHavLLrtML730kvr166f//u//7vIzS0pKVFdXFzh2794dxhqbk8L7hAAAiDhTgSU1NVVOp1PV1dVB56urq5Wenh7SM+Li4jRu3Dht375dkgL3mXmm2+1WUlJS0GGXPux2CwBAxJkKLC6XS+PHj1d5eXngnN/vV3l5uXJzc0N6Rmtrq/72t78pIyNDkpSdna309PSgZ/p8Pm3YsCHkZ9opsHkcQ0IAAERMrNkbiouLVVhYqAkTJmjixIlauHChGhsbVVRUJEmaOXOmzjzzTJWWlkqS/v3f/10XXnihhg4dqtraWv32t7/Vzp07ddNNN0k6toJo7ty5+vWvf61hw4YpOztb99xzjzIzMzV16tTwfdMIaethYfM4AAAix3RgmTZtmg4cOKB58+bJ6/Vq7NixWrVqVWDS7K5duxQT095x8/XXX2vWrFnyer3q06ePxo8fr/fee08jR44MlLnzzjvV2Niom2++WbW1tbrkkku0atWqEzaYi0a8ABEAgMhzGIbR7Xc88/l88ng8qqurs3w+yzMbdupXL3+svHPS9GThBEs/GwCA7szM72/eJXSamMMCAEDkEVhOE6uEAACIPALLaUph0i0AABFHYDlNbW9srjt8VC2tfptrAwBAz0RgOU1tL0A0jGOhBQAAhB+B5TTFOWOUFH9sdXgN81gAAIgIAksYZKUkSpK+PNhoc00AAOiZCCxhMKTfGZKkHQQWAAAigsASBtmpvSRJXxwgsAAAEAkEljA4q9/xwHKwweaaAADQMxFYwmBI6rEhIXpYAACIDAJLGAxOPTbptqaxWXWHWNoMAEC4EVjCoHd8nPr3dktiWAgAgEggsITJkH5MvAUAIFIILGHC0mYAACKHwBImQ1JZKQQAQKQQWMKEISEAACKHwBImbUubdxxslN9v2FwbAAB6FgJLmAzok6A4p0NNLX7tqztsd3UAAOhRCCxhEuuM0cDjL0FkWAgAgPAisIRR20qhLw4w8RYAgHAisIRR28RbljYDABBeBJYwal/aTGABACCcCCxh1D4kRGABACCcCCxh1NbDsrf2sI4cbbW5NgAA9BwEljBK6eWSJyFOEvNYAAAIJwJLGDkcDmWnsuMtAADhRmAJs/aVQixtBgAgXAgsYXYWE28BAAg7AkuYtQ0Jfc4cFgAAwobAEmaBIaEDDTIMXoIIAEA4EFjCbHDfXnI4JN+RFtU0NttdHQAAegQCS5jFxzl1ZnKCJOaxAAAQLgSWCGhf2sxKIQAAwqFLgWXRokUaPHiw4uPjlZOTo40bN5607BNPPKFLL71Uffr0UZ8+fZSXl3dC+RtuuEEOhyPomDRpUleqFhXaVgqxeRwAAOFhOrCsWLFCxcXFmj9/vrZs2aIxY8YoPz9f+/fv77D86tWrNX36dL377ruqqKhQVlaWrr76au3duzeo3KRJk1RVVRU4nnvuua59oyjQNvF22356WAAACAfTgWXBggWaNWuWioqKNHLkSC1evFiJiYlaunRph+WfeeYZ/fSnP9XYsWM1YsQIPfnkk/L7/SovLw8q53a7lZ6eHjj69OnTtW8UBcYMSJYkvb/jKx1t9dtbGQAAegBTgaW5uVmbN29WXl5e+wNiYpSXl6eKioqQnnHo0CEdPXpUKSkpQedXr16t/v37a/jw4Zo9e7ZqamrMVC2qnHemR8mJcapvatGHu2vtrg4AAN2eqcBy8OBBtba2Ki0tLeh8WlqavF5vSM/4xS9+oczMzKDQM2nSJD399NMqLy/XQw89pDVr1qigoECtrR2/8bipqUk+ny/oiCbOGIcuGZoqSVr72QGbawMAQPdn6SqhBx98UMuXL9fLL7+s+Pj4wPnrrrtOP/jBDzRq1ChNnTpVr776qt5//32tXr26w+eUlpbK4/EEjqysLIu+Qei+N6yfJGnttoM21wQAgO7PVGBJTU2V0+lUdXV10Pnq6mqlp6ef8t7f/e53evDBB/XWW29p9OjRpyw7ZMgQpaamavv27R1eLykpUV1dXeDYvXu3ma9hiUvPPtbD8tGeWtUeYgM5AABOh6nA4nK5NH78+KAJs20TaHNzc09638MPP6z7779fq1at0oQJEzr9nD179qimpkYZGRkdXne73UpKSgo6ok2GJ0HD+p8hvyH9dXv3nY8DAEA0MD0kVFxcrCeeeELLli3TJ598otmzZ6uxsVFFRUWSpJkzZ6qkpCRQ/qGHHtI999yjpUuXavDgwfJ6vfJ6vWpoOLbkt6GhQXfccYfWr1+vL7/8UuXl5brmmms0dOhQ5efnh+lr2uN7Zx8fFmIeCwAApyXW7A3Tpk3TgQMHNG/ePHm9Xo0dO1arVq0KTMTdtWuXYmLac9Bjjz2m5uZm/cu//EvQc+bPn697771XTqdTH330kZYtW6ba2lplZmbq6quv1v333y+3232aX89elw5L1ZJ1O/S/2w7IMAw5HA67qwQAQLfkMHrAK4V9Pp88Ho/q6uqianjocHOrxvz7W2pu8esvxd/T0P697a4SAABRw8zvb94lFEEJLqcmDj6238zaz1gtBABAVxFYIux7x1cLrd3GPBYAALqKwBJhlx7fj2X9FzVqaul4IzwAAHBqBJYIG5HeW/16u3XkqF+bvvza7uoAANAtEVgizOFw6NJhDAsBAHA6CCwWuCywHwsTbwEA6AoCiwUuPv4ixE+qfNpff8Tm2gAA0P0QWCyQeoZbowd4JEl//rDK5toAAND9EFgsMu2CY2+U/p+KL+X3d/u9+gAAsBSBxSJTx56p3vGx+rLmEJNvAQAwicBikV7uWF07vq2XZafNtQEAoHshsFjo+txBkqR3tu7XrppDNtcGAIDug8BioezUXrrs7H4yDOmPG+hlAQAgVAQWi8083suy4v3dOtzMVv0AAISCwGKxy4f3V1ZKguoOH9WfPtxrd3UAAOgWCCwWc8Y4dP2Fx3pZlr23U4bBEmcAADpDYLHBjyZkyR0bo39U+bR5Jy9EBACgMwQWGyQnujR17JmSpKfe+9LeygAA0A0QWGxSeNFgSdJrH1Xpw921ttYFAIBoR2CxycjMJP3TuGO9LPf9+e/MZQEA4BQILDa6c9IIJbqc2rKrVn/6cJ/d1QEAIGoRWGyU7onXTy8/S5JU+vqnOtTcYnONAACITgQWm9106RAN6JMgr++IFq/5wu7qAAAQlQgsNouPc+qX3z9HkvTfaz7Xnq95xxAAAN9GYIkCBeelKyc7RU0tfpW+8and1QEAIOoQWKKAw+HQvCkjFeM4tsz53U/3210lAACiCoElSpyb6dGPj2/ZP+fZLfrbnjqbawQAQPQgsESRuyeP1CVDU3WouVVFZRu1s6bR7ioBABAVCCxRxBUbo8d+fL5GZiTpYEOzCpduVE1Dk93VAgDAdgSWKNM7Pk5lP7lAA/ok6MuaQ/rJsk3szwIA+M4jsESh/r3jtewnE9UnMU4f7q7VjWWbtN93xO5qAQBgGwJLlDqr3xlacsMFSohzquKLGuUvXKs3/lZld7UAALAFgSWKnT+wj1752cU6NzNJXx86qtnPbFHxikrVHT5qd9UAALAUgSXKnZ3WWy//9GLNueIsxTiklz7Yq4KFa7V84y4dOdpqd/UAALCEwzAMw+5KnC6fzyePx6O6ujolJSXZXZ2I2bzzKxU//6F21hzbvj+ll0szcgbq+gsHqX9SvM21AwDAHDO/v7vUw7Jo0SINHjxY8fHxysnJ0caNG09Z/oUXXtCIESMUHx+vUaNG6fXXXw+6bhiG5s2bp4yMDCUkJCgvL0/btm3rStV6tPGDUvTGrZfql98foTOTE/RVY7P+453tuvihdzTn2S16+YM9LIMGAPRIpgPLihUrVFxcrPnz52vLli0aM2aM8vPztX9/x9vJv/fee5o+fbpuvPFGffDBB5o6daqmTp2qjz/+OFDm4Ycf1qOPPqrFixdrw4YN6tWrl/Lz83XkCCtjvi3RFaubv3eW1txxuRb93/M1flAfHW019NpHVbptxYea8MBf9MP/+qse+cs2vfNptXbWNKrV3+070QAA33Gmh4RycnJ0wQUX6D//8z8lSX6/X1lZWfrXf/1X3XXXXSeUnzZtmhobG/Xqq68Gzl144YUaO3asFi9eLMMwlJmZqZ///Oe6/fbbJUl1dXVKS0tTWVmZrrvuuk7r9F0ZEjqZj/bUatXHXr279YA+qfKdcN3ljFF2ai9lpSQq9QyXUnq51PcMt/r2cukMd6wS3U4lumKV6HIqIc4pV2yM4pwxinM6FOeMUWyMQ84YhxwOhw3fDgDQU5n5/R1r5sHNzc3avHmzSkpKAudiYmKUl5enioqKDu+pqKhQcXFx0Ln8/HytXLlSkrRjxw55vV7l5eUFrns8HuXk5KiioqLDwNLU1KSmpvahD5/vxF/S3yWjByRr9IBk3TlphKrqDmvN1gP66+c12lZdrx0HG9XU4tfW6nptra4/rc9pCy6xMQ7FfPPvjmN/j3E4FOt0yOk4ft3hkMMhxXzjzxiHpON/OtR+zeFw6PglOdR2rv3v0rfLKBCg2s4dL9Vevu1M4Of2wNX+zG9d+0Yma7//xKD27TMdZbkTy3T+nBNPBNf7ZJ/VkVDq2Nlnherbz+56tg1PKO7q54crknf98yP3j4Jw/Xujq4/hHzzdX2yMQ3f/n5H2fb6ZwgcPHlRra6vS0tKCzqelpenTTz/t8B6v19thea/XG7jedu5kZb6ttLRU9913n5mqf2dkeBJ03cSBum7iQElSq9/QvtrD2r6/QXtrD+urxmbVNDSpprFZXzU2q7GpRYeaW48fLTp8tFVHW40Oh5Fa/IZa/IaYJQMA3z2u2JjuE1iiRUlJSVCvjc/nU1ZWlo01il7OGIeyUhKVlZJo6r5Wv6GjrX41t/rlPx5UWo//2dLqV6vfkN8w1OqXWvx++f1Sq3GsTNthGIb8ho6VM479bBiS31DgmvSNc8f/bkiBsoFzx/NT4FpbRY+XkRS4t/3vJ54PnNC3zrWfPv73jst8u9zJy3Q+0nric068J7TP6uBchyU7v68rwrXQsOPvcaLO/p3e1dp09WuE0taR/fwwieCCUStn0XX/da8nF67/rXWVM8benVBMBZbU1FQ5nU5VV1cHna+urlZ6enqH96Snp5+yfNuf1dXVysjICCozduzYDp/pdrvldrvNVB0mOWMccsY4FR/ntLsqAACYWyXkcrk0fvx4lZeXB875/X6Vl5crNze3w3tyc3ODykvS22+/HSifnZ2t9PT0oDI+n08bNmw46TMBAMB3i+khoeLiYhUWFmrChAmaOHGiFi5cqMbGRhUVFUmSZs6cqTPPPFOlpaWSpFtvvVWXXXaZfv/732vy5Mlavny5Nm3apMcff1zSsYlYc+fO1a9//WsNGzZM2dnZuueee5SZmampU6eG75sCAIBuy3RgmTZtmg4cOKB58+bJ6/Vq7NixWrVqVWDS7K5duxTzjXGuiy66SM8++6zuvvtu/fKXv9SwYcO0cuVKnXfeeYEyd955pxobG3XzzTertrZWl1xyiVatWqX4eHZvBQAAbM0PAABsEvGt+QEAAKxEYAEAAFGPwAIAAKIegQUAAEQ9AgsAAIh6BBYAABD1CCwAACDqEVgAAEDUI7AAAICoZ3pr/mjUtlmvz+ezuSYAACBUbb+3Q9l0v0cElvr6eklSVlaWzTUBAABm1dfXy+PxnLJMj3iXkN/v1759+9S7d285HI6wPtvn8ykrK0u7d+/mPUURRltbh7a2Dm1tHdraOuFqa8MwVF9fr8zMzKAXJ3ekR/SwxMTEaMCAARH9jKSkJP4PYBHa2jq0tXVoa+vQ1tYJR1t31rPShkm3AAAg6hFYAABA1COwdMLtdmv+/Plyu912V6XHo62tQ1tbh7a2Dm1tHTvaukdMugUAAD0bPSwAACDqEVgAAEDUI7AAAICoR2ABAABRj8DSiUWLFmnw4MGKj49XTk6ONm7caHeVurXS0lJdcMEF6t27t/r376+pU6dq69atQWWOHDmiOXPmqG/fvjrjjDP0z//8z6qurrapxj3Hgw8+KIfDoblz5wbO0dbhs3fvXv34xz9W3759lZCQoFGjRmnTpk2B64ZhaN68ecrIyFBCQoLy8vK0bds2G2vcfbW2tuqee+5Rdna2EhISdNZZZ+n+++8Peh8N7d01a9eu1ZQpU5SZmSmHw6GVK1cGXQ+lXb/66ivNmDFDSUlJSk5O1o033qiGhobTr5yBk1q+fLnhcrmMpUuXGn//+9+NWbNmGcnJyUZ1dbXdVeu28vPzjaeeesr4+OOPjcrKSuP73/++MXDgQKOhoSFQ5pZbbjGysrKM8vJyY9OmTcaFF15oXHTRRTbWuvvbuHGjMXjwYGP06NHGrbfeGjhPW4fHV199ZQwaNMi44YYbjA0bNhhffPGF8eabbxrbt28PlHnwwQcNj8djrFy50vjwww+NH/zgB0Z2drZx+PBhG2vePT3wwANG3759jVdffdXYsWOH8cILLxhnnHGG8cgjjwTK0N5d8/rrrxu/+tWvjJdeesmQZLz88stB10Np10mTJhljxowx1q9fb/zv//6vMXToUGP69OmnXTcCyylMnDjRmDNnTuDn1tZWIzMz0ygtLbWxVj3L/v37DUnGmjVrDMMwjNraWiMuLs544YUXAmU++eQTQ5JRUVFhVzW7tfr6emPYsGHG22+/bVx22WWBwEJbh88vfvEL45JLLjnpdb/fb6Snpxu//e1vA+dqa2sNt9ttPPfcc1ZUsUeZPHmy8ZOf/CTo3D/90z8ZM2bMMAyD9g6XbweWUNr1H//4hyHJeP/99wNl3njjDcPhcBh79+49rfowJHQSzc3N2rx5s/Ly8gLnYmJilJeXp4qKChtr1rPU1dVJklJSUiRJmzdv1tGjR4PafcSIERo4cCDt3kVz5szR5MmTg9pUoq3D6U9/+pMmTJiga6+9Vv3799e4ceP0xBNPBK7v2LFDXq83qK09Ho9ycnJo6y646KKLVF5ers8++0yS9OGHH2rdunUqKCiQRHtHSijtWlFRoeTkZE2YMCFQJi8vTzExMdqwYcNpfX6PePlhJBw8eFCtra1KS0sLOp+WlqZPP/3Uplr1LH6/X3PnztXFF1+s8847T5Lk9XrlcrmUnJwcVDYtLU1er9eGWnZvy5cv15YtW/T++++fcI22Dp8vvvhCjz32mIqLi/XLX/5S77//vv7t3/5NLpdLhYWFgfbs6L8ntLV5d911l3w+n0aMGCGn06nW1lY98MADmjFjhiTR3hESSrt6vV71798/6HpsbKxSUlJOu+0JLLDNnDlz9PHHH2vdunV2V6VH2r17t2699Va9/fbbio+Pt7s6PZrf79eECRP0m9/8RpI0btw4ffzxx1q8eLEKCwttrl3P8/zzz+uZZ57Rs88+q3PPPVeVlZWaO3euMjMzae8ejCGhk0hNTZXT6TxhxUR1dbXS09NtqlXP8bOf/Uyvvvqq3n33XQ0YMCBwPj09Xc3NzaqtrQ0qT7ubt3nzZu3fv1/nn3++YmNjFRsbqzVr1ujRRx9VbGys0tLSaOswycjI0MiRI4POnXPOOdq1a5ckBdqT/56Exx133KG77rpL1113nUaNGqXrr79et912m0pLSyXR3pESSrump6dr//79QddbWlr01VdfnXbbE1hOwuVyafz48SovLw+c8/v9Ki8vV25uro01694Mw9DPfvYzvfzyy3rnnXeUnZ0ddH38+PGKi4sLavetW7dq165dtLtJV155pf72t7+psrIycEyYMEEzZswI/J22Do+LL774hOX5n332mQYNGiRJys7OVnp6elBb+3w+bdiwgbbugkOHDikmJvjXl9PplN/vl0R7R0oo7Zqbm6va2lpt3rw5UOadd96R3+9XTk7O6VXgtKbs9nDLly833G63UVZWZvzjH/8wbr75ZiM5Odnwer12V63bmj17tuHxeIzVq1cbVVVVgePQoUOBMrfccosxcOBA45133jE2bdpk5ObmGrm5uTbWuuf45iohw6Ctw2Xjxo1GbGys8cADDxjbtm0znnnmGSMxMdH44x//GCjz4IMPGsnJycYrr7xifPTRR8Y111zDMtsuKiwsNM4888zAsuaXXnrJSE1NNe68885AGdq7a+rr640PPvjA+OCDDwxJxoIFC4wPPvjA2Llzp2EYobXrpEmTjHHjxhkbNmww1q1bZwwbNoxlzVb4j//4D2PgwIGGy+UyJk6caKxfv97uKnVrkjo8nnrqqUCZw4cPGz/96U+NPn36GImJicYPf/hDo6qqyr5K9yDfDiy0dfj8+c9/Ns477zzD7XYbI0aMMB5//PGg636/37jnnnuMtLQ0w+12G1deeaWxdetWm2rbvfl8PuPWW281Bg4caMTHxxtDhgwxfvWrXxlNTU2BMrR317z77rsd/je6sLDQMIzQ2rWmpsaYPn26ccYZZxhJSUlGUVGRUV9ff9p1cxjGN7YGBAAAiELMYQEAAFGPwAIAAKIegQUAAEQ9AgsAAIh6BBYAABD1CCwAACDqEVgAAEDUI7AAAICoR2ABAABRj8ACAACiHoEFAABEPQILAACIev8/qI/3m7OGZFkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.75655038e+06 -3.63917271e+05 -2.31000000e-01  5.70200000e+00\n",
      "  7.75653753e+06 -3.63908823e+05 -8.46000000e-01  4.40600000e+00\n",
      "  7.50000000e-02] -> [4.3999896] (expected [4.406])\n",
      "[ 7.75766160e+06 -3.63610685e+05 -2.50900000e+00  8.55000000e+00\n",
      "  7.75768651e+06 -3.63592380e+05 -2.50700000e+00  7.70300000e+00\n",
      " -2.00000000e-03] -> [7.704249] (expected [7.703])\n",
      "[ 7.75754790e+06 -3.63656925e+05 -3.13600000e+00  8.55000000e+00\n",
      "  7.75757851e+06 -3.63654357e+05 -2.96700000e+00  7.70300000e+00\n",
      " -1.50000000e-02] -> [7.705766] (expected [7.703])\n",
      "[ 7.75769361e+06 -3.63590014e+05  6.39000000e-01  8.55000000e+00\n",
      "  7.75766713e+06 -3.63610291e+05  6.52000000e-01  8.52900000e+00\n",
      "  3.00000000e-03] -> [8.52703] (expected [8.529])\n",
      "[ 7.75685868e+06 -3.64044085e+05 -1.26000000e-01  8.55000000e+00\n",
      "  7.75682885e+06 -3.64038885e+05 -1.75000000e-01  7.65400000e+00\n",
      "  1.00000000e-03] -> [7.647367] (expected [7.654])\n"
     ]
    }
   ],
   "source": [
    "#FUNCIONOU (uma saida)\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "# Read data\n",
    "#data = fetch_california_housing()\n",
    "X = np.loadtxt(dataset_input,dtype='float',delimiter=\";\",usecols=np.arange(0,9))\n",
    "y = np.loadtxt(dataset_output,dtype='float',delimiter=\";\",usecols=np.arange(0,1))\n",
    "#X, y = data.data, data.target\n",
    " \n",
    "# train-test split for model evaluation\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "\n",
    "\n",
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    " \n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    " \n",
    "# Define the model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 24),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24, 12),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(12, 6),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(6, 1)\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()  # mean square error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "n_epochs = 100   # number of epochs to run\n",
    "batch_size = 8  # size of each batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for start in bar:\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_weights)\n",
    "print(\"MSE: %.2f\" % best_mse)\n",
    "print(\"RMSE: %.2f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    " \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        X_sample = X_test_raw[i: i+1]\n",
    "        X_sample = scaler.transform(X_sample)\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_pred = model(X_sample)\n",
    "        print(f\"{X_test_raw[i]} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#Criando o modelo \n",
    "l0 = tf.keras.layers.Dense(units = 9, input_shape = [9])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 64)\n",
    "#l3 = tf.keras.layers.Dense(units = 93)\n",
    "l3 = tf.keras.layers.Dense(units = 3)\n",
    "\n",
    "\"\"\"Modelo inicial: \n",
    "l0 = tf.keras.layers.Dense(units = 4, input_shape = [4])\n",
    "l1 = tf.keras.layers.Dense(units = 64)\n",
    "l2 = tf.keras.layers.Dense(units = 128)\n",
    "l3 = tf.keras.layers.Dense(units = 3) \"\"\"\n",
    "\n",
    "model = tf.keras.Sequential([l0,l1,l2,l3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compilando o modelo\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizers.RMSprop(lr=1e-4))#tf.keras.optimizers.Adam(0.1)), loss='mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Treinar o modelo\n",
    "history = model.fit(inputMatrix,outputMatrix,epochs=500,verbose=False)#epochs inicial=500\n",
    "print(\"Finished training the model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
